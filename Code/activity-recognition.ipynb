{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fdb9ada",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T18:52:37.280259Z",
     "iopub.status.busy": "2022-04-12T18:52:37.278799Z",
     "iopub.status.idle": "2022-04-12T18:53:02.473499Z",
     "shell.execute_reply": "2022-04-12T18:53:02.473943Z",
     "shell.execute_reply.started": "2022-04-12T18:32:05.58093Z"
    },
    "papermill": {
     "duration": 25.217673,
     "end_time": "2022-04-12T18:53:02.474327",
     "exception": false,
     "start_time": "2022-04-12T18:52:37.256654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown\r\n",
      "  Downloading gdown-4.4.0.tar.gz (14 kB)\r\n",
      "  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \bdone\r\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \bdone\r\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.7/site-packages (from gdown) (2.26.0)\r\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.7/site-packages (from gdown) (4.10.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from gdown) (3.6.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from gdown) (4.62.3)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from gdown) (1.16.0)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4->gdown) (2.3.1)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2.0.9)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2021.10.8)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.26.7)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (3.1)\r\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.7.1)\r\n",
      "Building wheels for collected packages: gdown\r\n",
      "  Building wheel for gdown (pyproject.toml) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for gdown: filename=gdown-4.4.0-py3-none-any.whl size=14775 sha256=baa2852fe7646a6adc98ed2d704269cb4b0864f06ecc5565cfa2d7959b473f75\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/fb/c3/0e/c4d8ff8bfcb0461afff199471449f642179b74968c15b7a69c\r\n",
      "Successfully built gdown\r\n",
      "Installing collected packages: gdown\r\n",
      "Successfully installed gdown-4.4.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06c04c7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T18:53:02.547522Z",
     "iopub.status.busy": "2022-04-12T18:53:02.546932Z",
     "iopub.status.idle": "2022-04-12T18:53:09.312611Z",
     "shell.execute_reply": "2022-04-12T18:53:09.312089Z",
     "shell.execute_reply.started": "2022-04-12T18:32:35.03258Z"
    },
    "id": "DXOyWMVR2ZgA",
    "outputId": "08d6e671-972c-4ac8-a636-03cbf241e9bf",
    "papermill": {
     "duration": 6.806532,
     "end_time": "2022-04-12T18:53:09.312733",
     "exception": false,
     "start_time": "2022-04-12T18:53:02.506201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1exw9vOYcb0fPVseleifK0m1VxbBCsBM_\n",
      "To: /kaggle/working/model_discovery.zip\n",
      "100%|██████████| 11.9k/11.9k [00:00<00:00, 12.2MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1ozrvNU128WOGWDVhhDKtZENzBMuO-w4i\n",
      "To: /kaggle/working/data.zip\n",
      "100%|██████████| 22.5M/22.5M [00:00<00:00, 209MB/s]\n"
     ]
    }
   ],
   "source": [
    "!rm -rf model_discovery\n",
    "!rm -rf data\n",
    "import gdown\n",
    "# download source code\n",
    "gdown.download('https://drive.google.com/uc?id=1exw9vOYcb0fPVseleifK0m1VxbBCsBM_', output=None, quiet=False)\n",
    "# download data\n",
    "gdown.download('https://drive.google.com/uc?id=1ozrvNU128WOGWDVhhDKtZENzBMuO-w4i', output=None, quiet=False)\n",
    "\n",
    "!unzip -qq data.zip\n",
    "!unzip -qq model_discovery.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d9e625f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T18:53:09.378358Z",
     "iopub.status.busy": "2022-04-12T18:53:09.375799Z",
     "iopub.status.idle": "2022-04-12T18:53:14.282283Z",
     "shell.execute_reply": "2022-04-12T18:53:14.281770Z",
     "shell.execute_reply.started": "2022-04-12T18:32:42.458959Z"
    },
    "id": "Y8FjE6Aw15Ar",
    "papermill": {
     "duration": 4.939289,
     "end_time": "2022-04-12T18:53:14.282423",
     "exception": false,
     "start_time": "2022-04-12T18:53:09.343134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import model_discovery\n",
    "from collections import Counter, defaultdict\n",
    "from importlib import reload\n",
    "from matplotlib import gridspec\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from model_discovery import utils, l2lsh, my_timer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ed3348f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T18:53:14.347029Z",
     "iopub.status.busy": "2022-04-12T18:53:14.346096Z",
     "iopub.status.idle": "2022-04-12T18:53:14.371121Z",
     "shell.execute_reply": "2022-04-12T18:53:14.370624Z",
     "shell.execute_reply.started": "2022-04-12T18:32:50.54429Z"
    },
    "id": "Tk9Mv8yr26PG",
    "papermill": {
     "duration": 0.058894,
     "end_time": "2022-04-12T18:53:14.371249",
     "exception": false,
     "start_time": "2022-04-12T18:53:14.312355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dir_path = './'\n",
    "ar_data = np.load(dir_path + 'data/activity_recognition/activity_recognition_full.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9ca8251",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T18:53:14.441269Z",
     "iopub.status.busy": "2022-04-12T18:53:14.440397Z",
     "iopub.status.idle": "2022-04-12T18:53:14.442485Z",
     "shell.execute_reply": "2022-04-12T18:53:14.442879Z",
     "shell.execute_reply.started": "2022-04-12T18:32:50.569081Z"
    },
    "id": "-4GtIcMu3VyU",
    "papermill": {
     "duration": 0.040157,
     "end_time": "2022-04-12T18:53:14.443054",
     "exception": false,
     "start_time": "2022-04-12T18:53:14.402897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets = ['dsads_t', 'dsads_ra', 'dsads_la', \n",
    "            'dsads_rl', 'dsads_ll', 'oppo_b', \n",
    "            'oppo_rua', 'oppo_rla', 'oppo_lua',\n",
    "            'oppo_lla', 'pamap_w', 'pamap_c',\n",
    "            'pamap_a']\n",
    "\n",
    "# datasets = ['dsads_t', 'oppo_rua', 'pamap_a', \n",
    "#             'dsads_rl']\n",
    "\n",
    "combinations = itertools.combinations(datasets,2)\n",
    "combinations = list(combinations)\n",
    "\n",
    "permutations = itertools.permutations(datasets,2)\n",
    "permutations = list(permutations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff82066",
   "metadata": {
    "id": "GjsVRDSz4yIm",
    "papermill": {
     "duration": 0.032059,
     "end_time": "2022-04-12T18:53:14.507266",
     "exception": false,
     "start_time": "2022-04-12T18:53:14.475207",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Validate the JS-Divergence can be estimated by squared hellinger distance\n",
    "\n",
    "proposed by \n",
    "```\n",
    "Chen, L., Esfandiari, H., Fu, G., & Mirrokni, V. (2019). Locality-sensitive hashing for f-divergences: Mutual information loss and beyond. Advances in Neural Information Processing Systems, 32, 10044-10054.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5abe9075",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T18:53:14.598414Z",
     "iopub.status.busy": "2022-04-12T18:53:14.597521Z",
     "iopub.status.idle": "2022-04-12T18:53:19.573956Z",
     "shell.execute_reply": "2022-04-12T18:53:19.574388Z",
     "shell.execute_reply.started": "2022-04-12T18:32:50.576838Z"
    },
    "id": "eNEejbGw3Xm7",
    "outputId": "fa98dfde-2672-4042-b0f9-9392d6942289",
    "papermill": {
     "duration": 5.036398,
     "end_time": "2022-04-12T18:53:19.574545",
     "exception": false,
     "start_time": "2022-04-12T18:53:14.538147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0a281fc0d3e4299a7798566bc3758b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Figure JSD vs. HSD\n",
    "\n",
    "jsd = []\n",
    "shd = []\n",
    "\n",
    "for comb in tqdm(combinations, leave=False):\n",
    "    data1 = ar_data[comb[0]]\n",
    "    data2 = ar_data[comb[1]]\n",
    "    for i in range(data1.shape[1]):\n",
    "        col1 = data1[:, i]\n",
    "        col2 = data2[:, i]\n",
    "        prob1 = utils.data_to_probability(col1, 100)\n",
    "        prob2 = utils.data_to_probability(col2, 100)\n",
    "        jsd.append(utils.jensen_shannon_divergence(prob1, prob2))\n",
    "        shd.append(utils.squared_hellinger_distance(prob1, prob2))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3201c44b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T18:53:19.648945Z",
     "iopub.status.busy": "2022-04-12T18:53:19.648230Z",
     "iopub.status.idle": "2022-04-12T18:53:20.178954Z",
     "shell.execute_reply": "2022-04-12T18:53:20.178546Z",
     "shell.execute_reply.started": "2022-04-12T18:32:55.511399Z"
    },
    "id": "hD1hAmC64qtK",
    "outputId": "145734ba-3d39-4911-e4ce-e9117f58bd9e",
    "papermill": {
     "duration": 0.570893,
     "end_time": "2022-04-12T18:53:20.179114",
     "exception": false,
     "start_time": "2022-04-12T18:53:19.608221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x1200 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,4), dpi=300)\n",
    "plt.scatter(shd, jsd, s=20, edgecolor='black')\n",
    "a = np.linspace(0, 1, 100)\n",
    "plt.grid()\n",
    "plt.plot(a, a, c='red', label='Upper bound (y=x)')\n",
    "plt.plot(a, 0.69*a, c='green', label='Lower bound (y=0.69x)')\n",
    "plt.xlabel('Squared Hellinger Distance (x)')\n",
    "plt.ylabel('JS Divergence (y)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff5bc3e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T18:53:20.254506Z",
     "iopub.status.busy": "2022-04-12T18:53:20.253885Z",
     "iopub.status.idle": "2022-04-12T18:53:20.256508Z",
     "shell.execute_reply": "2022-04-12T18:53:20.256893Z",
     "shell.execute_reply.started": "2022-04-12T18:32:56.137015Z"
    },
    "papermill": {
     "duration": 0.042388,
     "end_time": "2022-04-12T18:53:20.257034",
     "exception": false,
     "start_time": "2022-04-12T18:53:20.214646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1920"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ar_data['dsads_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cabbb6b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T18:53:20.343155Z",
     "iopub.status.busy": "2022-04-12T18:53:20.342335Z",
     "iopub.status.idle": "2022-04-12T18:53:20.344738Z",
     "shell.execute_reply": "2022-04-12T18:53:20.344344Z",
     "shell.execute_reply.started": "2022-04-12T18:32:56.145568Z"
    },
    "id": "VltbwgB45xFv",
    "papermill": {
     "duration": 0.052755,
     "end_time": "2022-04-12T18:53:20.344842",
     "exception": false,
     "start_time": "2022-04-12T18:53:20.292087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "arr_cache_trained_model=[]\n",
    "\n",
    "def look_up_labels(data):\n",
    "  if data in ['dsads_t', 'dsads_ra', 'dsads_la', 'dsads_rl', 'dsads_ll']:\n",
    "    return 'dsads_label'\n",
    "  elif data in ['oppo_b', 'oppo_rua', 'oppo_rla', 'oppo_lua', 'oppo_lla']:\n",
    "    return 'oppo_label'\n",
    "  elif data in ['pamap_w', 'pamap_c', 'pamap_a']:\n",
    "    return 'pamap_label'\n",
    "\n",
    "def nn_finetune(source_name,src_x, src_y, tar_x, tar_y, src_t_size=0.2, tar_t_size=0.8, verbose=0):\n",
    "\n",
    "    filename = source_name+'_model'\n",
    "    \n",
    "    src_x_train, src_x_test, src_y_train, src_y_test = train_test_split(src_x, src_y, test_size=src_t_size, random_state=0)\n",
    "    tar_x_train, tar_x_test, tar_y_train, tar_y_test = train_test_split(tar_x, tar_y, test_size=tar_t_size, random_state=0)\n",
    "\n",
    "    input_size = src_x.shape[1]\n",
    "    src_output_size = len(np.unique(src_y))\n",
    "    tar_output_size = len(np.unique(tar_y))\n",
    "    \n",
    "    if filename not in arr_cache_trained_model:\n",
    "        print(\"Training new model->\",filename)\n",
    "        model_src = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(input_size, 1)),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(src_output_size, activation='softmax')\n",
    "        ])\n",
    "\n",
    "        model_src.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['mae', 'acc'])\n",
    "        model_src.fit(src_x_train, src_y_train, epochs=15, verbose=verbose)\n",
    "        print('Source Domain NN Accuracy')\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        print(\"Already present model->\",filename)\n",
    "        model_src=tf.keras.models.load_model(filename)\n",
    "        \n",
    "    src_acc = model_src.evaluate(src_x_test, src_y_test, verbose=1)\n",
    "    \n",
    "    arr_cache_trained_model.append(filename)\n",
    "    print(filename)\n",
    "    model_src.save(filename)\n",
    "    \n",
    "    \n",
    "    # Finetune\n",
    "    model_tar = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(input_size, 1)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(tar_output_size, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model_tar.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['mae', 'acc'])\n",
    "\n",
    "    model_tar.layers[1].set_weights(model_src.layers[1].get_weights())\n",
    "    model_tar.layers[1].trainable = False\n",
    "\n",
    "    print('Serving Accuracy');\n",
    "    ser_acc = model_src.evaluate(tar_x_test, tar_y_test, verbose=1)\n",
    "\n",
    "    model_tar.fit(tar_x_train, tar_y_train, epochs=15, verbose=verbose)\n",
    "    print('Fine-tunned model trained with tar domain size ', 1 - tar_t_size,\n",
    "        'Train size: ', tar_x_train.shape[0], 'Test size: ', tar_x_test.shape[0])\n",
    "    ft_acc = model_tar.evaluate(tar_x_test, tar_y_test, verbose=1)\n",
    "\n",
    "    return [src_acc, ser_acc, ft_acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7510dd55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T18:53:20.425686Z",
     "iopub.status.busy": "2022-04-12T18:53:20.425012Z",
     "iopub.status.idle": "2022-04-12T18:53:20.427818Z",
     "shell.execute_reply": "2022-04-12T18:53:20.428226Z",
     "shell.execute_reply.started": "2022-04-12T18:32:56.171802Z"
    },
    "papermill": {
     "duration": 0.048581,
     "end_time": "2022-04-12T18:53:20.428340",
     "exception": false,
     "start_time": "2022-04-12T18:53:20.379759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dsads_t', 'dsads_ra'),\n",
       " ('dsads_t', 'dsads_la'),\n",
       " ('dsads_t', 'dsads_rl'),\n",
       " ('dsads_t', 'dsads_ll'),\n",
       " ('dsads_t', 'oppo_b'),\n",
       " ('dsads_t', 'oppo_rua'),\n",
       " ('dsads_t', 'oppo_rla'),\n",
       " ('dsads_t', 'oppo_lua'),\n",
       " ('dsads_t', 'oppo_lla'),\n",
       " ('dsads_t', 'pamap_w'),\n",
       " ('dsads_t', 'pamap_c'),\n",
       " ('dsads_t', 'pamap_a'),\n",
       " ('dsads_ra', 'dsads_t'),\n",
       " ('dsads_ra', 'dsads_la'),\n",
       " ('dsads_ra', 'dsads_rl'),\n",
       " ('dsads_ra', 'dsads_ll'),\n",
       " ('dsads_ra', 'oppo_b'),\n",
       " ('dsads_ra', 'oppo_rua'),\n",
       " ('dsads_ra', 'oppo_rla'),\n",
       " ('dsads_ra', 'oppo_lua'),\n",
       " ('dsads_ra', 'oppo_lla'),\n",
       " ('dsads_ra', 'pamap_w'),\n",
       " ('dsads_ra', 'pamap_c'),\n",
       " ('dsads_ra', 'pamap_a'),\n",
       " ('dsads_la', 'dsads_t'),\n",
       " ('dsads_la', 'dsads_ra'),\n",
       " ('dsads_la', 'dsads_rl'),\n",
       " ('dsads_la', 'dsads_ll'),\n",
       " ('dsads_la', 'oppo_b'),\n",
       " ('dsads_la', 'oppo_rua'),\n",
       " ('dsads_la', 'oppo_rla'),\n",
       " ('dsads_la', 'oppo_lua'),\n",
       " ('dsads_la', 'oppo_lla'),\n",
       " ('dsads_la', 'pamap_w'),\n",
       " ('dsads_la', 'pamap_c'),\n",
       " ('dsads_la', 'pamap_a'),\n",
       " ('dsads_rl', 'dsads_t'),\n",
       " ('dsads_rl', 'dsads_ra'),\n",
       " ('dsads_rl', 'dsads_la'),\n",
       " ('dsads_rl', 'dsads_ll'),\n",
       " ('dsads_rl', 'oppo_b'),\n",
       " ('dsads_rl', 'oppo_rua'),\n",
       " ('dsads_rl', 'oppo_rla'),\n",
       " ('dsads_rl', 'oppo_lua'),\n",
       " ('dsads_rl', 'oppo_lla'),\n",
       " ('dsads_rl', 'pamap_w'),\n",
       " ('dsads_rl', 'pamap_c'),\n",
       " ('dsads_rl', 'pamap_a'),\n",
       " ('dsads_ll', 'dsads_t'),\n",
       " ('dsads_ll', 'dsads_ra'),\n",
       " ('dsads_ll', 'dsads_la'),\n",
       " ('dsads_ll', 'dsads_rl'),\n",
       " ('dsads_ll', 'oppo_b'),\n",
       " ('dsads_ll', 'oppo_rua'),\n",
       " ('dsads_ll', 'oppo_rla'),\n",
       " ('dsads_ll', 'oppo_lua'),\n",
       " ('dsads_ll', 'oppo_lla'),\n",
       " ('dsads_ll', 'pamap_w'),\n",
       " ('dsads_ll', 'pamap_c'),\n",
       " ('dsads_ll', 'pamap_a'),\n",
       " ('oppo_b', 'dsads_t'),\n",
       " ('oppo_b', 'dsads_ra'),\n",
       " ('oppo_b', 'dsads_la'),\n",
       " ('oppo_b', 'dsads_rl'),\n",
       " ('oppo_b', 'dsads_ll'),\n",
       " ('oppo_b', 'oppo_rua'),\n",
       " ('oppo_b', 'oppo_rla'),\n",
       " ('oppo_b', 'oppo_lua'),\n",
       " ('oppo_b', 'oppo_lla'),\n",
       " ('oppo_b', 'pamap_w'),\n",
       " ('oppo_b', 'pamap_c'),\n",
       " ('oppo_b', 'pamap_a'),\n",
       " ('oppo_rua', 'dsads_t'),\n",
       " ('oppo_rua', 'dsads_ra'),\n",
       " ('oppo_rua', 'dsads_la'),\n",
       " ('oppo_rua', 'dsads_rl'),\n",
       " ('oppo_rua', 'dsads_ll'),\n",
       " ('oppo_rua', 'oppo_b'),\n",
       " ('oppo_rua', 'oppo_rla'),\n",
       " ('oppo_rua', 'oppo_lua'),\n",
       " ('oppo_rua', 'oppo_lla'),\n",
       " ('oppo_rua', 'pamap_w'),\n",
       " ('oppo_rua', 'pamap_c'),\n",
       " ('oppo_rua', 'pamap_a'),\n",
       " ('oppo_rla', 'dsads_t'),\n",
       " ('oppo_rla', 'dsads_ra'),\n",
       " ('oppo_rla', 'dsads_la'),\n",
       " ('oppo_rla', 'dsads_rl'),\n",
       " ('oppo_rla', 'dsads_ll'),\n",
       " ('oppo_rla', 'oppo_b'),\n",
       " ('oppo_rla', 'oppo_rua'),\n",
       " ('oppo_rla', 'oppo_lua'),\n",
       " ('oppo_rla', 'oppo_lla'),\n",
       " ('oppo_rla', 'pamap_w'),\n",
       " ('oppo_rla', 'pamap_c'),\n",
       " ('oppo_rla', 'pamap_a'),\n",
       " ('oppo_lua', 'dsads_t'),\n",
       " ('oppo_lua', 'dsads_ra'),\n",
       " ('oppo_lua', 'dsads_la'),\n",
       " ('oppo_lua', 'dsads_rl'),\n",
       " ('oppo_lua', 'dsads_ll'),\n",
       " ('oppo_lua', 'oppo_b'),\n",
       " ('oppo_lua', 'oppo_rua'),\n",
       " ('oppo_lua', 'oppo_rla'),\n",
       " ('oppo_lua', 'oppo_lla'),\n",
       " ('oppo_lua', 'pamap_w'),\n",
       " ('oppo_lua', 'pamap_c'),\n",
       " ('oppo_lua', 'pamap_a'),\n",
       " ('oppo_lla', 'dsads_t'),\n",
       " ('oppo_lla', 'dsads_ra'),\n",
       " ('oppo_lla', 'dsads_la'),\n",
       " ('oppo_lla', 'dsads_rl'),\n",
       " ('oppo_lla', 'dsads_ll'),\n",
       " ('oppo_lla', 'oppo_b'),\n",
       " ('oppo_lla', 'oppo_rua'),\n",
       " ('oppo_lla', 'oppo_rla'),\n",
       " ('oppo_lla', 'oppo_lua'),\n",
       " ('oppo_lla', 'pamap_w'),\n",
       " ('oppo_lla', 'pamap_c'),\n",
       " ('oppo_lla', 'pamap_a'),\n",
       " ('pamap_w', 'dsads_t'),\n",
       " ('pamap_w', 'dsads_ra'),\n",
       " ('pamap_w', 'dsads_la'),\n",
       " ('pamap_w', 'dsads_rl'),\n",
       " ('pamap_w', 'dsads_ll'),\n",
       " ('pamap_w', 'oppo_b'),\n",
       " ('pamap_w', 'oppo_rua'),\n",
       " ('pamap_w', 'oppo_rla'),\n",
       " ('pamap_w', 'oppo_lua'),\n",
       " ('pamap_w', 'oppo_lla'),\n",
       " ('pamap_w', 'pamap_c'),\n",
       " ('pamap_w', 'pamap_a'),\n",
       " ('pamap_c', 'dsads_t'),\n",
       " ('pamap_c', 'dsads_ra'),\n",
       " ('pamap_c', 'dsads_la'),\n",
       " ('pamap_c', 'dsads_rl'),\n",
       " ('pamap_c', 'dsads_ll'),\n",
       " ('pamap_c', 'oppo_b'),\n",
       " ('pamap_c', 'oppo_rua'),\n",
       " ('pamap_c', 'oppo_rla'),\n",
       " ('pamap_c', 'oppo_lua'),\n",
       " ('pamap_c', 'oppo_lla'),\n",
       " ('pamap_c', 'pamap_w'),\n",
       " ('pamap_c', 'pamap_a'),\n",
       " ('pamap_a', 'dsads_t'),\n",
       " ('pamap_a', 'dsads_ra'),\n",
       " ('pamap_a', 'dsads_la'),\n",
       " ('pamap_a', 'dsads_rl'),\n",
       " ('pamap_a', 'dsads_ll'),\n",
       " ('pamap_a', 'oppo_b'),\n",
       " ('pamap_a', 'oppo_rua'),\n",
       " ('pamap_a', 'oppo_rla'),\n",
       " ('pamap_a', 'oppo_lua'),\n",
       " ('pamap_a', 'oppo_lla'),\n",
       " ('pamap_a', 'pamap_w'),\n",
       " ('pamap_a', 'pamap_c')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd5f2d5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T18:53:20.508710Z",
     "iopub.status.busy": "2022-04-12T18:53:20.507769Z",
     "iopub.status.idle": "2022-04-12T19:01:25.459284Z",
     "shell.execute_reply": "2022-04-12T19:01:25.458763Z"
    },
    "id": "HhDv9Qf759C2",
    "outputId": "44a4aa4c-798b-48ab-8f6d-32ee33529dd6",
    "papermill": {
     "duration": 484.995234,
     "end_time": "2022-04-12T19:01:25.459425",
     "exception": false,
     "start_time": "2022-04-12T18:53:20.464191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9522508d0af648f6b06bda27998a0494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/156 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training new model-> dsads_t_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-12 18:53:21.641311: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-12 18:53:21.724103: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-12 18:53:21.724806: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-12 18:53:21.725903: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-12 18:53:21.726964: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-12 18:53:21.727656: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-12 18:53:21.728299: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-12 18:53:23.394470: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-12 18:53:23.395334: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-12 18:53:23.395975: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-12 18:53:23.396572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
      "2022-04-12 18:53:23.792879: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Domain NN Accuracy\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.7468 - mae: 1.3854 - acc: 0.6094\n",
      "dsads_t_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-12 18:53:26.527837: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.8154 - mae: 1.3799 - acc: 0.5716\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6542 - mae: 1.3799 - acc: 0.7057\n",
      "Already present model-> dsads_t_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.7468 - mae: 1.3854 - acc: 0.6094\n",
      "dsads_t_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.8176 - mae: 1.3799 - acc: 0.6042\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6487 - mae: 1.3799 - acc: 0.7207\n",
      "Already present model-> dsads_t_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.7468 - mae: 1.3854 - acc: 0.6094\n",
      "dsads_t_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.8480 - mae: 1.3799 - acc: 0.5905\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.7330 - mae: 1.3799 - acc: 0.6484\n",
      "Already present model-> dsads_t_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.7468 - mae: 1.3854 - acc: 0.6094\n",
      "dsads_t_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.8403 - mae: 1.3799 - acc: 0.5898\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.7159 - mae: 1.3799 - acc: 0.6328\n",
      "Already present model-> dsads_t_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.7468 - mae: 1.3854 - acc: 0.6094\n",
      "dsads_t_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 4.3466 - mae: 1.4795 - acc: 0.3420\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.3472 - mae: 1.4795 - acc: 0.8828\n",
      "Already present model-> dsads_t_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.7468 - mae: 1.3854 - acc: 0.6094\n",
      "dsads_t_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 5.9587 - mae: 1.4795 - acc: 0.3186\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.4746 - mae: 1.4795 - acc: 0.8245\n",
      "Already present model-> dsads_t_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.7468 - mae: 1.3854 - acc: 0.6094\n",
      "dsads_t_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 6.4693 - mae: 1.4795 - acc: 0.3081\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 1s 2ms/step - loss: 0.5992 - mae: 1.4795 - acc: 0.7636\n",
      "Already present model-> dsads_t_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.7468 - mae: 1.3854 - acc: 0.6094\n",
      "dsads_t_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 4.8684 - mae: 1.4795 - acc: 0.3298\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.4837 - mae: 1.4795 - acc: 0.8089\n",
      "Already present model-> dsads_t_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.7468 - mae: 1.3854 - acc: 0.6094\n",
      "dsads_t_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 5.9032 - mae: 1.4795 - acc: 0.3283\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.5477 - mae: 1.4795 - acc: 0.7720\n",
      "Already present model-> dsads_t_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.7468 - mae: 1.3854 - acc: 0.6094\n",
      "dsads_t_model\n",
      "Serving Accuracy\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 17.8434 - mae: 1.3098 - acc: 0.2387\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  612 Test size:  2451\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7149 - mae: 1.3098 - acc: 0.6924\n",
      "Already present model-> dsads_t_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.7468 - mae: 1.3854 - acc: 0.6094\n",
      "dsads_t_model\n",
      "Serving Accuracy\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 18.5158 - mae: 1.3098 - acc: 0.2387\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  612 Test size:  2451\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5755 - mae: 1.3098 - acc: 0.7764\n",
      "Already present model-> dsads_t_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.7468 - mae: 1.3854 - acc: 0.6094\n",
      "dsads_t_model\n",
      "Serving Accuracy\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 17.6601 - mae: 1.3098 - acc: 0.2774\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  612 Test size:  2451\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7718 - mae: 1.3098 - acc: 0.6312\n",
      "Training new model-> dsads_ra_model\n",
      "Source Domain NN Accuracy\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6259 - mae: 1.3854 - acc: 0.7474\n",
      "dsads_ra_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.9654 - mae: 1.3799 - acc: 0.5026\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.8085 - mae: 1.3799 - acc: 0.5645\n",
      "Already present model-> dsads_ra_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6259 - mae: 1.3854 - acc: 0.7474\n",
      "dsads_ra_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6999 - mae: 1.3799 - acc: 0.6816\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6324 - mae: 1.3799 - acc: 0.7324\n",
      "Already present model-> dsads_ra_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6259 - mae: 1.3854 - acc: 0.7474\n",
      "dsads_ra_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.0255 - mae: 1.3799 - acc: 0.4967\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.7158 - mae: 1.3799 - acc: 0.6784\n",
      "Already present model-> dsads_ra_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6259 - mae: 1.3854 - acc: 0.7474\n",
      "dsads_ra_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.9685 - mae: 1.3799 - acc: 0.5078\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.7275 - mae: 1.3799 - acc: 0.6419\n",
      "Already present model-> dsads_ra_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6259 - mae: 1.3854 - acc: 0.7474\n",
      "dsads_ra_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 6.9259 - mae: 1.4795 - acc: 0.5097\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.3563 - mae: 1.4795 - acc: 0.8746\n",
      "Already present model-> dsads_ra_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6259 - mae: 1.3854 - acc: 0.7474\n",
      "dsads_ra_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 7.8041 - mae: 1.4795 - acc: 0.4873\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.4645 - mae: 1.4795 - acc: 0.8265\n",
      "Already present model-> dsads_ra_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6259 - mae: 1.3854 - acc: 0.7474\n",
      "dsads_ra_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 7.8909 - mae: 1.4795 - acc: 0.4873\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.5909 - mae: 1.4795 - acc: 0.7646\n",
      "Already present model-> dsads_ra_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6259 - mae: 1.3854 - acc: 0.7474\n",
      "dsads_ra_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 7.2835 - mae: 1.4795 - acc: 0.5002\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.4904 - mae: 1.4795 - acc: 0.7919\n",
      "Already present model-> dsads_ra_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6259 - mae: 1.3854 - acc: 0.7474\n",
      "dsads_ra_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 7.7412 - mae: 1.4795 - acc: 0.4963\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.5308 - mae: 1.4795 - acc: 0.7822\n",
      "Already present model-> dsads_ra_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6259 - mae: 1.3854 - acc: 0.7474\n",
      "dsads_ra_model\n",
      "Serving Accuracy\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 17.6072 - mae: 1.3098 - acc: 0.2346\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  612 Test size:  2451\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7024 - mae: 1.3098 - acc: 0.6924\n",
      "Already present model-> dsads_ra_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6259 - mae: 1.3854 - acc: 0.7474\n",
      "dsads_ra_model\n",
      "Serving Accuracy\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 18.1456 - mae: 1.3098 - acc: 0.2346\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  612 Test size:  2451\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5678 - mae: 1.3098 - acc: 0.7923\n",
      "Already present model-> dsads_ra_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6259 - mae: 1.3854 - acc: 0.7474\n",
      "dsads_ra_model\n",
      "Serving Accuracy\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 15.8697 - mae: 1.3098 - acc: 0.2346\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  612 Test size:  2451\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7423 - mae: 1.3098 - acc: 0.6414\n",
      "Training new model-> dsads_la_model\n",
      "Source Domain NN Accuracy\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6076 - mae: 1.3854 - acc: 0.7188\n",
      "dsads_la_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.0113 - mae: 1.3799 - acc: 0.4987\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.8051 - mae: 1.3799 - acc: 0.5827\n",
      "Already present model-> dsads_la_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6076 - mae: 1.3854 - acc: 0.7188\n",
      "dsads_la_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6146 - mae: 1.3799 - acc: 0.7116\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6576 - mae: 1.3799 - acc: 0.6979\n",
      "Already present model-> dsads_la_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6076 - mae: 1.3854 - acc: 0.7188\n",
      "dsads_la_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.0674 - mae: 1.3799 - acc: 0.5130\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.7404 - mae: 1.3799 - acc: 0.6556\n",
      "Already present model-> dsads_la_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6076 - mae: 1.3854 - acc: 0.7188\n",
      "dsads_la_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.0080 - mae: 1.3799 - acc: 0.5443\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.7309 - mae: 1.3799 - acc: 0.6504\n",
      "Already present model-> dsads_la_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6076 - mae: 1.3854 - acc: 0.7188\n",
      "dsads_la_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 7.4039 - mae: 1.4795 - acc: 0.4883\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.3456 - mae: 1.4795 - acc: 0.8820\n",
      "Already present model-> dsads_la_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6076 - mae: 1.3854 - acc: 0.7188\n",
      "dsads_la_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 7.5522 - mae: 1.4795 - acc: 0.4898\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.4687 - mae: 1.4795 - acc: 0.8255\n",
      "Already present model-> dsads_la_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6076 - mae: 1.3854 - acc: 0.7188\n",
      "dsads_la_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 7.8269 - mae: 1.4795 - acc: 0.4642\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.6062 - mae: 1.4795 - acc: 0.7300\n",
      "Already present model-> dsads_la_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6076 - mae: 1.3854 - acc: 0.7188\n",
      "dsads_la_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 7.1643 - mae: 1.4795 - acc: 0.5172\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.4684 - mae: 1.4795 - acc: 0.8310\n",
      "Already present model-> dsads_la_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6076 - mae: 1.3854 - acc: 0.7188\n",
      "dsads_la_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 7.6868 - mae: 1.4795 - acc: 0.4995\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.5340 - mae: 1.4795 - acc: 0.7790\n",
      "Already present model-> dsads_la_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6076 - mae: 1.3854 - acc: 0.7188\n",
      "dsads_la_model\n",
      "Serving Accuracy\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 20.4731 - mae: 1.3098 - acc: 0.0379\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  612 Test size:  2451\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7507 - mae: 1.3098 - acc: 0.6675\n",
      "Already present model-> dsads_la_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6076 - mae: 1.3854 - acc: 0.7188\n",
      "dsads_la_model\n",
      "Serving Accuracy\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 20.9230 - mae: 1.3098 - acc: 0.0224\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  612 Test size:  2451\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5645 - mae: 1.3098 - acc: 0.7838\n",
      "Already present model-> dsads_la_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6076 - mae: 1.3854 - acc: 0.7188\n",
      "dsads_la_model\n",
      "Serving Accuracy\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 21.4449 - mae: 1.3098 - acc: 0.0298\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  612 Test size:  2451\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7068 - mae: 1.3098 - acc: 0.6818\n",
      "Training new model-> dsads_rl_model\n",
      "Source Domain NN Accuracy\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6814 - mae: 1.3854 - acc: 0.6432\n",
      "dsads_rl_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.2894 - mae: 1.3799 - acc: 0.3424\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.8112 - mae: 1.3799 - acc: 0.5807\n",
      "Already present model-> dsads_rl_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6814 - mae: 1.3854 - acc: 0.6432\n",
      "dsads_rl_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.0976 - mae: 1.3799 - acc: 0.5098\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6688 - mae: 1.3799 - acc: 0.6992\n",
      "Already present model-> dsads_rl_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6814 - mae: 1.3854 - acc: 0.6432\n",
      "dsads_rl_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.1955 - mae: 1.3799 - acc: 0.5182\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6654 - mae: 1.3799 - acc: 0.7064\n",
      "Already present model-> dsads_rl_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6814 - mae: 1.3854 - acc: 0.6432\n",
      "dsads_rl_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6965 - mae: 1.3799 - acc: 0.6712\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.7116 - mae: 1.3799 - acc: 0.6634\n",
      "Already present model-> dsads_rl_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6814 - mae: 1.3854 - acc: 0.6432\n",
      "dsads_rl_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 2.5929 - mae: 1.4795 - acc: 0.4283\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.3459 - mae: 1.4795 - acc: 0.8853\n",
      "Already present model-> dsads_rl_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6814 - mae: 1.3854 - acc: 0.6432\n",
      "dsads_rl_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 3.8731 - mae: 1.4795 - acc: 0.3412\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.5108 - mae: 1.4795 - acc: 0.7740\n",
      "Already present model-> dsads_rl_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6814 - mae: 1.3854 - acc: 0.6432\n",
      "dsads_rl_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 4.1716 - mae: 1.4795 - acc: 0.3462\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.5688 - mae: 1.4795 - acc: 0.7795\n",
      "Already present model-> dsads_rl_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6814 - mae: 1.3854 - acc: 0.6432\n",
      "dsads_rl_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 3.2026 - mae: 1.4795 - acc: 0.3502\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.4665 - mae: 1.4795 - acc: 0.8270\n",
      "Already present model-> dsads_rl_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6814 - mae: 1.3854 - acc: 0.6432\n",
      "dsads_rl_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 4.0643 - mae: 1.4795 - acc: 0.3382\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.5306 - mae: 1.4795 - acc: 0.7852\n",
      "Already present model-> dsads_rl_model\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6814 - mae: 1.3854 - acc: 0.6432\n",
      "dsads_rl_model\n",
      "Serving Accuracy\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 10.4960 - mae: 1.3098 - acc: 0.2411\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  612 Test size:  2451\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7006 - mae: 1.3098 - acc: 0.7148\n",
      "Already present model-> dsads_rl_model\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6814 - mae: 1.3854 - acc: 0.6432\n",
      "dsads_rl_model\n",
      "Serving Accuracy\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 11.0942 - mae: 1.3098 - acc: 0.2411\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  612 Test size:  2451\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5799 - mae: 1.3098 - acc: 0.7850\n",
      "Already present model-> dsads_rl_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6814 - mae: 1.3854 - acc: 0.6432\n",
      "dsads_rl_model\n",
      "Serving Accuracy\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 10.2548 - mae: 1.3098 - acc: 0.2472\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  612 Test size:  2451\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7103 - mae: 1.3098 - acc: 0.6793\n",
      "Training new model-> dsads_ll_model\n",
      "Source Domain NN Accuracy\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6512 - mae: 1.3854 - acc: 0.6979\n",
      "dsads_ll_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.0579 - mae: 1.3799 - acc: 0.4889\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.8072 - mae: 1.3799 - acc: 0.5703\n",
      "Already present model-> dsads_ll_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6512 - mae: 1.3854 - acc: 0.6979\n",
      "dsads_ll_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.9181 - mae: 1.3799 - acc: 0.5111\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6681 - mae: 1.3799 - acc: 0.7090\n",
      "Already present model-> dsads_ll_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6512 - mae: 1.3854 - acc: 0.6979\n",
      "dsads_ll_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.8900 - mae: 1.3799 - acc: 0.5391\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.6722 - mae: 1.3799 - acc: 0.7096\n",
      "Already present model-> dsads_ll_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6512 - mae: 1.3854 - acc: 0.6979\n",
      "dsads_ll_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6962 - mae: 1.3799 - acc: 0.6628\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.7096 - mae: 1.3799 - acc: 0.6836\n",
      "Already present model-> dsads_ll_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6512 - mae: 1.3854 - acc: 0.6979\n",
      "dsads_ll_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 2.2036 - mae: 1.4795 - acc: 0.4099\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.3438 - mae: 1.4795 - acc: 0.8860\n",
      "Already present model-> dsads_ll_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6512 - mae: 1.3854 - acc: 0.6979\n",
      "dsads_ll_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 2.9818 - mae: 1.4795 - acc: 0.4084\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.4838 - mae: 1.4795 - acc: 0.8066\n",
      "Already present model-> dsads_ll_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6512 - mae: 1.3854 - acc: 0.6979\n",
      "dsads_ll_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 3.0282 - mae: 1.4795 - acc: 0.4438\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.6065 - mae: 1.4795 - acc: 0.7539\n",
      "Already present model-> dsads_ll_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6512 - mae: 1.3854 - acc: 0.6979\n",
      "dsads_ll_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 2.5239 - mae: 1.4795 - acc: 0.4121\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.4527 - mae: 1.4795 - acc: 0.8474\n",
      "Already present model-> dsads_ll_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6512 - mae: 1.3854 - acc: 0.6979\n",
      "dsads_ll_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 2.6741 - mae: 1.4795 - acc: 0.4759\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.5672 - mae: 1.4795 - acc: 0.7603\n",
      "Already present model-> dsads_ll_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6512 - mae: 1.3854 - acc: 0.6979\n",
      "dsads_ll_model\n",
      "Serving Accuracy\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 8.4692 - mae: 1.3098 - acc: 0.3370\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  612 Test size:  2451\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7752 - mae: 1.3098 - acc: 0.6499\n",
      "Already present model-> dsads_ll_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6512 - mae: 1.3854 - acc: 0.6979\n",
      "dsads_ll_model\n",
      "Serving Accuracy\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 8.8420 - mae: 1.3098 - acc: 0.2970\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  612 Test size:  2451\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5801 - mae: 1.3098 - acc: 0.7936\n",
      "Already present model-> dsads_ll_model\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6512 - mae: 1.3854 - acc: 0.6979\n",
      "dsads_ll_model\n",
      "Serving Accuracy\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 8.6369 - mae: 1.3098 - acc: 0.4047\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  612 Test size:  2451\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7206 - mae: 1.3098 - acc: 0.6618\n",
      "Training new model-> oppo_b_model\n",
      "Source Domain NN Accuracy\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2430 - mae: 1.5057 - acc: 0.9104\n",
      "oppo_b_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.0379 - mae: 1.3799 - acc: 0.2591\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.8218 - mae: 1.3799 - acc: 0.5579\n",
      "Already present model-> oppo_b_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2430 - mae: 1.5057 - acc: 0.9104\n",
      "oppo_b_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3.1506 - mae: 1.3799 - acc: 0.3066\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6702 - mae: 1.3799 - acc: 0.7083\n",
      "Already present model-> oppo_b_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2430 - mae: 1.5057 - acc: 0.9104\n",
      "oppo_b_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.5062 - mae: 1.3799 - acc: 0.3665\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6549 - mae: 1.3799 - acc: 0.7292\n",
      "Already present model-> oppo_b_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2430 - mae: 1.5057 - acc: 0.9104\n",
      "oppo_b_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.8632 - mae: 1.3799 - acc: 0.3366\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.7344 - mae: 1.3799 - acc: 0.6589\n",
      "Already present model-> oppo_b_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2430 - mae: 1.5057 - acc: 0.9104\n",
      "oppo_b_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3.5893 - mae: 1.3799 - acc: 0.2949\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 1s 2ms/step - loss: 0.7178 - mae: 1.3799 - acc: 0.6361\n",
      "Already present model-> oppo_b_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2430 - mae: 1.5057 - acc: 0.9104\n",
      "oppo_b_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 1.9315 - mae: 1.4795 - acc: 0.5679\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.3915 - mae: 1.4795 - acc: 0.8614\n",
      "Already present model-> oppo_b_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2430 - mae: 1.5057 - acc: 0.9104\n",
      "oppo_b_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 2.6927 - mae: 1.4795 - acc: 0.4965\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.5481 - mae: 1.4795 - acc: 0.7763\n",
      "Already present model-> oppo_b_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2430 - mae: 1.5057 - acc: 0.9104\n",
      "oppo_b_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 1.3336 - mae: 1.4795 - acc: 0.6526\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.4284 - mae: 1.4795 - acc: 0.8233\n",
      "Already present model-> oppo_b_model\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2430 - mae: 1.5057 - acc: 0.9104\n",
      "oppo_b_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 2.6541 - mae: 1.4795 - acc: 0.5304\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.5132 - mae: 1.4795 - acc: 0.7907\n",
      "Already present model-> oppo_b_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2430 - mae: 1.5057 - acc: 0.9104\n",
      "oppo_b_model\n",
      "Serving Accuracy\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 10.6110 - mae: 1.3098 - acc: 0.2346\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  612 Test size:  2451\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6568 - mae: 1.3098 - acc: 0.7609\n",
      "Already present model-> oppo_b_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2430 - mae: 1.5057 - acc: 0.9104\n",
      "oppo_b_model\n",
      "Serving Accuracy\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 9.0905 - mae: 1.3098 - acc: 0.1281\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  612 Test size:  2451\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3738 - mae: 1.3098 - acc: 0.8739\n",
      "Already present model-> oppo_b_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2430 - mae: 1.5057 - acc: 0.9104\n",
      "oppo_b_model\n",
      "Serving Accuracy\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 7.4465 - mae: 1.3098 - acc: 0.2530\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  612 Test size:  2451\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6992 - mae: 1.3098 - acc: 0.6716\n",
      "Training new model-> oppo_rua_model\n",
      "Source Domain NN Accuracy\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2965 - mae: 1.5057 - acc: 0.8975\n",
      "oppo_rua_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3.5312 - mae: 1.3799 - acc: 0.3171\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.8243 - mae: 1.3799 - acc: 0.5749\n",
      "Already present model-> oppo_rua_model\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2965 - mae: 1.5057 - acc: 0.8975\n",
      "oppo_rua_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7119 - mae: 1.3799 - acc: 0.4010\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6772 - mae: 1.3799 - acc: 0.7148\n",
      "Already present model-> oppo_rua_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2965 - mae: 1.5057 - acc: 0.8975\n",
      "oppo_rua_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.3135 - mae: 1.3799 - acc: 0.4023\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.6599 - mae: 1.3799 - acc: 0.7168\n",
      "Already present model-> oppo_rua_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2965 - mae: 1.5057 - acc: 0.8975\n",
      "oppo_rua_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3.4202 - mae: 1.3799 - acc: 0.3470\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.7230 - mae: 1.3799 - acc: 0.6712\n",
      "Already present model-> oppo_rua_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2965 - mae: 1.5057 - acc: 0.8975\n",
      "oppo_rua_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3.0027 - mae: 1.3799 - acc: 0.3815\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.7131 - mae: 1.3799 - acc: 0.6699\n",
      "Already present model-> oppo_rua_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2965 - mae: 1.5057 - acc: 0.8975\n",
      "oppo_rua_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 1.0108 - mae: 1.4795 - acc: 0.6605\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.3107 - mae: 1.4795 - acc: 0.9017\n",
      "Already present model-> oppo_rua_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2965 - mae: 1.5057 - acc: 0.8975\n",
      "oppo_rua_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.8331 - mae: 1.4795 - acc: 0.6697\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.5239 - mae: 1.4795 - acc: 0.7822\n",
      "Already present model-> oppo_rua_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2965 - mae: 1.5057 - acc: 0.8975\n",
      "oppo_rua_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.5662 - mae: 1.4795 - acc: 0.8143\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.4020 - mae: 1.4795 - acc: 0.8504\n",
      "Already present model-> oppo_rua_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2965 - mae: 1.5057 - acc: 0.8975\n",
      "oppo_rua_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 1.1847 - mae: 1.4795 - acc: 0.6834\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.4973 - mae: 1.4795 - acc: 0.8066\n",
      "Already present model-> oppo_rua_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2965 - mae: 1.5057 - acc: 0.8975\n",
      "oppo_rua_model\n",
      "Serving Accuracy\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 11.8828 - mae: 1.3098 - acc: 0.2346\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  612 Test size:  2451\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6308 - mae: 1.3098 - acc: 0.7540\n",
      "Already present model-> oppo_rua_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2965 - mae: 1.5057 - acc: 0.8975\n",
      "oppo_rua_model\n",
      "Serving Accuracy\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 10.6710 - mae: 1.3098 - acc: 0.1979\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  612 Test size:  2451\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3621 - mae: 1.3098 - acc: 0.8743\n",
      "Already present model-> oppo_rua_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2965 - mae: 1.5057 - acc: 0.8975\n",
      "oppo_rua_model\n",
      "Serving Accuracy\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 8.5610 - mae: 1.3098 - acc: 0.2424\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  612 Test size:  2451\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6894 - mae: 1.3098 - acc: 0.6993\n",
      "Training new model-> oppo_rla_model\n",
      "Source Domain NN Accuracy\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4353 - mae: 1.5057 - acc: 0.8418\n",
      "oppo_rla_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.8007 - mae: 1.3799 - acc: 0.2767\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.8169 - mae: 1.3799 - acc: 0.5716\n",
      "Already present model-> oppo_rla_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4353 - mae: 1.5057 - acc: 0.8418\n",
      "oppo_rla_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2394 - mae: 1.3799 - acc: 0.3770\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.6562 - mae: 1.3799 - acc: 0.7122\n",
      "Already present model-> oppo_rla_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4353 - mae: 1.5057 - acc: 0.8418\n",
      "oppo_rla_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7277 - mae: 1.3799 - acc: 0.4049\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6537 - mae: 1.3799 - acc: 0.7129\n",
      "Already present model-> oppo_rla_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4353 - mae: 1.5057 - acc: 0.8418\n",
      "oppo_rla_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.8558 - mae: 1.3799 - acc: 0.2695\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.7301 - mae: 1.3799 - acc: 0.6497\n",
      "Already present model-> oppo_rla_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4353 - mae: 1.5057 - acc: 0.8418\n",
      "oppo_rla_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.5952 - mae: 1.3799 - acc: 0.2767\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.7120 - mae: 1.3799 - acc: 0.6621\n",
      "Already present model-> oppo_rla_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4353 - mae: 1.5057 - acc: 0.8418\n",
      "oppo_rla_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 1.3190 - mae: 1.4795 - acc: 0.5704\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.3117 - mae: 1.4795 - acc: 0.8950\n",
      "Already present model-> oppo_rla_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4353 - mae: 1.5057 - acc: 0.8418\n",
      "oppo_rla_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.7200 - mae: 1.4795 - acc: 0.6899\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.3993 - mae: 1.4795 - acc: 0.8581\n",
      "Already present model-> oppo_rla_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4353 - mae: 1.5057 - acc: 0.8418\n",
      "oppo_rla_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.9453 - mae: 1.4795 - acc: 0.6127\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.4088 - mae: 1.4795 - acc: 0.8514\n",
      "Already present model-> oppo_rla_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4353 - mae: 1.5057 - acc: 0.8418\n",
      "oppo_rla_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.9563 - mae: 1.4795 - acc: 0.6553\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.4916 - mae: 1.4795 - acc: 0.8116\n",
      "Already present model-> oppo_rla_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4353 - mae: 1.5057 - acc: 0.8418\n",
      "oppo_rla_model\n",
      "Serving Accuracy\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 7.5820 - mae: 1.3098 - acc: 0.1253\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  612 Test size:  2451\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6431 - mae: 1.3098 - acc: 0.7499\n",
      "Already present model-> oppo_rla_model\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4353 - mae: 1.5057 - acc: 0.8418\n",
      "oppo_rla_model\n",
      "Serving Accuracy\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 7.1295 - mae: 1.3098 - acc: 0.0685\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  612 Test size:  2451\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3994 - mae: 1.3098 - acc: 0.8629\n",
      "Already present model-> oppo_rla_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4353 - mae: 1.5057 - acc: 0.8418\n",
      "oppo_rla_model\n",
      "Serving Accuracy\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 6.9920 - mae: 1.3098 - acc: 0.1534\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  612 Test size:  2451\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7019 - mae: 1.3098 - acc: 0.6699\n",
      "Training new model-> oppo_lua_model\n",
      "Source Domain NN Accuracy\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3400 - mae: 1.5057 - acc: 0.8846\n",
      "oppo_lua_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.4338 - mae: 1.3799 - acc: 0.4707\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.8069 - mae: 1.3799 - acc: 0.5885\n",
      "Already present model-> oppo_lua_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3400 - mae: 1.5057 - acc: 0.8846\n",
      "oppo_lua_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8051 - mae: 1.3799 - acc: 0.5586\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6571 - mae: 1.3799 - acc: 0.7116\n",
      "Already present model-> oppo_lua_model\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3400 - mae: 1.5057 - acc: 0.8846\n",
      "oppo_lua_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.4683 - mae: 1.3799 - acc: 0.5736\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6425 - mae: 1.3799 - acc: 0.7272\n",
      "Already present model-> oppo_lua_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3400 - mae: 1.5057 - acc: 0.8846\n",
      "oppo_lua_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.3526 - mae: 1.3799 - acc: 0.4701\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.7408 - mae: 1.3799 - acc: 0.6491\n",
      "Already present model-> oppo_lua_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3400 - mae: 1.5057 - acc: 0.8846\n",
      "oppo_lua_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0088 - mae: 1.3799 - acc: 0.4935\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.7034 - mae: 1.3799 - acc: 0.6725\n",
      "Already present model-> oppo_lua_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3400 - mae: 1.5057 - acc: 0.8846\n",
      "oppo_lua_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.5537 - mae: 1.4795 - acc: 0.7914\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.3179 - mae: 1.4795 - acc: 0.8962\n",
      "Already present model-> oppo_lua_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3400 - mae: 1.5057 - acc: 0.8846\n",
      "oppo_lua_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.4626 - mae: 1.4795 - acc: 0.8270\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.3891 - mae: 1.4795 - acc: 0.8586\n",
      "Already present model-> oppo_lua_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3400 - mae: 1.5057 - acc: 0.8846\n",
      "oppo_lua_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 1.0035 - mae: 1.4795 - acc: 0.5677\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.5219 - mae: 1.4795 - acc: 0.7932\n",
      "Already present model-> oppo_lua_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3400 - mae: 1.5057 - acc: 0.8846\n",
      "oppo_lua_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.7413 - mae: 1.4795 - acc: 0.7332\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.4712 - mae: 1.4795 - acc: 0.8128\n",
      "Already present model-> oppo_lua_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3400 - mae: 1.5057 - acc: 0.8846\n",
      "oppo_lua_model\n",
      "Serving Accuracy\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 8.4153 - mae: 1.3098 - acc: 0.2346\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  612 Test size:  2451\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6343 - mae: 1.3098 - acc: 0.7528\n",
      "Already present model-> oppo_lua_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3400 - mae: 1.5057 - acc: 0.8846\n",
      "oppo_lua_model\n",
      "Serving Accuracy\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 7.7311 - mae: 1.3098 - acc: 0.0608\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  612 Test size:  2451\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3841 - mae: 1.3098 - acc: 0.8470\n",
      "Already present model-> oppo_lua_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3400 - mae: 1.5057 - acc: 0.8846\n",
      "oppo_lua_model\n",
      "Serving Accuracy\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 5.9968 - mae: 1.3098 - acc: 0.2517\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  612 Test size:  2451\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6909 - mae: 1.3098 - acc: 0.6781\n",
      "Training new model-> oppo_lla_model\n",
      "Source Domain NN Accuracy\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4582 - mae: 1.5057 - acc: 0.8328\n",
      "oppo_lla_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2663 - mae: 1.3799 - acc: 0.4010\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.8158 - mae: 1.3799 - acc: 0.5755\n",
      "Already present model-> oppo_lla_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4582 - mae: 1.5057 - acc: 0.8328\n",
      "oppo_lla_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8154 - mae: 1.3799 - acc: 0.4661\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6541 - mae: 1.3799 - acc: 0.7148\n",
      "Already present model-> oppo_lla_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4582 - mae: 1.5057 - acc: 0.8328\n",
      "oppo_lla_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5812 - mae: 1.3799 - acc: 0.4863\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6488 - mae: 1.3799 - acc: 0.7188\n",
      "Already present model-> oppo_lla_model\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4582 - mae: 1.5057 - acc: 0.8328\n",
      "oppo_lla_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2680 - mae: 1.3799 - acc: 0.3789\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.7268 - mae: 1.3799 - acc: 0.6419\n",
      "Already present model-> oppo_lla_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4582 - mae: 1.5057 - acc: 0.8328\n",
      "oppo_lla_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9274 - mae: 1.3799 - acc: 0.4479\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.7062 - mae: 1.3799 - acc: 0.6510\n",
      "Already present model-> oppo_lla_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4582 - mae: 1.5057 - acc: 0.8328\n",
      "oppo_lla_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.8140 - mae: 1.4795 - acc: 0.6784\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.3402 - mae: 1.4795 - acc: 0.8776\n",
      "Already present model-> oppo_lla_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4582 - mae: 1.5057 - acc: 0.8328\n",
      "oppo_lla_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.7158 - mae: 1.4795 - acc: 0.7302\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.4063 - mae: 1.4795 - acc: 0.8502\n",
      "Already present model-> oppo_lla_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4582 - mae: 1.5057 - acc: 0.8328\n",
      "oppo_lla_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 1.0826 - mae: 1.4795 - acc: 0.5615\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.5281 - mae: 1.4795 - acc: 0.7919\n",
      "Already present model-> oppo_lla_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4582 - mae: 1.5057 - acc: 0.8328\n",
      "oppo_lla_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.5415 - mae: 1.4795 - acc: 0.7887\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.4208 - mae: 1.4795 - acc: 0.8370\n",
      "Already present model-> oppo_lla_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4582 - mae: 1.5057 - acc: 0.8328\n",
      "oppo_lla_model\n",
      "Serving Accuracy\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 5.7106 - mae: 1.3098 - acc: 0.1599\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  612 Test size:  2451\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6510 - mae: 1.3098 - acc: 0.7385\n",
      "Already present model-> oppo_lla_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4582 - mae: 1.5057 - acc: 0.8328\n",
      "oppo_lla_model\n",
      "Serving Accuracy\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 5.5116 - mae: 1.3098 - acc: 0.1212\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  612 Test size:  2451\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4878 - mae: 1.3098 - acc: 0.8066\n",
      "Already present model-> oppo_lla_model\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4582 - mae: 1.5057 - acc: 0.8328\n",
      "oppo_lla_model\n",
      "Serving Accuracy\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 6.0000 - mae: 1.3098 - acc: 0.2109\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  612 Test size:  2451\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7026 - mae: 1.3098 - acc: 0.6793\n",
      "Training new model-> pamap_w_model\n",
      "Source Domain NN Accuracy\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5092 - mae: 1.3071 - acc: 0.8091\n",
      "pamap_w_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3.7440 - mae: 1.3799 - acc: 0.2520\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.7973 - mae: 1.3799 - acc: 0.6081\n",
      "Already present model-> pamap_w_model\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5092 - mae: 1.3071 - acc: 0.8091\n",
      "pamap_w_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3.6963 - mae: 1.3799 - acc: 0.2526\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6563 - mae: 1.3799 - acc: 0.7109\n",
      "Already present model-> pamap_w_model\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5092 - mae: 1.3071 - acc: 0.8091\n",
      "pamap_w_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3.4643 - mae: 1.3799 - acc: 0.2507\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6544 - mae: 1.3799 - acc: 0.7188\n",
      "Already present model-> pamap_w_model\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5092 - mae: 1.3071 - acc: 0.8091\n",
      "pamap_w_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3.5104 - mae: 1.3799 - acc: 0.2520\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.7239 - mae: 1.3799 - acc: 0.6471\n",
      "Already present model-> pamap_w_model\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5092 - mae: 1.3071 - acc: 0.8091\n",
      "pamap_w_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3.4736 - mae: 1.3799 - acc: 0.2520\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.7167 - mae: 1.3799 - acc: 0.6536\n",
      "Already present model-> pamap_w_model\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5092 - mae: 1.3071 - acc: 0.8091\n",
      "pamap_w_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 3.4994 - mae: 1.4795 - acc: 0.3186\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.3396 - mae: 1.4795 - acc: 0.8875\n",
      "Already present model-> pamap_w_model\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5092 - mae: 1.3071 - acc: 0.8091\n",
      "pamap_w_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 3.0496 - mae: 1.4795 - acc: 0.3188\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.4198 - mae: 1.4795 - acc: 0.8487\n",
      "Already present model-> pamap_w_model\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5092 - mae: 1.3071 - acc: 0.8091\n",
      "pamap_w_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 2.4203 - mae: 1.4795 - acc: 0.3024\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.6054 - mae: 1.4795 - acc: 0.7180\n",
      "Already present model-> pamap_w_model\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5092 - mae: 1.3071 - acc: 0.8091\n",
      "pamap_w_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 3.2925 - mae: 1.4795 - acc: 0.3166\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.4245 - mae: 1.4795 - acc: 0.8499\n",
      "Already present model-> pamap_w_model\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5092 - mae: 1.3071 - acc: 0.8091\n",
      "pamap_w_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 3.1261 - mae: 1.4795 - acc: 0.2987\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.5207 - mae: 1.4795 - acc: 0.7892\n",
      "Already present model-> pamap_w_model\n",
      "20/20 [==============================] - 1s 2ms/step - loss: 0.5092 - mae: 1.3071 - acc: 0.8091\n",
      "pamap_w_model\n",
      "Serving Accuracy\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 1.0568 - mae: 1.3098 - acc: 0.6275\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  612 Test size:  2451\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4739 - mae: 1.3098 - acc: 0.8009\n",
      "Already present model-> pamap_w_model\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5092 - mae: 1.3071 - acc: 0.8091\n",
      "pamap_w_model\n",
      "Serving Accuracy\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.9839 - mae: 1.3098 - acc: 0.6222\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  612 Test size:  2451\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7005 - mae: 1.3098 - acc: 0.6883\n",
      "Training new model-> pamap_c_model\n",
      "Source Domain NN Accuracy\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2567 - mae: 1.3071 - acc: 0.8989\n",
      "pamap_c_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.5475 - mae: 1.3799 - acc: 0.2520\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.8195 - mae: 1.3799 - acc: 0.5898\n",
      "Already present model-> pamap_c_model\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2567 - mae: 1.3071 - acc: 0.8989\n",
      "pamap_c_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1804 - mae: 1.3799 - acc: 0.2585\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6716 - mae: 1.3799 - acc: 0.6966\n",
      "Already present model-> pamap_c_model\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2567 - mae: 1.3071 - acc: 0.8989\n",
      "pamap_c_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8905 - mae: 1.3799 - acc: 0.3516\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6637 - mae: 1.3799 - acc: 0.7103\n",
      "Already present model-> pamap_c_model\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2567 - mae: 1.3071 - acc: 0.8989\n",
      "pamap_c_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.5638 - mae: 1.3799 - acc: 0.2520\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.7414 - mae: 1.3799 - acc: 0.6569\n",
      "Already present model-> pamap_c_model\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2567 - mae: 1.3071 - acc: 0.8989\n",
      "pamap_c_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.3485 - mae: 1.3799 - acc: 0.2520\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.7232 - mae: 1.3799 - acc: 0.6426\n",
      "Already present model-> pamap_c_model\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2567 - mae: 1.3071 - acc: 0.8989\n",
      "pamap_c_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 2.0033 - mae: 1.4795 - acc: 0.3965\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.3309 - mae: 1.4795 - acc: 0.8863\n",
      "Already present model-> pamap_c_model\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2567 - mae: 1.3071 - acc: 0.8989\n",
      "pamap_c_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 2.9326 - mae: 1.4795 - acc: 0.1456\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.4229 - mae: 1.4795 - acc: 0.8457\n",
      "Already present model-> pamap_c_model\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2567 - mae: 1.3071 - acc: 0.8989\n",
      "pamap_c_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 3.0867 - mae: 1.4795 - acc: 0.2190\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.5436 - mae: 1.4795 - acc: 0.7932\n",
      "Already present model-> pamap_c_model\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2567 - mae: 1.3071 - acc: 0.8989\n",
      "pamap_c_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 2.7938 - mae: 1.4795 - acc: 0.2666\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.4423 - mae: 1.4795 - acc: 0.8305\n",
      "Already present model-> pamap_c_model\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2567 - mae: 1.3071 - acc: 0.8989\n",
      "pamap_c_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 3.0529 - mae: 1.4795 - acc: 0.2195\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.5099 - mae: 1.4795 - acc: 0.8019\n",
      "Already present model-> pamap_c_model\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2567 - mae: 1.3071 - acc: 0.8989\n",
      "pamap_c_model\n",
      "Serving Accuracy\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 1.4550 - mae: 1.3098 - acc: 0.5308\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  612 Test size:  2451\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6888 - mae: 1.3098 - acc: 0.7344\n",
      "Already present model-> pamap_c_model\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2567 - mae: 1.3071 - acc: 0.8989\n",
      "pamap_c_model\n",
      "Serving Accuracy\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 1.1748 - mae: 1.3098 - acc: 0.5590\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  612 Test size:  2451\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6960 - mae: 1.3098 - acc: 0.6777\n",
      "Training new model-> pamap_a_model\n",
      "Source Domain NN Accuracy\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6279 - mae: 1.3071 - acc: 0.7227\n",
      "pamap_a_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.5536 - mae: 1.3799 - acc: 0.2826\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.8124 - mae: 1.3799 - acc: 0.5749\n",
      "Already present model-> pamap_a_model\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6279 - mae: 1.3071 - acc: 0.7227\n",
      "pamap_a_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.4927 - mae: 1.3799 - acc: 0.2441\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6692 - mae: 1.3799 - acc: 0.7018\n",
      "Already present model-> pamap_a_model\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6279 - mae: 1.3071 - acc: 0.7227\n",
      "pamap_a_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2898 - mae: 1.3799 - acc: 0.2461\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.6617 - mae: 1.3799 - acc: 0.7168\n",
      "Already present model-> pamap_a_model\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6279 - mae: 1.3071 - acc: 0.7227\n",
      "pamap_a_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.8593 - mae: 1.3799 - acc: 0.2246\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.7298 - mae: 1.3799 - acc: 0.6491\n",
      "Already present model-> pamap_a_model\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6279 - mae: 1.3071 - acc: 0.7227\n",
      "pamap_a_model\n",
      "Serving Accuracy\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7643 - mae: 1.3799 - acc: 0.2311\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  384 Test size:  1536\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.7347 - mae: 1.3799 - acc: 0.6296\n",
      "Already present model-> pamap_a_model\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6279 - mae: 1.3071 - acc: 0.7227\n",
      "pamap_a_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 2.4108 - mae: 1.4795 - acc: 0.3221\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.3388 - mae: 1.4795 - acc: 0.8880\n",
      "Already present model-> pamap_a_model\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6279 - mae: 1.3071 - acc: 0.7227\n",
      "pamap_a_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 2.3999 - mae: 1.4795 - acc: 0.2917\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.4450 - mae: 1.4795 - acc: 0.8325\n",
      "Already present model-> pamap_a_model\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6279 - mae: 1.3071 - acc: 0.7227\n",
      "pamap_a_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 2.6262 - mae: 1.4795 - acc: 0.2708\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.5667 - mae: 1.4795 - acc: 0.7768\n",
      "Already present model-> pamap_a_model\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6279 - mae: 1.3071 - acc: 0.7227\n",
      "pamap_a_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 2.3444 - mae: 1.4795 - acc: 0.2797\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.4500 - mae: 1.4795 - acc: 0.8243\n",
      "Already present model-> pamap_a_model\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6279 - mae: 1.3071 - acc: 0.7227\n",
      "pamap_a_model\n",
      "Serving Accuracy\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 2.6374 - mae: 1.4795 - acc: 0.2374\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  1004 Test size:  4018\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.5502 - mae: 1.4795 - acc: 0.7705\n",
      "Already present model-> pamap_a_model\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6279 - mae: 1.3071 - acc: 0.7227\n",
      "pamap_a_model\n",
      "Serving Accuracy\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 1.0215 - mae: 1.3098 - acc: 0.4774\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  612 Test size:  2451\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6887 - mae: 1.3098 - acc: 0.7295\n",
      "Already present model-> pamap_a_model\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6279 - mae: 1.3071 - acc: 0.7227\n",
      "pamap_a_model\n",
      "Serving Accuracy\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 1.5091 - mae: 1.3098 - acc: 0.3725\n",
      "Fine-tunned model trained with tar domain size  0.19999999999999996 Train size:  612 Test size:  2451\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4564 - mae: 1.3098 - acc: 0.8140\n"
     ]
    }
   ],
   "source": [
    "# Figure exhaust combination of AR to compute JSD\n",
    "\n",
    "src = []\n",
    "tar = []\n",
    "jsd = []\n",
    "l2d = []\n",
    "adp = []\n",
    "\n",
    "source = [] \n",
    "serving = []\n",
    "finetune = []\n",
    "\n",
    "for comb in tqdm(permutations, leave=False):\n",
    "    # Retrieve Data\n",
    "    data1 = ar_data[comb[0]]\n",
    "    data1_label = ar_data[look_up_labels(comb[0])]\n",
    "    data2 = ar_data[comb[1]]\n",
    "    data2_label = ar_data[look_up_labels(comb[1])]\n",
    "    \n",
    "    # Calculate JSD\n",
    "    prob1 = utils.data_to_probability(data1, bins=100)\n",
    "    prob2 = utils.data_to_probability(data2, bins=100)\n",
    "\n",
    "    # Calculate L2D\n",
    "    center1 = utils.data_to_center(data1)\n",
    "    center2 = utils.data_to_center(data2)\n",
    "    \n",
    "    src.append(comb[0])\n",
    "    tar.append(comb[1])\n",
    "    jsd.append(utils.jensen_shannon_divergence(prob1, prob2))\n",
    "    adp.append(utils.adaptivity(data1, data2, threshold=0.3))\n",
    "    l2d.append(utils.l2_distance(center1, center2))\n",
    "\n",
    "    accs = nn_finetune(comb[0],data1, data1_label, data2, data2_label,src_t_size=0.2, tar_t_size=0.8, verbose=0)\n",
    "    source.append(accs[0][2])    \n",
    "    serving.append(accs[1][2])\n",
    "    finetune.append(accs[2][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72560b1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T19:01:26.861254Z",
     "iopub.status.busy": "2022-04-12T19:01:26.860474Z",
     "iopub.status.idle": "2022-04-12T19:01:26.863475Z",
     "shell.execute_reply": "2022-04-12T19:01:26.862997Z"
    },
    "id": "Kse2rIxH_yvg",
    "papermill": {
     "duration": 0.705871,
     "end_time": "2022-04-12T19:01:26.863594",
     "exception": false,
     "start_time": "2022-04-12T19:01:26.157723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame({'Source': src, 'Target': tar, 'l2d': l2d, 'jsd': jsd, 'Adaptivity':adp, 'Source Accuracy': source, 'serving': serving, 'finetune': finetune})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da9a104d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T19:01:28.550530Z",
     "iopub.status.busy": "2022-04-12T19:01:28.549662Z",
     "iopub.status.idle": "2022-04-12T19:01:28.565586Z",
     "shell.execute_reply": "2022-04-12T19:01:28.566015Z"
    },
    "papermill": {
     "duration": 0.986809,
     "end_time": "2022-04-12T19:01:28.566153",
     "exception": false,
     "start_time": "2022-04-12T19:01:27.579344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>l2d</th>\n",
       "      <th>jsd</th>\n",
       "      <th>Adaptivity</th>\n",
       "      <th>Source Accuracy</th>\n",
       "      <th>serving</th>\n",
       "      <th>finetune</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dsads_t</td>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.017977</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.571615</td>\n",
       "      <td>0.705729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dsads_t</td>\n",
       "      <td>dsads_la</td>\n",
       "      <td>0.778643</td>\n",
       "      <td>0.021905</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.720703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dsads_t</td>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>0.479365</td>\n",
       "      <td>0.019388</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.590495</td>\n",
       "      <td>0.648438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dsads_t</td>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>0.509558</td>\n",
       "      <td>0.014866</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.589844</td>\n",
       "      <td>0.632812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dsads_t</td>\n",
       "      <td>oppo_b</td>\n",
       "      <td>1.699683</td>\n",
       "      <td>0.087178</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.341961</td>\n",
       "      <td>0.882778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>pamap_a</td>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>1.097437</td>\n",
       "      <td>0.062846</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.722675</td>\n",
       "      <td>0.270781</td>\n",
       "      <td>0.776755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>pamap_a</td>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>1.187925</td>\n",
       "      <td>0.056171</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.722675</td>\n",
       "      <td>0.279741</td>\n",
       "      <td>0.824291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>pamap_a</td>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>1.002996</td>\n",
       "      <td>0.062375</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.722675</td>\n",
       "      <td>0.237432</td>\n",
       "      <td>0.770533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>pamap_a</td>\n",
       "      <td>pamap_w</td>\n",
       "      <td>0.743870</td>\n",
       "      <td>0.014660</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.722675</td>\n",
       "      <td>0.477356</td>\n",
       "      <td>0.729498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>pamap_a</td>\n",
       "      <td>pamap_c</td>\n",
       "      <td>0.646948</td>\n",
       "      <td>0.019264</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.722675</td>\n",
       "      <td>0.372501</td>\n",
       "      <td>0.813953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Source    Target       l2d       jsd  Adaptivity  Source Accuracy  \\\n",
       "0    dsads_t  dsads_ra  0.505051  0.017977         4.0         0.609375   \n",
       "1    dsads_t  dsads_la  0.778643  0.021905         4.0         0.609375   \n",
       "2    dsads_t  dsads_rl  0.479365  0.019388         4.0         0.609375   \n",
       "3    dsads_t  dsads_ll  0.509558  0.014866         4.0         0.609375   \n",
       "4    dsads_t    oppo_b  1.699683  0.087178         4.0         0.609375   \n",
       "..       ...       ...       ...       ...         ...              ...   \n",
       "151  pamap_a  oppo_rla  1.097437  0.062846         7.0         0.722675   \n",
       "152  pamap_a  oppo_lua  1.187925  0.056171         7.0         0.722675   \n",
       "153  pamap_a  oppo_lla  1.002996  0.062375         7.0         0.722675   \n",
       "154  pamap_a   pamap_w  0.743870  0.014660         7.0         0.722675   \n",
       "155  pamap_a   pamap_c  0.646948  0.019264         7.0         0.722675   \n",
       "\n",
       "      serving  finetune  \n",
       "0    0.571615  0.705729  \n",
       "1    0.604167  0.720703  \n",
       "2    0.590495  0.648438  \n",
       "3    0.589844  0.632812  \n",
       "4    0.341961  0.882778  \n",
       "..        ...       ...  \n",
       "151  0.270781  0.776755  \n",
       "152  0.279741  0.824291  \n",
       "153  0.237432  0.770533  \n",
       "154  0.477356  0.729498  \n",
       "155  0.372501  0.813953  \n",
       "\n",
       "[156 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76900c66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T19:01:30.064846Z",
     "iopub.status.busy": "2022-04-12T19:01:30.018306Z",
     "iopub.status.idle": "2022-04-12T19:01:30.077591Z",
     "shell.execute_reply": "2022-04-12T19:01:30.078011Z"
    },
    "id": "u3euxgCdAF4U",
    "outputId": "9236ba8d-3f18-40c5-dbef-889d24440bcb",
    "papermill": {
     "duration": 0.763789,
     "end_time": "2022-04-12T19:01:30.078154",
     "exception": false,
     "start_time": "2022-04-12T19:01:29.314365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>l2d</th>\n",
       "      <th>jsd</th>\n",
       "      <th>Adaptivity</th>\n",
       "      <th>Source Accuracy</th>\n",
       "      <th>serving</th>\n",
       "      <th>finetune</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>pamap_c</td>\n",
       "      <td>pamap_w</td>\n",
       "      <td>0.622451</td>\n",
       "      <td>0.005972</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.898858</td>\n",
       "      <td>0.530804</td>\n",
       "      <td>0.734394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>pamap_a</td>\n",
       "      <td>pamap_w</td>\n",
       "      <td>0.743870</td>\n",
       "      <td>0.014660</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.722675</td>\n",
       "      <td>0.477356</td>\n",
       "      <td>0.729498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>pamap_w</td>\n",
       "      <td>1.729038</td>\n",
       "      <td>0.044448</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.337005</td>\n",
       "      <td>0.649939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>pamap_w</td>\n",
       "      <td>1.791822</td>\n",
       "      <td>0.048892</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.643229</td>\n",
       "      <td>0.241126</td>\n",
       "      <td>0.714810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dsads_t</td>\n",
       "      <td>pamap_w</td>\n",
       "      <td>1.713112</td>\n",
       "      <td>0.041491</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.238678</td>\n",
       "      <td>0.692370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>pamap_w</td>\n",
       "      <td>1.578720</td>\n",
       "      <td>0.032859</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.747396</td>\n",
       "      <td>0.234598</td>\n",
       "      <td>0.692370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>oppo_b</td>\n",
       "      <td>pamap_w</td>\n",
       "      <td>1.384871</td>\n",
       "      <td>0.041871</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.234598</td>\n",
       "      <td>0.760914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>pamap_w</td>\n",
       "      <td>1.251849</td>\n",
       "      <td>0.052333</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.897512</td>\n",
       "      <td>0.234598</td>\n",
       "      <td>0.753978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>pamap_w</td>\n",
       "      <td>1.277806</td>\n",
       "      <td>0.051026</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.884577</td>\n",
       "      <td>0.234598</td>\n",
       "      <td>0.752754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>pamap_w</td>\n",
       "      <td>1.100290</td>\n",
       "      <td>0.049828</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.832836</td>\n",
       "      <td>0.159935</td>\n",
       "      <td>0.738474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>pamap_w</td>\n",
       "      <td>1.185198</td>\n",
       "      <td>0.055354</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.841791</td>\n",
       "      <td>0.125255</td>\n",
       "      <td>0.749898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>dsads_la</td>\n",
       "      <td>pamap_w</td>\n",
       "      <td>1.464021</td>\n",
       "      <td>0.030521</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.037944</td>\n",
       "      <td>0.667483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>pamap_w</td>\n",
       "      <td>pamap_c</td>\n",
       "      <td>0.622451</td>\n",
       "      <td>0.005972</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.809135</td>\n",
       "      <td>0.627499</td>\n",
       "      <td>0.800898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>pamap_a</td>\n",
       "      <td>pamap_c</td>\n",
       "      <td>0.646948</td>\n",
       "      <td>0.019264</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.722675</td>\n",
       "      <td>0.372501</td>\n",
       "      <td>0.813953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>pamap_c</td>\n",
       "      <td>1.429557</td>\n",
       "      <td>0.045948</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.297022</td>\n",
       "      <td>0.793554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>pamap_c</td>\n",
       "      <td>1.489314</td>\n",
       "      <td>0.052656</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.643229</td>\n",
       "      <td>0.241126</td>\n",
       "      <td>0.784986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dsads_t</td>\n",
       "      <td>pamap_c</td>\n",
       "      <td>1.351234</td>\n",
       "      <td>0.037984</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.238678</td>\n",
       "      <td>0.776418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>pamap_c</td>\n",
       "      <td>1.270784</td>\n",
       "      <td>0.037071</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.747396</td>\n",
       "      <td>0.234598</td>\n",
       "      <td>0.792330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>pamap_c</td>\n",
       "      <td>1.242194</td>\n",
       "      <td>0.052731</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.897512</td>\n",
       "      <td>0.197878</td>\n",
       "      <td>0.874337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>oppo_b</td>\n",
       "      <td>pamap_c</td>\n",
       "      <td>1.323274</td>\n",
       "      <td>0.040178</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.128111</td>\n",
       "      <td>0.873929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>pamap_c</td>\n",
       "      <td>1.117596</td>\n",
       "      <td>0.047397</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.832836</td>\n",
       "      <td>0.121175</td>\n",
       "      <td>0.806610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>pamap_c</td>\n",
       "      <td>1.252205</td>\n",
       "      <td>0.057905</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.841791</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.862913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>pamap_c</td>\n",
       "      <td>1.273298</td>\n",
       "      <td>0.051980</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.884577</td>\n",
       "      <td>0.060792</td>\n",
       "      <td>0.847001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>dsads_la</td>\n",
       "      <td>pamap_c</td>\n",
       "      <td>1.233911</td>\n",
       "      <td>0.033504</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.022440</td>\n",
       "      <td>0.783762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>pamap_w</td>\n",
       "      <td>pamap_a</td>\n",
       "      <td>0.743870</td>\n",
       "      <td>0.014660</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.809135</td>\n",
       "      <td>0.622195</td>\n",
       "      <td>0.688290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>pamap_c</td>\n",
       "      <td>pamap_a</td>\n",
       "      <td>0.646948</td>\n",
       "      <td>0.019264</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.898858</td>\n",
       "      <td>0.558956</td>\n",
       "      <td>0.677683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>pamap_a</td>\n",
       "      <td>1.366061</td>\n",
       "      <td>0.033579</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.404733</td>\n",
       "      <td>0.661771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dsads_t</td>\n",
       "      <td>pamap_a</td>\n",
       "      <td>1.403282</td>\n",
       "      <td>0.036236</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.277438</td>\n",
       "      <td>0.631171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>oppo_b</td>\n",
       "      <td>pamap_a</td>\n",
       "      <td>1.226980</td>\n",
       "      <td>0.040490</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.252958</td>\n",
       "      <td>0.671563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>pamap_a</td>\n",
       "      <td>1.187925</td>\n",
       "      <td>0.056171</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.884577</td>\n",
       "      <td>0.251734</td>\n",
       "      <td>0.678091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>pamap_a</td>\n",
       "      <td>1.427837</td>\n",
       "      <td>0.038547</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.643229</td>\n",
       "      <td>0.247246</td>\n",
       "      <td>0.679315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>pamap_a</td>\n",
       "      <td>1.151606</td>\n",
       "      <td>0.059286</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.897512</td>\n",
       "      <td>0.242350</td>\n",
       "      <td>0.699306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>pamap_a</td>\n",
       "      <td>1.279896</td>\n",
       "      <td>0.028512</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.747396</td>\n",
       "      <td>0.234598</td>\n",
       "      <td>0.641371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>pamap_a</td>\n",
       "      <td>1.002996</td>\n",
       "      <td>0.062375</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.832836</td>\n",
       "      <td>0.210934</td>\n",
       "      <td>0.679315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>pamap_a</td>\n",
       "      <td>1.097437</td>\n",
       "      <td>0.062846</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.841791</td>\n",
       "      <td>0.153407</td>\n",
       "      <td>0.669931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>dsads_la</td>\n",
       "      <td>pamap_a</td>\n",
       "      <td>1.213597</td>\n",
       "      <td>0.027482</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.029784</td>\n",
       "      <td>0.681763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>0.359323</td>\n",
       "      <td>0.001838</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.884577</td>\n",
       "      <td>0.827028</td>\n",
       "      <td>0.858636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>0.410786</td>\n",
       "      <td>0.003059</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.832836</td>\n",
       "      <td>0.730214</td>\n",
       "      <td>0.850174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>0.322763</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.841791</td>\n",
       "      <td>0.689895</td>\n",
       "      <td>0.858138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>oppo_b</td>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>0.703657</td>\n",
       "      <td>0.007503</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.567944</td>\n",
       "      <td>0.861374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>dsads_la</td>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>1.725070</td>\n",
       "      <td>0.089272</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.825535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>1.727428</td>\n",
       "      <td>0.093210</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.747396</td>\n",
       "      <td>0.487307</td>\n",
       "      <td>0.826531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>1.868353</td>\n",
       "      <td>0.100481</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.408412</td>\n",
       "      <td>0.806620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>1.859685</td>\n",
       "      <td>0.106835</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.643229</td>\n",
       "      <td>0.341215</td>\n",
       "      <td>0.774017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>pamap_w</td>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>1.251849</td>\n",
       "      <td>0.052333</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.809135</td>\n",
       "      <td>0.318815</td>\n",
       "      <td>0.848681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dsads_t</td>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>1.782091</td>\n",
       "      <td>0.107024</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.318566</td>\n",
       "      <td>0.824540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>pamap_a</td>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>1.151606</td>\n",
       "      <td>0.059286</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.722675</td>\n",
       "      <td>0.291687</td>\n",
       "      <td>0.832504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>pamap_c</td>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>1.242194</td>\n",
       "      <td>0.052731</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.898858</td>\n",
       "      <td>0.145595</td>\n",
       "      <td>0.845694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>0.322763</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.897512</td>\n",
       "      <td>0.669736</td>\n",
       "      <td>0.782230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>0.490672</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.884577</td>\n",
       "      <td>0.567695</td>\n",
       "      <td>0.793181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>0.458541</td>\n",
       "      <td>0.004374</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.832836</td>\n",
       "      <td>0.561473</td>\n",
       "      <td>0.791936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>oppo_b</td>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>0.819508</td>\n",
       "      <td>0.009806</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.496516</td>\n",
       "      <td>0.776257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>1.766390</td>\n",
       "      <td>0.097714</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.747396</td>\n",
       "      <td>0.487307</td>\n",
       "      <td>0.764560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>dsads_la</td>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>1.745335</td>\n",
       "      <td>0.093644</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.464161</td>\n",
       "      <td>0.729965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>1.901222</td>\n",
       "      <td>0.105857</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.443753</td>\n",
       "      <td>0.753858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>1.890939</td>\n",
       "      <td>0.111826</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.643229</td>\n",
       "      <td>0.346192</td>\n",
       "      <td>0.779492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dsads_t</td>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>1.843148</td>\n",
       "      <td>0.116170</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.308113</td>\n",
       "      <td>0.763564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>pamap_w</td>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>1.185198</td>\n",
       "      <td>0.055354</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.809135</td>\n",
       "      <td>0.302389</td>\n",
       "      <td>0.718019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>pamap_a</td>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>1.097437</td>\n",
       "      <td>0.062846</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.722675</td>\n",
       "      <td>0.270781</td>\n",
       "      <td>0.776755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>pamap_c</td>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>1.252205</td>\n",
       "      <td>0.057905</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.898858</td>\n",
       "      <td>0.219014</td>\n",
       "      <td>0.793181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>0.359323</td>\n",
       "      <td>0.001838</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.897512</td>\n",
       "      <td>0.814335</td>\n",
       "      <td>0.850423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>0.408083</td>\n",
       "      <td>0.004326</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.832836</td>\n",
       "      <td>0.788701</td>\n",
       "      <td>0.836984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>oppo_b</td>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>0.503649</td>\n",
       "      <td>0.005801</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.652563</td>\n",
       "      <td>0.823295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>0.490672</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.841791</td>\n",
       "      <td>0.612743</td>\n",
       "      <td>0.851419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>dsads_la</td>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>1.708458</td>\n",
       "      <td>0.086910</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.517173</td>\n",
       "      <td>0.831010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>1.733388</td>\n",
       "      <td>0.091065</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.747396</td>\n",
       "      <td>0.500249</td>\n",
       "      <td>0.791936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>1.880057</td>\n",
       "      <td>0.098857</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.412145</td>\n",
       "      <td>0.847437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>1.880956</td>\n",
       "      <td>0.104589</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.643229</td>\n",
       "      <td>0.350174</td>\n",
       "      <td>0.827028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dsads_t</td>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>1.798233</td>\n",
       "      <td>0.108311</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.329766</td>\n",
       "      <td>0.808860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>pamap_w</td>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>1.277806</td>\n",
       "      <td>0.051026</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.809135</td>\n",
       "      <td>0.316575</td>\n",
       "      <td>0.849925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>pamap_a</td>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>1.187925</td>\n",
       "      <td>0.056171</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.722675</td>\n",
       "      <td>0.279741</td>\n",
       "      <td>0.824291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>pamap_c</td>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>1.273298</td>\n",
       "      <td>0.051980</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.898858</td>\n",
       "      <td>0.266551</td>\n",
       "      <td>0.830513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>0.408083</td>\n",
       "      <td>0.004326</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.884577</td>\n",
       "      <td>0.733201</td>\n",
       "      <td>0.812842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>0.410786</td>\n",
       "      <td>0.003059</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.897512</td>\n",
       "      <td>0.683425</td>\n",
       "      <td>0.806620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>0.458541</td>\n",
       "      <td>0.004374</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.841791</td>\n",
       "      <td>0.655301</td>\n",
       "      <td>0.811598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>oppo_b</td>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>0.712610</td>\n",
       "      <td>0.010136</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.530363</td>\n",
       "      <td>0.790692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>dsads_la</td>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>1.572520</td>\n",
       "      <td>0.085790</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.499502</td>\n",
       "      <td>0.778995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>1.615822</td>\n",
       "      <td>0.090679</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.747396</td>\n",
       "      <td>0.496267</td>\n",
       "      <td>0.782230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>1.777116</td>\n",
       "      <td>0.099175</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.475859</td>\n",
       "      <td>0.760329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>1.774472</td>\n",
       "      <td>0.106481</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.643229</td>\n",
       "      <td>0.338228</td>\n",
       "      <td>0.785217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dsads_t</td>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>1.704680</td>\n",
       "      <td>0.104460</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.328273</td>\n",
       "      <td>0.772026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>pamap_w</td>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>1.100290</td>\n",
       "      <td>0.049828</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.809135</td>\n",
       "      <td>0.298656</td>\n",
       "      <td>0.789199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>pamap_a</td>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>1.002996</td>\n",
       "      <td>0.062375</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.722675</td>\n",
       "      <td>0.237432</td>\n",
       "      <td>0.770533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>pamap_c</td>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>1.117596</td>\n",
       "      <td>0.047397</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.898858</td>\n",
       "      <td>0.219512</td>\n",
       "      <td>0.801892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>oppo_b</td>\n",
       "      <td>0.503649</td>\n",
       "      <td>0.005801</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.884577</td>\n",
       "      <td>0.791439</td>\n",
       "      <td>0.896217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>oppo_b</td>\n",
       "      <td>0.712610</td>\n",
       "      <td>0.010136</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.832836</td>\n",
       "      <td>0.678447</td>\n",
       "      <td>0.877551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>oppo_b</td>\n",
       "      <td>0.703657</td>\n",
       "      <td>0.007503</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.897512</td>\n",
       "      <td>0.660528</td>\n",
       "      <td>0.901692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>oppo_b</td>\n",
       "      <td>0.819508</td>\n",
       "      <td>0.009806</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.841791</td>\n",
       "      <td>0.570433</td>\n",
       "      <td>0.894973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>oppo_b</td>\n",
       "      <td>1.670562</td>\n",
       "      <td>0.076164</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.747396</td>\n",
       "      <td>0.509706</td>\n",
       "      <td>0.874564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>dsads_la</td>\n",
       "      <td>oppo_b</td>\n",
       "      <td>1.671462</td>\n",
       "      <td>0.073346</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.488303</td>\n",
       "      <td>0.882031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>oppo_b</td>\n",
       "      <td>1.779333</td>\n",
       "      <td>0.087971</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.643229</td>\n",
       "      <td>0.428323</td>\n",
       "      <td>0.885266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>oppo_b</td>\n",
       "      <td>1.760782</td>\n",
       "      <td>0.082694</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.409905</td>\n",
       "      <td>0.886013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>pamap_c</td>\n",
       "      <td>oppo_b</td>\n",
       "      <td>1.323274</td>\n",
       "      <td>0.040178</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.898858</td>\n",
       "      <td>0.396466</td>\n",
       "      <td>0.886262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dsads_t</td>\n",
       "      <td>oppo_b</td>\n",
       "      <td>1.699683</td>\n",
       "      <td>0.087178</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.341961</td>\n",
       "      <td>0.882778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>pamap_a</td>\n",
       "      <td>oppo_b</td>\n",
       "      <td>1.226980</td>\n",
       "      <td>0.040490</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.722675</td>\n",
       "      <td>0.322051</td>\n",
       "      <td>0.888004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>pamap_w</td>\n",
       "      <td>oppo_b</td>\n",
       "      <td>1.384871</td>\n",
       "      <td>0.041871</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.809135</td>\n",
       "      <td>0.318566</td>\n",
       "      <td>0.887506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>dsads_t</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.017977</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.747396</td>\n",
       "      <td>0.502604</td>\n",
       "      <td>0.564453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>dsads_la</td>\n",
       "      <td>dsads_t</td>\n",
       "      <td>0.778643</td>\n",
       "      <td>0.021905</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.498698</td>\n",
       "      <td>0.582682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>dsads_t</td>\n",
       "      <td>0.509558</td>\n",
       "      <td>0.014866</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.488932</td>\n",
       "      <td>0.570312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>dsads_t</td>\n",
       "      <td>1.798233</td>\n",
       "      <td>0.108311</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.884577</td>\n",
       "      <td>0.470703</td>\n",
       "      <td>0.588542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>dsads_t</td>\n",
       "      <td>1.704680</td>\n",
       "      <td>0.104460</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.832836</td>\n",
       "      <td>0.401042</td>\n",
       "      <td>0.575521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>dsads_t</td>\n",
       "      <td>0.479365</td>\n",
       "      <td>0.019388</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.643229</td>\n",
       "      <td>0.342448</td>\n",
       "      <td>0.580729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>dsads_t</td>\n",
       "      <td>1.782091</td>\n",
       "      <td>0.107024</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.897512</td>\n",
       "      <td>0.317057</td>\n",
       "      <td>0.574870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>pamap_a</td>\n",
       "      <td>dsads_t</td>\n",
       "      <td>1.403282</td>\n",
       "      <td>0.036236</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.722675</td>\n",
       "      <td>0.282552</td>\n",
       "      <td>0.574870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>dsads_t</td>\n",
       "      <td>1.843148</td>\n",
       "      <td>0.116170</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.841791</td>\n",
       "      <td>0.276693</td>\n",
       "      <td>0.571615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>oppo_b</td>\n",
       "      <td>dsads_t</td>\n",
       "      <td>1.699683</td>\n",
       "      <td>0.087178</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.259115</td>\n",
       "      <td>0.557943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>pamap_w</td>\n",
       "      <td>dsads_t</td>\n",
       "      <td>1.713112</td>\n",
       "      <td>0.041491</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.809135</td>\n",
       "      <td>0.251953</td>\n",
       "      <td>0.608073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>pamap_c</td>\n",
       "      <td>dsads_t</td>\n",
       "      <td>1.351234</td>\n",
       "      <td>0.037984</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.898858</td>\n",
       "      <td>0.251953</td>\n",
       "      <td>0.589844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>0.336949</td>\n",
       "      <td>0.005562</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.662760</td>\n",
       "      <td>0.683594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dsads_t</td>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>0.479365</td>\n",
       "      <td>0.019388</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.590495</td>\n",
       "      <td>0.648438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>dsads_la</td>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>0.850386</td>\n",
       "      <td>0.016635</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.513021</td>\n",
       "      <td>0.655599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>0.593826</td>\n",
       "      <td>0.012356</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.747396</td>\n",
       "      <td>0.496745</td>\n",
       "      <td>0.678385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>1.880956</td>\n",
       "      <td>0.104589</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.884577</td>\n",
       "      <td>0.470052</td>\n",
       "      <td>0.649089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>1.774472</td>\n",
       "      <td>0.106481</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.832836</td>\n",
       "      <td>0.378906</td>\n",
       "      <td>0.641927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>1.859685</td>\n",
       "      <td>0.106835</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.897512</td>\n",
       "      <td>0.347005</td>\n",
       "      <td>0.671224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>oppo_b</td>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>1.779333</td>\n",
       "      <td>0.087971</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.336589</td>\n",
       "      <td>0.658854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>1.890939</td>\n",
       "      <td>0.111826</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.841791</td>\n",
       "      <td>0.269531</td>\n",
       "      <td>0.649740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>pamap_w</td>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>1.791822</td>\n",
       "      <td>0.048892</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.809135</td>\n",
       "      <td>0.251953</td>\n",
       "      <td>0.647135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>pamap_c</td>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>1.489314</td>\n",
       "      <td>0.052656</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.898858</td>\n",
       "      <td>0.251953</td>\n",
       "      <td>0.656901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>pamap_a</td>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>1.427837</td>\n",
       "      <td>0.038547</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.722675</td>\n",
       "      <td>0.224609</td>\n",
       "      <td>0.649089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>dsads_la</td>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>0.396833</td>\n",
       "      <td>0.008943</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.711589</td>\n",
       "      <td>0.697917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dsads_t</td>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.017977</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.571615</td>\n",
       "      <td>0.705729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>1.733388</td>\n",
       "      <td>0.091065</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.884577</td>\n",
       "      <td>0.558594</td>\n",
       "      <td>0.711589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>0.462330</td>\n",
       "      <td>0.011396</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.511068</td>\n",
       "      <td>0.708984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>0.593826</td>\n",
       "      <td>0.012356</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.643229</td>\n",
       "      <td>0.509766</td>\n",
       "      <td>0.699219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>1.615822</td>\n",
       "      <td>0.090679</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.832836</td>\n",
       "      <td>0.466146</td>\n",
       "      <td>0.714844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>1.727428</td>\n",
       "      <td>0.093210</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.897512</td>\n",
       "      <td>0.401042</td>\n",
       "      <td>0.714844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>1.766390</td>\n",
       "      <td>0.097714</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.841791</td>\n",
       "      <td>0.376953</td>\n",
       "      <td>0.712240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>oppo_b</td>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>1.670562</td>\n",
       "      <td>0.076164</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.306641</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>pamap_c</td>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>1.270784</td>\n",
       "      <td>0.037071</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.898858</td>\n",
       "      <td>0.258464</td>\n",
       "      <td>0.696615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>pamap_w</td>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>1.578720</td>\n",
       "      <td>0.032859</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.809135</td>\n",
       "      <td>0.252604</td>\n",
       "      <td>0.710938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>pamap_a</td>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>1.279896</td>\n",
       "      <td>0.028512</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.722675</td>\n",
       "      <td>0.244141</td>\n",
       "      <td>0.701823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>0.336949</td>\n",
       "      <td>0.005562</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.643229</td>\n",
       "      <td>0.671224</td>\n",
       "      <td>0.663411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dsads_t</td>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>0.509558</td>\n",
       "      <td>0.014866</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.589844</td>\n",
       "      <td>0.632812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>dsads_la</td>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>0.708819</td>\n",
       "      <td>0.014258</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.544271</td>\n",
       "      <td>0.650391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>0.462330</td>\n",
       "      <td>0.011396</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.747396</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.641927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>1.880057</td>\n",
       "      <td>0.098857</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.884577</td>\n",
       "      <td>0.493490</td>\n",
       "      <td>0.672526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>1.777116</td>\n",
       "      <td>0.099175</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.832836</td>\n",
       "      <td>0.447917</td>\n",
       "      <td>0.651042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>1.868353</td>\n",
       "      <td>0.100481</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.897512</td>\n",
       "      <td>0.381510</td>\n",
       "      <td>0.669922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>oppo_b</td>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>1.760782</td>\n",
       "      <td>0.082694</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.294922</td>\n",
       "      <td>0.636068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>1.901222</td>\n",
       "      <td>0.105857</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.841791</td>\n",
       "      <td>0.276693</td>\n",
       "      <td>0.662109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>pamap_w</td>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>1.729038</td>\n",
       "      <td>0.044448</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.809135</td>\n",
       "      <td>0.251953</td>\n",
       "      <td>0.653646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>pamap_c</td>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>1.429557</td>\n",
       "      <td>0.045948</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.898858</td>\n",
       "      <td>0.251953</td>\n",
       "      <td>0.642578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>pamap_a</td>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>1.366061</td>\n",
       "      <td>0.033579</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.722675</td>\n",
       "      <td>0.231120</td>\n",
       "      <td>0.629557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>dsads_la</td>\n",
       "      <td>0.396833</td>\n",
       "      <td>0.008943</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.747396</td>\n",
       "      <td>0.681641</td>\n",
       "      <td>0.732422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dsads_t</td>\n",
       "      <td>dsads_la</td>\n",
       "      <td>0.778643</td>\n",
       "      <td>0.021905</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.720703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>dsads_la</td>\n",
       "      <td>1.708458</td>\n",
       "      <td>0.086910</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.884577</td>\n",
       "      <td>0.573568</td>\n",
       "      <td>0.727214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>dsads_la</td>\n",
       "      <td>0.708819</td>\n",
       "      <td>0.014258</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.539062</td>\n",
       "      <td>0.709635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>dsads_la</td>\n",
       "      <td>0.850386</td>\n",
       "      <td>0.016635</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.643229</td>\n",
       "      <td>0.518229</td>\n",
       "      <td>0.706380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>dsads_la</td>\n",
       "      <td>1.572520</td>\n",
       "      <td>0.085790</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.832836</td>\n",
       "      <td>0.486328</td>\n",
       "      <td>0.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>dsads_la</td>\n",
       "      <td>1.745335</td>\n",
       "      <td>0.093644</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.841791</td>\n",
       "      <td>0.404948</td>\n",
       "      <td>0.712891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>dsads_la</td>\n",
       "      <td>1.725070</td>\n",
       "      <td>0.089272</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.897512</td>\n",
       "      <td>0.402344</td>\n",
       "      <td>0.716797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>oppo_b</td>\n",
       "      <td>dsads_la</td>\n",
       "      <td>1.671462</td>\n",
       "      <td>0.073346</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.366536</td>\n",
       "      <td>0.729167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>pamap_c</td>\n",
       "      <td>dsads_la</td>\n",
       "      <td>1.233911</td>\n",
       "      <td>0.033504</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.898858</td>\n",
       "      <td>0.351562</td>\n",
       "      <td>0.710286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>pamap_w</td>\n",
       "      <td>dsads_la</td>\n",
       "      <td>1.464021</td>\n",
       "      <td>0.030521</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.809135</td>\n",
       "      <td>0.250651</td>\n",
       "      <td>0.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>pamap_a</td>\n",
       "      <td>dsads_la</td>\n",
       "      <td>1.213597</td>\n",
       "      <td>0.027482</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.722675</td>\n",
       "      <td>0.246094</td>\n",
       "      <td>0.716797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Source    Target       l2d       jsd  Adaptivity  Source Accuracy  \\\n",
       "142   pamap_c   pamap_w  0.622451  0.005972         7.0         0.898858   \n",
       "154   pamap_a   pamap_w  0.743870  0.014660         7.0         0.722675   \n",
       "57   dsads_ll   pamap_w  1.729038  0.044448         4.0         0.697917   \n",
       "45   dsads_rl   pamap_w  1.791822  0.048892         4.0         0.643229   \n",
       "9     dsads_t   pamap_w  1.713112  0.041491         4.0         0.609375   \n",
       "21   dsads_ra   pamap_w  1.578720  0.032859         4.0         0.747396   \n",
       "69     oppo_b   pamap_w  1.384871  0.041871        11.0         0.910448   \n",
       "81   oppo_rua   pamap_w  1.251849  0.052333        11.0         0.897512   \n",
       "105  oppo_lua   pamap_w  1.277806  0.051026        11.0         0.884577   \n",
       "117  oppo_lla   pamap_w  1.100290  0.049828        11.0         0.832836   \n",
       "93   oppo_rla   pamap_w  1.185198  0.055354        11.0         0.841791   \n",
       "33   dsads_la   pamap_w  1.464021  0.030521         4.0         0.718750   \n",
       "130   pamap_w   pamap_c  0.622451  0.005972         7.0         0.809135   \n",
       "155   pamap_a   pamap_c  0.646948  0.019264         7.0         0.722675   \n",
       "58   dsads_ll   pamap_c  1.429557  0.045948         4.0         0.697917   \n",
       "46   dsads_rl   pamap_c  1.489314  0.052656         4.0         0.643229   \n",
       "10    dsads_t   pamap_c  1.351234  0.037984         4.0         0.609375   \n",
       "22   dsads_ra   pamap_c  1.270784  0.037071         4.0         0.747396   \n",
       "82   oppo_rua   pamap_c  1.242194  0.052731        11.0         0.897512   \n",
       "70     oppo_b   pamap_c  1.323274  0.040178        11.0         0.910448   \n",
       "118  oppo_lla   pamap_c  1.117596  0.047397        11.0         0.832836   \n",
       "94   oppo_rla   pamap_c  1.252205  0.057905        11.0         0.841791   \n",
       "106  oppo_lua   pamap_c  1.273298  0.051980        11.0         0.884577   \n",
       "34   dsads_la   pamap_c  1.233911  0.033504         4.0         0.718750   \n",
       "131   pamap_w   pamap_a  0.743870  0.014660         7.0         0.809135   \n",
       "143   pamap_c   pamap_a  0.646948  0.019264         7.0         0.898858   \n",
       "59   dsads_ll   pamap_a  1.366061  0.033579         4.0         0.697917   \n",
       "11    dsads_t   pamap_a  1.403282  0.036236         4.0         0.609375   \n",
       "71     oppo_b   pamap_a  1.226980  0.040490        11.0         0.910448   \n",
       "107  oppo_lua   pamap_a  1.187925  0.056171        11.0         0.884577   \n",
       "47   dsads_rl   pamap_a  1.427837  0.038547         4.0         0.643229   \n",
       "83   oppo_rua   pamap_a  1.151606  0.059286        11.0         0.897512   \n",
       "23   dsads_ra   pamap_a  1.279896  0.028512         4.0         0.747396   \n",
       "119  oppo_lla   pamap_a  1.002996  0.062375        11.0         0.832836   \n",
       "95   oppo_rla   pamap_a  1.097437  0.062846        11.0         0.841791   \n",
       "35   dsads_la   pamap_a  1.213597  0.027482         4.0         0.718750   \n",
       "102  oppo_lua  oppo_rua  0.359323  0.001838        11.0         0.884577   \n",
       "114  oppo_lla  oppo_rua  0.410786  0.003059        11.0         0.832836   \n",
       "90   oppo_rla  oppo_rua  0.322763  0.001938        11.0         0.841791   \n",
       "65     oppo_b  oppo_rua  0.703657  0.007503        11.0         0.910448   \n",
       "29   dsads_la  oppo_rua  1.725070  0.089272         4.0         0.718750   \n",
       "17   dsads_ra  oppo_rua  1.727428  0.093210         4.0         0.747396   \n",
       "53   dsads_ll  oppo_rua  1.868353  0.100481         4.0         0.697917   \n",
       "41   dsads_rl  oppo_rua  1.859685  0.106835         4.0         0.643229   \n",
       "126   pamap_w  oppo_rua  1.251849  0.052333         7.0         0.809135   \n",
       "5     dsads_t  oppo_rua  1.782091  0.107024         4.0         0.609375   \n",
       "150   pamap_a  oppo_rua  1.151606  0.059286         7.0         0.722675   \n",
       "138   pamap_c  oppo_rua  1.242194  0.052731         7.0         0.898858   \n",
       "78   oppo_rua  oppo_rla  0.322763  0.001938        11.0         0.897512   \n",
       "103  oppo_lua  oppo_rla  0.490672  0.001744        11.0         0.884577   \n",
       "115  oppo_lla  oppo_rla  0.458541  0.004374        11.0         0.832836   \n",
       "66     oppo_b  oppo_rla  0.819508  0.009806        11.0         0.910448   \n",
       "18   dsads_ra  oppo_rla  1.766390  0.097714         4.0         0.747396   \n",
       "30   dsads_la  oppo_rla  1.745335  0.093644         4.0         0.718750   \n",
       "54   dsads_ll  oppo_rla  1.901222  0.105857         4.0         0.697917   \n",
       "42   dsads_rl  oppo_rla  1.890939  0.111826         4.0         0.643229   \n",
       "6     dsads_t  oppo_rla  1.843148  0.116170         4.0         0.609375   \n",
       "127   pamap_w  oppo_rla  1.185198  0.055354         7.0         0.809135   \n",
       "151   pamap_a  oppo_rla  1.097437  0.062846         7.0         0.722675   \n",
       "139   pamap_c  oppo_rla  1.252205  0.057905         7.0         0.898858   \n",
       "79   oppo_rua  oppo_lua  0.359323  0.001838        11.0         0.897512   \n",
       "116  oppo_lla  oppo_lua  0.408083  0.004326        11.0         0.832836   \n",
       "67     oppo_b  oppo_lua  0.503649  0.005801        11.0         0.910448   \n",
       "91   oppo_rla  oppo_lua  0.490672  0.001744        11.0         0.841791   \n",
       "31   dsads_la  oppo_lua  1.708458  0.086910         4.0         0.718750   \n",
       "19   dsads_ra  oppo_lua  1.733388  0.091065         4.0         0.747396   \n",
       "55   dsads_ll  oppo_lua  1.880057  0.098857         4.0         0.697917   \n",
       "43   dsads_rl  oppo_lua  1.880956  0.104589         4.0         0.643229   \n",
       "7     dsads_t  oppo_lua  1.798233  0.108311         4.0         0.609375   \n",
       "128   pamap_w  oppo_lua  1.277806  0.051026         7.0         0.809135   \n",
       "152   pamap_a  oppo_lua  1.187925  0.056171         7.0         0.722675   \n",
       "140   pamap_c  oppo_lua  1.273298  0.051980         7.0         0.898858   \n",
       "104  oppo_lua  oppo_lla  0.408083  0.004326        11.0         0.884577   \n",
       "80   oppo_rua  oppo_lla  0.410786  0.003059        11.0         0.897512   \n",
       "92   oppo_rla  oppo_lla  0.458541  0.004374        11.0         0.841791   \n",
       "68     oppo_b  oppo_lla  0.712610  0.010136        11.0         0.910448   \n",
       "32   dsads_la  oppo_lla  1.572520  0.085790         4.0         0.718750   \n",
       "20   dsads_ra  oppo_lla  1.615822  0.090679         4.0         0.747396   \n",
       "56   dsads_ll  oppo_lla  1.777116  0.099175         4.0         0.697917   \n",
       "44   dsads_rl  oppo_lla  1.774472  0.106481         4.0         0.643229   \n",
       "8     dsads_t  oppo_lla  1.704680  0.104460         4.0         0.609375   \n",
       "129   pamap_w  oppo_lla  1.100290  0.049828         7.0         0.809135   \n",
       "153   pamap_a  oppo_lla  1.002996  0.062375         7.0         0.722675   \n",
       "141   pamap_c  oppo_lla  1.117596  0.047397         7.0         0.898858   \n",
       "101  oppo_lua    oppo_b  0.503649  0.005801        11.0         0.884577   \n",
       "113  oppo_lla    oppo_b  0.712610  0.010136        11.0         0.832836   \n",
       "77   oppo_rua    oppo_b  0.703657  0.007503        11.0         0.897512   \n",
       "89   oppo_rla    oppo_b  0.819508  0.009806        11.0         0.841791   \n",
       "16   dsads_ra    oppo_b  1.670562  0.076164         4.0         0.747396   \n",
       "28   dsads_la    oppo_b  1.671462  0.073346         4.0         0.718750   \n",
       "40   dsads_rl    oppo_b  1.779333  0.087971         4.0         0.643229   \n",
       "52   dsads_ll    oppo_b  1.760782  0.082694         4.0         0.697917   \n",
       "137   pamap_c    oppo_b  1.323274  0.040178         7.0         0.898858   \n",
       "4     dsads_t    oppo_b  1.699683  0.087178         4.0         0.609375   \n",
       "149   pamap_a    oppo_b  1.226980  0.040490         7.0         0.722675   \n",
       "125   pamap_w    oppo_b  1.384871  0.041871         7.0         0.809135   \n",
       "12   dsads_ra   dsads_t  0.505051  0.017977         4.0         0.747396   \n",
       "24   dsads_la   dsads_t  0.778643  0.021905         4.0         0.718750   \n",
       "48   dsads_ll   dsads_t  0.509558  0.014866         4.0         0.697917   \n",
       "96   oppo_lua   dsads_t  1.798233  0.108311        11.0         0.884577   \n",
       "108  oppo_lla   dsads_t  1.704680  0.104460        11.0         0.832836   \n",
       "36   dsads_rl   dsads_t  0.479365  0.019388         4.0         0.643229   \n",
       "72   oppo_rua   dsads_t  1.782091  0.107024        11.0         0.897512   \n",
       "144   pamap_a   dsads_t  1.403282  0.036236         7.0         0.722675   \n",
       "84   oppo_rla   dsads_t  1.843148  0.116170        11.0         0.841791   \n",
       "60     oppo_b   dsads_t  1.699683  0.087178        11.0         0.910448   \n",
       "120   pamap_w   dsads_t  1.713112  0.041491         7.0         0.809135   \n",
       "132   pamap_c   dsads_t  1.351234  0.037984         7.0         0.898858   \n",
       "51   dsads_ll  dsads_rl  0.336949  0.005562         4.0         0.697917   \n",
       "2     dsads_t  dsads_rl  0.479365  0.019388         4.0         0.609375   \n",
       "26   dsads_la  dsads_rl  0.850386  0.016635         4.0         0.718750   \n",
       "14   dsads_ra  dsads_rl  0.593826  0.012356         4.0         0.747396   \n",
       "99   oppo_lua  dsads_rl  1.880956  0.104589        11.0         0.884577   \n",
       "111  oppo_lla  dsads_rl  1.774472  0.106481        11.0         0.832836   \n",
       "75   oppo_rua  dsads_rl  1.859685  0.106835        11.0         0.897512   \n",
       "63     oppo_b  dsads_rl  1.779333  0.087971        11.0         0.910448   \n",
       "87   oppo_rla  dsads_rl  1.890939  0.111826        11.0         0.841791   \n",
       "123   pamap_w  dsads_rl  1.791822  0.048892         7.0         0.809135   \n",
       "135   pamap_c  dsads_rl  1.489314  0.052656         7.0         0.898858   \n",
       "147   pamap_a  dsads_rl  1.427837  0.038547         7.0         0.722675   \n",
       "25   dsads_la  dsads_ra  0.396833  0.008943         4.0         0.718750   \n",
       "0     dsads_t  dsads_ra  0.505051  0.017977         4.0         0.609375   \n",
       "97   oppo_lua  dsads_ra  1.733388  0.091065        11.0         0.884577   \n",
       "49   dsads_ll  dsads_ra  0.462330  0.011396         4.0         0.697917   \n",
       "37   dsads_rl  dsads_ra  0.593826  0.012356         4.0         0.643229   \n",
       "109  oppo_lla  dsads_ra  1.615822  0.090679        11.0         0.832836   \n",
       "73   oppo_rua  dsads_ra  1.727428  0.093210        11.0         0.897512   \n",
       "85   oppo_rla  dsads_ra  1.766390  0.097714        11.0         0.841791   \n",
       "61     oppo_b  dsads_ra  1.670562  0.076164        11.0         0.910448   \n",
       "133   pamap_c  dsads_ra  1.270784  0.037071         7.0         0.898858   \n",
       "121   pamap_w  dsads_ra  1.578720  0.032859         7.0         0.809135   \n",
       "145   pamap_a  dsads_ra  1.279896  0.028512         7.0         0.722675   \n",
       "39   dsads_rl  dsads_ll  0.336949  0.005562         4.0         0.643229   \n",
       "3     dsads_t  dsads_ll  0.509558  0.014866         4.0         0.609375   \n",
       "27   dsads_la  dsads_ll  0.708819  0.014258         4.0         0.718750   \n",
       "15   dsads_ra  dsads_ll  0.462330  0.011396         4.0         0.747396   \n",
       "100  oppo_lua  dsads_ll  1.880057  0.098857        11.0         0.884577   \n",
       "112  oppo_lla  dsads_ll  1.777116  0.099175        11.0         0.832836   \n",
       "76   oppo_rua  dsads_ll  1.868353  0.100481        11.0         0.897512   \n",
       "64     oppo_b  dsads_ll  1.760782  0.082694        11.0         0.910448   \n",
       "88   oppo_rla  dsads_ll  1.901222  0.105857        11.0         0.841791   \n",
       "124   pamap_w  dsads_ll  1.729038  0.044448         7.0         0.809135   \n",
       "136   pamap_c  dsads_ll  1.429557  0.045948         7.0         0.898858   \n",
       "148   pamap_a  dsads_ll  1.366061  0.033579         7.0         0.722675   \n",
       "13   dsads_ra  dsads_la  0.396833  0.008943         4.0         0.747396   \n",
       "1     dsads_t  dsads_la  0.778643  0.021905         4.0         0.609375   \n",
       "98   oppo_lua  dsads_la  1.708458  0.086910        11.0         0.884577   \n",
       "50   dsads_ll  dsads_la  0.708819  0.014258         4.0         0.697917   \n",
       "38   dsads_rl  dsads_la  0.850386  0.016635         4.0         0.643229   \n",
       "110  oppo_lla  dsads_la  1.572520  0.085790        11.0         0.832836   \n",
       "86   oppo_rla  dsads_la  1.745335  0.093644        11.0         0.841791   \n",
       "74   oppo_rua  dsads_la  1.725070  0.089272        11.0         0.897512   \n",
       "62     oppo_b  dsads_la  1.671462  0.073346        11.0         0.910448   \n",
       "134   pamap_c  dsads_la  1.233911  0.033504         7.0         0.898858   \n",
       "122   pamap_w  dsads_la  1.464021  0.030521         7.0         0.809135   \n",
       "146   pamap_a  dsads_la  1.213597  0.027482         7.0         0.722675   \n",
       "\n",
       "      serving  finetune  \n",
       "142  0.530804  0.734394  \n",
       "154  0.477356  0.729498  \n",
       "57   0.337005  0.649939  \n",
       "45   0.241126  0.714810  \n",
       "9    0.238678  0.692370  \n",
       "21   0.234598  0.692370  \n",
       "69   0.234598  0.760914  \n",
       "81   0.234598  0.753978  \n",
       "105  0.234598  0.752754  \n",
       "117  0.159935  0.738474  \n",
       "93   0.125255  0.749898  \n",
       "33   0.037944  0.667483  \n",
       "130  0.627499  0.800898  \n",
       "155  0.372501  0.813953  \n",
       "58   0.297022  0.793554  \n",
       "46   0.241126  0.784986  \n",
       "10   0.238678  0.776418  \n",
       "22   0.234598  0.792330  \n",
       "82   0.197878  0.874337  \n",
       "70   0.128111  0.873929  \n",
       "118  0.121175  0.806610  \n",
       "94   0.068543  0.862913  \n",
       "106  0.060792  0.847001  \n",
       "34   0.022440  0.783762  \n",
       "131  0.622195  0.688290  \n",
       "143  0.558956  0.677683  \n",
       "59   0.404733  0.661771  \n",
       "11   0.277438  0.631171  \n",
       "71   0.252958  0.671563  \n",
       "107  0.251734  0.678091  \n",
       "47   0.247246  0.679315  \n",
       "83   0.242350  0.699306  \n",
       "23   0.234598  0.641371  \n",
       "119  0.210934  0.679315  \n",
       "95   0.153407  0.669931  \n",
       "35   0.029784  0.681763  \n",
       "102  0.827028  0.858636  \n",
       "114  0.730214  0.850174  \n",
       "90   0.689895  0.858138  \n",
       "65   0.567944  0.861374  \n",
       "29   0.489796  0.825535  \n",
       "17   0.487307  0.826531  \n",
       "53   0.408412  0.806620  \n",
       "41   0.341215  0.774017  \n",
       "126  0.318815  0.848681  \n",
       "5    0.318566  0.824540  \n",
       "150  0.291687  0.832504  \n",
       "138  0.145595  0.845694  \n",
       "78   0.669736  0.782230  \n",
       "103  0.567695  0.793181  \n",
       "115  0.561473  0.791936  \n",
       "66   0.496516  0.776257  \n",
       "18   0.487307  0.764560  \n",
       "30   0.464161  0.729965  \n",
       "54   0.443753  0.753858  \n",
       "42   0.346192  0.779492  \n",
       "6    0.308113  0.763564  \n",
       "127  0.302389  0.718019  \n",
       "151  0.270781  0.776755  \n",
       "139  0.219014  0.793181  \n",
       "79   0.814335  0.850423  \n",
       "116  0.788701  0.836984  \n",
       "67   0.652563  0.823295  \n",
       "91   0.612743  0.851419  \n",
       "31   0.517173  0.831010  \n",
       "19   0.500249  0.791936  \n",
       "55   0.412145  0.847437  \n",
       "43   0.350174  0.827028  \n",
       "7    0.329766  0.808860  \n",
       "128  0.316575  0.849925  \n",
       "152  0.279741  0.824291  \n",
       "140  0.266551  0.830513  \n",
       "104  0.733201  0.812842  \n",
       "80   0.683425  0.806620  \n",
       "92   0.655301  0.811598  \n",
       "68   0.530363  0.790692  \n",
       "32   0.499502  0.778995  \n",
       "20   0.496267  0.782230  \n",
       "56   0.475859  0.760329  \n",
       "44   0.338228  0.785217  \n",
       "8    0.328273  0.772026  \n",
       "129  0.298656  0.789199  \n",
       "153  0.237432  0.770533  \n",
       "141  0.219512  0.801892  \n",
       "101  0.791439  0.896217  \n",
       "113  0.678447  0.877551  \n",
       "77   0.660528  0.901692  \n",
       "89   0.570433  0.894973  \n",
       "16   0.509706  0.874564  \n",
       "28   0.488303  0.882031  \n",
       "40   0.428323  0.885266  \n",
       "52   0.409905  0.886013  \n",
       "137  0.396466  0.886262  \n",
       "4    0.341961  0.882778  \n",
       "149  0.322051  0.888004  \n",
       "125  0.318566  0.887506  \n",
       "12   0.502604  0.564453  \n",
       "24   0.498698  0.582682  \n",
       "48   0.488932  0.570312  \n",
       "96   0.470703  0.588542  \n",
       "108  0.401042  0.575521  \n",
       "36   0.342448  0.580729  \n",
       "72   0.317057  0.574870  \n",
       "144  0.282552  0.574870  \n",
       "84   0.276693  0.571615  \n",
       "60   0.259115  0.557943  \n",
       "120  0.251953  0.608073  \n",
       "132  0.251953  0.589844  \n",
       "51   0.662760  0.683594  \n",
       "2    0.590495  0.648438  \n",
       "26   0.513021  0.655599  \n",
       "14   0.496745  0.678385  \n",
       "99   0.470052  0.649089  \n",
       "111  0.378906  0.641927  \n",
       "75   0.347005  0.671224  \n",
       "63   0.336589  0.658854  \n",
       "87   0.269531  0.649740  \n",
       "123  0.251953  0.647135  \n",
       "135  0.251953  0.656901  \n",
       "147  0.224609  0.649089  \n",
       "25   0.711589  0.697917  \n",
       "0    0.571615  0.705729  \n",
       "97   0.558594  0.711589  \n",
       "49   0.511068  0.708984  \n",
       "37   0.509766  0.699219  \n",
       "109  0.466146  0.714844  \n",
       "73   0.401042  0.714844  \n",
       "85   0.376953  0.712240  \n",
       "61   0.306641  0.708333  \n",
       "133  0.258464  0.696615  \n",
       "121  0.252604  0.710938  \n",
       "145  0.244141  0.701823  \n",
       "39   0.671224  0.663411  \n",
       "3    0.589844  0.632812  \n",
       "27   0.544271  0.650391  \n",
       "15   0.507812  0.641927  \n",
       "100  0.493490  0.672526  \n",
       "112  0.447917  0.651042  \n",
       "76   0.381510  0.669922  \n",
       "64   0.294922  0.636068  \n",
       "88   0.276693  0.662109  \n",
       "124  0.251953  0.653646  \n",
       "136  0.251953  0.642578  \n",
       "148  0.231120  0.629557  \n",
       "13   0.681641  0.732422  \n",
       "1    0.604167  0.720703  \n",
       "98   0.573568  0.727214  \n",
       "50   0.539062  0.709635  \n",
       "38   0.518229  0.706380  \n",
       "110  0.486328  0.718750  \n",
       "86   0.404948  0.712891  \n",
       "74   0.402344  0.716797  \n",
       "62   0.366536  0.729167  \n",
       "134  0.351562  0.710286  \n",
       "122  0.250651  0.718750  \n",
       "146  0.246094  0.716797  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 200)\n",
    "result_df=result_df.sort_values(by=['Target', 'serving'], ascending=False)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69df24ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T19:01:31.524068Z",
     "iopub.status.busy": "2022-04-12T19:01:31.523261Z",
     "iopub.status.idle": "2022-04-12T19:01:31.526441Z",
     "shell.execute_reply": "2022-04-12T19:01:31.526831Z"
    },
    "papermill": {
     "duration": 0.747074,
     "end_time": "2022-04-12T19:01:31.526962",
     "exception": false,
     "start_time": "2022-04-12T19:01:30.779888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dsads_t',\n",
       " 'dsads_ra',\n",
       " 'dsads_la',\n",
       " 'dsads_rl',\n",
       " 'dsads_ll',\n",
       " 'oppo_b',\n",
       " 'oppo_rua',\n",
       " 'oppo_rla',\n",
       " 'oppo_lua',\n",
       " 'oppo_lla',\n",
       " 'pamap_w',\n",
       " 'pamap_c',\n",
       " 'pamap_a']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "266fff6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T19:01:32.937252Z",
     "iopub.status.busy": "2022-04-12T19:01:32.935841Z",
     "iopub.status.idle": "2022-04-12T19:01:32.940121Z",
     "shell.execute_reply": "2022-04-12T19:01:32.939436Z"
    },
    "papermill": {
     "duration": 0.708247,
     "end_time": "2022-04-12T19:01:32.940307",
     "exception": false,
     "start_time": "2022-04-12T19:01:32.232060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.8159e-01, 1.2891e-03, 9.7740e-01, ..., 3.5026e-04, 1.6672e-01,\n",
       "        4.8733e-02],\n",
       "       [1.8186e-01, 9.6067e-04, 9.7901e-01, ..., 1.6386e-03, 8.2052e-01,\n",
       "        7.6149e-01],\n",
       "       [1.8171e-01, 5.2793e-04, 9.9120e-01, ..., 2.5491e-04, 1.8438e-01,\n",
       "        7.9390e-02],\n",
       "       ...,\n",
       "       [1.9397e-01, 1.0257e-01, 5.6145e-01, ..., 1.5153e-02, 5.6430e-01,\n",
       "        3.8648e-01],\n",
       "       [2.0082e-01, 1.0653e-01, 5.4812e-01, ..., 2.6152e-02, 6.2379e-01,\n",
       "        4.1909e-01],\n",
       "       [1.8725e-01, 1.0268e-01, 5.5722e-01, ..., 1.4752e-02, 5.8800e-01,\n",
       "        4.2501e-01]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_data['dsads_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98375816",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T19:01:34.357423Z",
     "iopub.status.busy": "2022-04-12T19:01:34.356288Z",
     "iopub.status.idle": "2022-04-12T19:01:34.359405Z",
     "shell.execute_reply": "2022-04-12T19:01:34.359772Z"
    },
    "papermill": {
     "duration": 0.703229,
     "end_time": "2022-04-12T19:01:34.359902",
     "exception": false,
     "start_time": "2022-04-12T19:01:33.656673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function keras.engine.training.Model.predict(self, x, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.models.Sequential.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a0c8651",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T19:01:35.807764Z",
     "iopub.status.busy": "2022-04-12T19:01:35.806871Z",
     "iopub.status.idle": "2022-04-12T19:02:38.106891Z",
     "shell.execute_reply": "2022-04-12T19:02:38.104480Z"
    },
    "id": "nsiaH6Cj24jX",
    "papermill": {
     "duration": 63.009109,
     "end_time": "2022-04-12T19:02:38.107057",
     "exception": false,
     "start_time": "2022-04-12T19:01:35.097948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET- dsads_t\n",
      "dsads_ll_model\n",
      "\n",
      "Weights Loaded-       dsads_ll_model\n",
      "Target dataset loaded-     dsads_t\n",
      "1920\n",
      "dsads_ra_model\n",
      "\n",
      "Weights Loaded-       dsads_ra_model\n",
      "Target dataset loaded-     dsads_t\n",
      "1920\n",
      "dsads_rl_model\n",
      "\n",
      "Weights Loaded-       dsads_rl_model\n",
      "Target dataset loaded-     dsads_t\n",
      "1920\n",
      "{'dsads_ll': array([0, 2, 2, ..., 3, 3, 3]), 'dsads_ra': array([2, 2, 2, ..., 3, 3, 3]), 'dsads_rl': array([2, 2, 2, ..., 3, 0, 3])}\n",
      "dsads_ll --> dsads_t\n",
      "dsads_ra --> dsads_t\n",
      "dsads_rl --> dsads_t\n",
      "{'dsads_ll': 0.8817708333333333, 'dsads_ra': 0.5630208333333333, 'dsads_rl': 0.7572916666666667}\n",
      "TARGET- dsads_ra\n",
      "dsads_la_model\n",
      "\n",
      "Weights Loaded-       dsads_la_model\n",
      "Target dataset loaded-     dsads_ra\n",
      "1920\n",
      "dsads_ll_model\n",
      "\n",
      "Weights Loaded-       dsads_ll_model\n",
      "Target dataset loaded-     dsads_ra\n",
      "1920\n",
      "dsads_rl_model\n",
      "\n",
      "Weights Loaded-       dsads_rl_model\n",
      "Target dataset loaded-     dsads_ra\n",
      "1920\n",
      "{'dsads_la': array([1, 1, 0, ..., 3, 3, 3]), 'dsads_ll': array([2, 1, 0, ..., 3, 3, 3]), 'dsads_rl': array([2, 2, 0, ..., 3, 3, 3])}\n",
      "dsads_la --> dsads_ra\n",
      "dsads_ll --> dsads_ra\n",
      "dsads_rl --> dsads_ra\n",
      "{'dsads_la': 0.7223958333333333, 'dsads_ll': 0.834375, 'dsads_rl': 0.8276041666666667}\n",
      "TARGET- dsads_la\n",
      "dsads_ra_model\n",
      "\n",
      "Weights Loaded-       dsads_ra_model\n",
      "Target dataset loaded-     dsads_la\n",
      "1920\n",
      "dsads_ll_model\n",
      "\n",
      "Weights Loaded-       dsads_ll_model\n",
      "Target dataset loaded-     dsads_la\n",
      "1920\n",
      "dsads_rl_model\n",
      "\n",
      "Weights Loaded-       dsads_rl_model\n",
      "Target dataset loaded-     dsads_la\n",
      "1920\n",
      "{'dsads_ra': array([2, 2, 2, ..., 3, 3, 3]), 'dsads_ll': array([2, 2, 2, ..., 3, 3, 3]), 'dsads_rl': array([2, 2, 2, ..., 3, 3, 3])}\n",
      "dsads_ra --> dsads_la\n",
      "dsads_ll --> dsads_la\n",
      "dsads_rl --> dsads_la\n",
      "{'dsads_ra': 0.740625, 'dsads_ll': 0.8479166666666667, 'dsads_rl': 0.83125}\n",
      "TARGET- dsads_rl\n",
      "dsads_ll_model\n",
      "\n",
      "Weights Loaded-       dsads_ll_model\n",
      "Target dataset loaded-     dsads_rl\n",
      "1920\n",
      "dsads_ra_model\n",
      "\n",
      "Weights Loaded-       dsads_ra_model\n",
      "Target dataset loaded-     dsads_rl\n",
      "1920\n",
      "dsads_la_model\n",
      "\n",
      "Weights Loaded-       dsads_la_model\n",
      "Target dataset loaded-     dsads_rl\n",
      "1920\n",
      "{'dsads_ll': array([1, 2, 1, ..., 3, 3, 3]), 'dsads_ra': array([1, 0, 0, ..., 3, 3, 3]), 'dsads_la': array([1, 1, 0, ..., 3, 3, 3])}\n",
      "dsads_ll --> dsads_rl\n",
      "dsads_ra --> dsads_rl\n",
      "dsads_la --> dsads_rl\n",
      "{'dsads_ll': 0.6020833333333333, 'dsads_ra': 0.9359375, 'dsads_la': 0.8583333333333333}\n",
      "TARGET- dsads_ll\n",
      "dsads_rl_model\n",
      "\n",
      "Weights Loaded-       dsads_rl_model\n",
      "Target dataset loaded-     dsads_ll\n",
      "1920\n",
      "dsads_ra_model\n",
      "\n",
      "Weights Loaded-       dsads_ra_model\n",
      "Target dataset loaded-     dsads_ll\n",
      "1920\n",
      "dsads_la_model\n",
      "\n",
      "Weights Loaded-       dsads_la_model\n",
      "Target dataset loaded-     dsads_ll\n",
      "1920\n",
      "{'dsads_rl': array([1, 2, 2, ..., 3, 3, 3]), 'dsads_ra': array([1, 0, 1, ..., 3, 3, 3]), 'dsads_la': array([1, 1, 1, ..., 3, 3, 3])}\n",
      "dsads_rl --> dsads_ll\n",
      "dsads_ra --> dsads_ll\n",
      "dsads_la --> dsads_ll\n",
      "{'dsads_rl': 0.5708333333333333, 'dsads_ra': 0.8734375, 'dsads_la': 0.9432291666666667}\n",
      "TARGET- oppo_b\n",
      "oppo_lua_model\n",
      "\n",
      "Weights Loaded-       oppo_lua_model\n",
      "Target dataset loaded-     oppo_b\n",
      "5022\n",
      "oppo_rua_model\n",
      "\n",
      "Weights Loaded-       oppo_rua_model\n",
      "Target dataset loaded-     oppo_b\n",
      "5022\n",
      "oppo_rla_model\n",
      "\n",
      "Weights Loaded-       oppo_rla_model\n",
      "Target dataset loaded-     oppo_b\n",
      "5022\n",
      "{'oppo_lua': array([2, 2, 2, ..., 1, 1, 1]), 'oppo_rua': array([2, 2, 2, ..., 2, 2, 2]), 'oppo_rla': array([2, 2, 2, ..., 2, 2, 2])}\n",
      "oppo_lua --> oppo_b\n",
      "oppo_rua --> oppo_b\n",
      "oppo_rla --> oppo_b\n",
      "{'oppo_lua': 0.6979291119076065, 'oppo_rua': 0.9297092791716448, 'oppo_rla': 0.84926324173636}\n",
      "TARGET- oppo_rua\n",
      "oppo_lua_model\n",
      "\n",
      "Weights Loaded-       oppo_lua_model\n",
      "Target dataset loaded-     oppo_rua\n",
      "5022\n",
      "oppo_rla_model\n",
      "\n",
      "Weights Loaded-       oppo_rla_model\n",
      "Target dataset loaded-     oppo_rua\n",
      "5022\n",
      "oppo_lla_model\n",
      "\n",
      "Weights Loaded-       oppo_lla_model\n",
      "Target dataset loaded-     oppo_rua\n",
      "5022\n",
      "{'oppo_lua': array([2, 2, 2, ..., 1, 1, 1]), 'oppo_rla': array([2, 2, 2, ..., 2, 1, 2]), 'oppo_lla': array([2, 2, 2, ..., 0, 1, 1])}\n",
      "oppo_lua --> oppo_rua\n",
      "oppo_rla --> oppo_rua\n",
      "oppo_lla --> oppo_rua\n",
      "{'oppo_lua': 0.9257268020708881, 'oppo_rla': 0.7228195937873357, 'oppo_lla': 0.869573874950219}\n",
      "TARGET- oppo_rla\n",
      "oppo_lua_model\n",
      "\n",
      "Weights Loaded-       oppo_lua_model\n",
      "Target dataset loaded-     oppo_rla\n",
      "5022\n",
      "oppo_rua_model\n",
      "\n",
      "Weights Loaded-       oppo_rua_model\n",
      "Target dataset loaded-     oppo_rla\n",
      "5022\n",
      "oppo_lla_model\n",
      "\n",
      "Weights Loaded-       oppo_lla_model\n",
      "Target dataset loaded-     oppo_rla\n",
      "5022\n",
      "{'oppo_lua': array([1, 1, 1, ..., 2, 1, 1]), 'oppo_rua': array([1, 1, 1, ..., 2, 1, 1]), 'oppo_lla': array([1, 1, 1, ..., 1, 1, 1])}\n",
      "oppo_lua --> oppo_rla\n",
      "oppo_rua --> oppo_rla\n",
      "oppo_lla --> oppo_rla\n",
      "{'oppo_lua': 0.8972520908004779, 'oppo_rua': 0.8405017921146953, 'oppo_lla': 0.7783751493428913}\n",
      "TARGET- oppo_lua\n",
      "oppo_rla_model\n",
      "\n",
      "Weights Loaded-       oppo_rla_model\n",
      "Target dataset loaded-     oppo_lua\n",
      "5022\n",
      "oppo_rua_model\n",
      "\n",
      "Weights Loaded-       oppo_rua_model\n",
      "Target dataset loaded-     oppo_lua\n",
      "5022\n",
      "oppo_lla_model\n",
      "\n",
      "Weights Loaded-       oppo_lla_model\n",
      "Target dataset loaded-     oppo_lua\n",
      "5022\n",
      "{'oppo_rla': array([2, 2, 2, ..., 2, 2, 2]), 'oppo_rua': array([2, 2, 2, ..., 1, 2, 2]), 'oppo_lla': array([2, 2, 2, ..., 1, 1, 1])}\n",
      "oppo_rla --> oppo_lua\n",
      "oppo_rua --> oppo_lua\n",
      "oppo_lla --> oppo_lua\n",
      "{'oppo_rla': 0.7289924332935086, 'oppo_rua': 0.9368777379530068, 'oppo_lla': 0.8311429709279171}\n",
      "TARGET- oppo_lla\n",
      "oppo_rua_model\n",
      "\n",
      "Weights Loaded-       oppo_rua_model\n",
      "Target dataset loaded-     oppo_lla\n",
      "5022\n",
      "oppo_lua_model\n",
      "\n",
      "Weights Loaded-       oppo_lua_model\n",
      "Target dataset loaded-     oppo_lla\n",
      "5022\n",
      "oppo_rla_model\n",
      "\n",
      "Weights Loaded-       oppo_rla_model\n",
      "Target dataset loaded-     oppo_lla\n",
      "5022\n",
      "{'oppo_rua': array([2, 2, 2, ..., 1, 1, 1]), 'oppo_lua': array([2, 2, 2, ..., 1, 1, 0]), 'oppo_rla': array([2, 2, 2, ..., 2, 2, 2])}\n",
      "oppo_rua --> oppo_lla\n",
      "oppo_lua --> oppo_lla\n",
      "oppo_rla --> oppo_lla\n",
      "{'oppo_rua': 0.9382716049382716, 'oppo_lua': 0.9277180406212664, 'oppo_rla': 0.8092393468737554}\n",
      "TARGET- pamap_w\n",
      "pamap_c_model\n",
      "\n",
      "Weights Loaded-       pamap_c_model\n",
      "Target dataset loaded-     pamap_w\n",
      "3063\n",
      "pamap_a_model\n",
      "\n",
      "Weights Loaded-       pamap_a_model\n",
      "Target dataset loaded-     pamap_w\n",
      "3063\n",
      "dsads_la_model\n",
      "\n",
      "Weights Loaded-       dsads_la_model\n",
      "Target dataset loaded-     pamap_w\n",
      "3063\n",
      "{'pamap_c': array([0, 0, 0, ..., 0, 0, 0]), 'pamap_a': array([3, 3, 0, ..., 0, 3, 3]), 'dsads_la': array([2, 2, 2, ..., 2, 2, 2])}\n",
      "pamap_c --> pamap_w\n",
      "pamap_a --> pamap_w\n",
      "dsads_la --> pamap_w\n",
      "{'pamap_c': 0.8021547502448579, 'pamap_a': 0.7064968984655566, 'dsads_la': 0.13091740124061377}\n",
      "TARGET- pamap_c\n",
      "pamap_w_model\n",
      "\n",
      "Weights Loaded-       pamap_w_model\n",
      "Target dataset loaded-     pamap_c\n",
      "3063\n",
      "pamap_a_model\n",
      "\n",
      "Weights Loaded-       pamap_a_model\n",
      "Target dataset loaded-     pamap_c\n",
      "3063\n",
      "dsads_la_model\n",
      "\n",
      "Weights Loaded-       dsads_la_model\n",
      "Target dataset loaded-     pamap_c\n",
      "3063\n",
      "{'pamap_w': array([1, 1, 1, ..., 0, 0, 1]), 'pamap_a': array([1, 1, 0, ..., 3, 2, 1]), 'dsads_la': array([0, 0, 2, ..., 2, 2, 2])}\n",
      "pamap_w --> pamap_c\n",
      "pamap_a --> pamap_c\n",
      "dsads_la --> pamap_c\n",
      "{'pamap_w': 0.7368592882794646, 'pamap_a': 0.41821743388834476, 'dsads_la': 0.25824355207313093}\n",
      "TARGET- pamap_a\n",
      "pamap_w_model\n",
      "\n",
      "Weights Loaded-       pamap_w_model\n",
      "Target dataset loaded-     pamap_a\n",
      "3063\n",
      "pamap_c_model\n",
      "\n",
      "Weights Loaded-       pamap_c_model\n",
      "Target dataset loaded-     pamap_a\n",
      "3063\n",
      "dsads_la_model\n",
      "\n",
      "Weights Loaded-       dsads_la_model\n",
      "Target dataset loaded-     pamap_a\n",
      "3063\n",
      "{'pamap_w': array([1, 1, 1, ..., 0, 1, 1]), 'pamap_c': array([2, 2, 3, ..., 0, 0, 0]), 'dsads_la': array([0, 0, 2, ..., 2, 2, 2])}\n",
      "pamap_w --> pamap_a\n",
      "pamap_c --> pamap_a\n",
      "dsads_la --> pamap_a\n",
      "{'pamap_w': 0.6353248449232778, 'pamap_c': 0.6565458700620307, 'dsads_la': 0.32517140058765914}\n",
      "{'dsads_t': {'dsads_ll': 0.8817708333333333, 'dsads_ra': 0.5630208333333333, 'dsads_rl': 0.7572916666666667}, 'dsads_ra': {'dsads_la': 0.7223958333333333, 'dsads_ll': 0.834375, 'dsads_rl': 0.8276041666666667}, 'dsads_la': {'dsads_ra': 0.740625, 'dsads_ll': 0.8479166666666667, 'dsads_rl': 0.83125}, 'dsads_rl': {'dsads_ll': 0.6020833333333333, 'dsads_ra': 0.9359375, 'dsads_la': 0.8583333333333333}, 'dsads_ll': {'dsads_rl': 0.5708333333333333, 'dsads_ra': 0.8734375, 'dsads_la': 0.9432291666666667}, 'oppo_b': {'oppo_lua': 0.6979291119076065, 'oppo_rua': 0.9297092791716448, 'oppo_rla': 0.84926324173636}, 'oppo_rua': {'oppo_lua': 0.9257268020708881, 'oppo_rla': 0.7228195937873357, 'oppo_lla': 0.869573874950219}, 'oppo_rla': {'oppo_lua': 0.8972520908004779, 'oppo_rua': 0.8405017921146953, 'oppo_lla': 0.7783751493428913}, 'oppo_lua': {'oppo_rla': 0.7289924332935086, 'oppo_rua': 0.9368777379530068, 'oppo_lla': 0.8311429709279171}, 'oppo_lla': {'oppo_rua': 0.9382716049382716, 'oppo_lua': 0.9277180406212664, 'oppo_rla': 0.8092393468737554}, 'pamap_w': {'pamap_c': 0.8021547502448579, 'pamap_a': 0.7064968984655566, 'dsads_la': 0.13091740124061377}, 'pamap_c': {'pamap_w': 0.7368592882794646, 'pamap_a': 0.41821743388834476, 'dsads_la': 0.25824355207313093}, 'pamap_a': {'pamap_w': 0.6353248449232778, 'pamap_c': 0.6565458700620307, 'dsads_la': 0.32517140058765914}}\n",
      "TARGET- dsads_t\n",
      "oppo_lua_model\n",
      "\n",
      "Weights Loaded-       oppo_lua_model\n",
      "Target dataset loaded-     dsads_t\n",
      "1920\n",
      "oppo_lla_model\n",
      "\n",
      "Weights Loaded-       oppo_lla_model\n",
      "Target dataset loaded-     dsads_t\n",
      "1920\n",
      "oppo_rua_model\n",
      "\n",
      "Weights Loaded-       oppo_rua_model\n",
      "Target dataset loaded-     dsads_t\n",
      "1920\n",
      "{'oppo_lua': array([3, 3, 0, ..., 3, 3, 2]), 'oppo_lla': array([3, 3, 0, ..., 3, 3, 3]), 'oppo_rua': array([3, 3, 3, ..., 3, 3, 3])}\n",
      "oppo_lua --> dsads_t\n",
      "oppo_lla --> dsads_t\n",
      "oppo_rua --> dsads_t\n",
      "{'oppo_lua': 0.7328125, 'oppo_lla': 0.9802083333333333, 'oppo_rua': 0.7770833333333333}\n",
      "TARGET- dsads_ra\n",
      "oppo_lua_model\n",
      "\n",
      "Weights Loaded-       oppo_lua_model\n",
      "Target dataset loaded-     dsads_ra\n",
      "1920\n",
      "oppo_lla_model\n",
      "\n",
      "Weights Loaded-       oppo_lla_model\n",
      "Target dataset loaded-     dsads_ra\n",
      "1920\n",
      "oppo_rua_model\n",
      "\n",
      "Weights Loaded-       oppo_rua_model\n",
      "Target dataset loaded-     dsads_ra\n",
      "1920\n",
      "{'oppo_lua': array([0, 0, 0, ..., 3, 3, 3]), 'oppo_lla': array([0, 0, 0, ..., 3, 3, 3]), 'oppo_rua': array([3, 3, 0, ..., 3, 3, 3])}\n",
      "oppo_lua --> dsads_ra\n",
      "oppo_lla --> dsads_ra\n",
      "oppo_rua --> dsads_ra\n",
      "{'oppo_lua': 0.8526041666666667, 'oppo_lla': 0.9901041666666667, 'oppo_rua': 0.765625}\n",
      "TARGET- dsads_la\n",
      "oppo_lua_model\n",
      "\n",
      "Weights Loaded-       oppo_lua_model\n",
      "Target dataset loaded-     dsads_la\n",
      "1920\n",
      "oppo_lla_model\n",
      "\n",
      "Weights Loaded-       oppo_lla_model\n",
      "Target dataset loaded-     dsads_la\n",
      "1920\n",
      "oppo_rla_model\n",
      "\n",
      "Weights Loaded-       oppo_rla_model\n",
      "Target dataset loaded-     dsads_la\n",
      "1920\n",
      "{'oppo_lua': array([0, 2, 0, ..., 3, 3, 3]), 'oppo_lla': array([0, 3, 0, ..., 3, 3, 3]), 'oppo_rla': array([0, 0, 0, ..., 2, 3, 2])}\n",
      "oppo_lua --> dsads_la\n",
      "oppo_lla --> dsads_la\n",
      "oppo_rla --> dsads_la\n",
      "{'oppo_lua': 0.9651041666666667, 'oppo_lla': 0.8578125, 'oppo_rla': 0.646875}\n",
      "TARGET- dsads_rl\n",
      "oppo_lua_model\n",
      "\n",
      "Weights Loaded-       oppo_lua_model\n",
      "Target dataset loaded-     dsads_rl\n",
      "1920\n",
      "oppo_lla_model\n",
      "\n",
      "Weights Loaded-       oppo_lla_model\n",
      "Target dataset loaded-     dsads_rl\n",
      "1920\n",
      "oppo_rua_model\n",
      "\n",
      "Weights Loaded-       oppo_rua_model\n",
      "Target dataset loaded-     dsads_rl\n",
      "1920\n",
      "{'oppo_lua': array([0, 0, 0, ..., 3, 3, 3]), 'oppo_lla': array([3, 0, 0, ..., 3, 3, 3]), 'oppo_rua': array([3, 3, 0, ..., 2, 3, 3])}\n",
      "oppo_lua --> dsads_rl\n",
      "oppo_lla --> dsads_rl\n",
      "oppo_rua --> dsads_rl\n",
      "{'oppo_lua': 0.7557291666666667, 'oppo_lla': 0.9713541666666666, 'oppo_rua': 0.8901041666666667}\n",
      "TARGET- dsads_ll\n",
      "oppo_lua_model\n",
      "\n",
      "Weights Loaded-       oppo_lua_model\n",
      "Target dataset loaded-     dsads_ll\n",
      "1920\n",
      "oppo_lla_model\n",
      "\n",
      "Weights Loaded-       oppo_lla_model\n",
      "Target dataset loaded-     dsads_ll\n",
      "1920\n",
      "oppo_rua_model\n",
      "\n",
      "Weights Loaded-       oppo_rua_model\n",
      "Target dataset loaded-     dsads_ll\n",
      "1920\n",
      "{'oppo_lua': array([0, 0, 0, ..., 3, 3, 3]), 'oppo_lla': array([0, 0, 0, ..., 3, 3, 3]), 'oppo_rua': array([0, 0, 3, ..., 3, 3, 2])}\n",
      "oppo_lua --> dsads_ll\n",
      "oppo_lla --> dsads_ll\n",
      "oppo_rua --> dsads_ll\n",
      "{'oppo_lua': 0.8505208333333333, 'oppo_lla': 0.9854166666666667, 'oppo_rua': 0.8369791666666667}\n",
      "TARGET- oppo_b\n",
      "oppo_lua_model\n",
      "\n",
      "Weights Loaded-       oppo_lua_model\n",
      "Target dataset loaded-     oppo_b\n",
      "5022\n",
      "oppo_lla_model\n",
      "\n",
      "Weights Loaded-       oppo_lla_model\n",
      "Target dataset loaded-     oppo_b\n",
      "5022\n",
      "oppo_rua_model\n",
      "\n",
      "Weights Loaded-       oppo_rua_model\n",
      "Target dataset loaded-     oppo_b\n",
      "5022\n",
      "{'oppo_lua': array([2, 2, 2, ..., 1, 1, 1]), 'oppo_lla': array([2, 2, 2, ..., 0, 1, 0]), 'oppo_rua': array([2, 2, 2, ..., 2, 2, 2])}\n",
      "oppo_lua --> oppo_b\n",
      "oppo_lla --> oppo_b\n",
      "oppo_rua --> oppo_b\n",
      "{'oppo_lua': 0.913779370768618, 'oppo_lla': 0.8677817602548785, 'oppo_rua': 0.6770211071286341}\n",
      "TARGET- oppo_rua\n",
      "oppo_lua_model\n",
      "\n",
      "Weights Loaded-       oppo_lua_model\n",
      "Target dataset loaded-     oppo_rua\n",
      "5022\n",
      "oppo_lla_model\n",
      "\n",
      "Weights Loaded-       oppo_lla_model\n",
      "Target dataset loaded-     oppo_rua\n",
      "5022\n",
      "oppo_rla_model\n",
      "\n",
      "Weights Loaded-       oppo_rla_model\n",
      "Target dataset loaded-     oppo_rua\n",
      "5022\n",
      "{'oppo_lua': array([2, 2, 2, ..., 1, 1, 1]), 'oppo_lla': array([2, 2, 2, ..., 0, 1, 1]), 'oppo_rla': array([2, 2, 2, ..., 2, 1, 2])}\n",
      "oppo_lua --> oppo_rua\n",
      "oppo_lla --> oppo_rua\n",
      "oppo_rla --> oppo_rua\n",
      "{'oppo_lua': 0.9257268020708881, 'oppo_lla': 0.869573874950219, 'oppo_rla': 0.7228195937873357}\n",
      "TARGET- oppo_rla\n",
      "oppo_rua_model\n",
      "\n",
      "Weights Loaded-       oppo_rua_model\n",
      "Target dataset loaded-     oppo_rla\n",
      "5022\n",
      "oppo_lua_model\n",
      "\n",
      "Weights Loaded-       oppo_lua_model\n",
      "Target dataset loaded-     oppo_rla\n",
      "5022\n",
      "oppo_lla_model\n",
      "\n",
      "Weights Loaded-       oppo_lla_model\n",
      "Target dataset loaded-     oppo_rla\n",
      "5022\n",
      "{'oppo_rua': array([1, 1, 1, ..., 2, 1, 1]), 'oppo_lua': array([1, 1, 1, ..., 2, 1, 1]), 'oppo_lla': array([1, 1, 1, ..., 1, 1, 1])}\n",
      "oppo_rua --> oppo_rla\n",
      "oppo_lua --> oppo_rla\n",
      "oppo_lla --> oppo_rla\n",
      "{'oppo_rua': 0.8405017921146953, 'oppo_lua': 0.8972520908004779, 'oppo_lla': 0.7783751493428913}\n",
      "TARGET- oppo_lua\n",
      "oppo_rua_model\n",
      "\n",
      "Weights Loaded-       oppo_rua_model\n",
      "Target dataset loaded-     oppo_lua\n",
      "5022\n",
      "oppo_lla_model\n",
      "\n",
      "Weights Loaded-       oppo_lla_model\n",
      "Target dataset loaded-     oppo_lua\n",
      "5022\n",
      "oppo_b_model\n",
      "\n",
      "Weights Loaded-       oppo_b_model\n",
      "Target dataset loaded-     oppo_lua\n",
      "5022\n",
      "{'oppo_rua': array([2, 2, 2, ..., 1, 2, 2]), 'oppo_lla': array([2, 2, 2, ..., 1, 1, 1]), 'oppo_b': array([2, 2, 2, ..., 2, 2, 2])}\n",
      "oppo_rua --> oppo_lua\n",
      "oppo_lla --> oppo_lua\n",
      "oppo_b --> oppo_lua\n",
      "{'oppo_rua': 0.9516129032258065, 'oppo_lla': 0.815810434090004, 'oppo_b': 0.743926722421346}\n",
      "TARGET- oppo_lla\n",
      "oppo_lua_model\n",
      "\n",
      "Weights Loaded-       oppo_lua_model\n",
      "Target dataset loaded-     oppo_lla\n",
      "5022\n",
      "oppo_rua_model\n",
      "\n",
      "Weights Loaded-       oppo_rua_model\n",
      "Target dataset loaded-     oppo_lla\n",
      "5022\n",
      "oppo_rla_model\n",
      "\n",
      "Weights Loaded-       oppo_rla_model\n",
      "Target dataset loaded-     oppo_lla\n",
      "5022\n",
      "{'oppo_lua': array([2, 2, 2, ..., 1, 1, 0]), 'oppo_rua': array([2, 2, 2, ..., 1, 1, 1]), 'oppo_rla': array([2, 2, 2, ..., 2, 2, 2])}\n",
      "oppo_lua --> oppo_lla\n",
      "oppo_rua --> oppo_lla\n",
      "oppo_rla --> oppo_lla\n",
      "{'oppo_lua': 0.9277180406212664, 'oppo_rua': 0.9382716049382716, 'oppo_rla': 0.8092393468737554}\n",
      "TARGET- pamap_w\n",
      "oppo_b_model\n",
      "\n",
      "Weights Loaded-       oppo_b_model\n",
      "Target dataset loaded-     pamap_w\n",
      "3063\n",
      "oppo_rua_model\n",
      "\n",
      "Weights Loaded-       oppo_rua_model\n",
      "Target dataset loaded-     pamap_w\n",
      "3063\n",
      "oppo_lua_model\n",
      "\n",
      "Weights Loaded-       oppo_lua_model\n",
      "Target dataset loaded-     pamap_w\n",
      "3063\n",
      "{'oppo_b': array([2, 2, 2, ..., 2, 2, 2]), 'oppo_rua': array([2, 2, 2, ..., 2, 2, 2]), 'oppo_lua': array([2, 2, 2, ..., 2, 2, 2])}\n",
      "oppo_b --> pamap_w\n",
      "oppo_rua --> pamap_w\n",
      "oppo_lua --> pamap_w\n",
      "{'oppo_b': 0.9986940907606922, 'oppo_rua': 0.9986940907606922, 'oppo_lua': 0.999347045380346}\n",
      "TARGET- pamap_c\n",
      "oppo_rua_model\n",
      "\n",
      "Weights Loaded-       oppo_rua_model\n",
      "Target dataset loaded-     pamap_c\n",
      "3063\n",
      "oppo_b_model\n",
      "\n",
      "Weights Loaded-       oppo_b_model\n",
      "Target dataset loaded-     pamap_c\n",
      "3063\n",
      "oppo_lla_model\n",
      "\n",
      "Weights Loaded-       oppo_lla_model\n",
      "Target dataset loaded-     pamap_c\n",
      "3063\n",
      "{'oppo_rua': array([2, 0, 2, ..., 2, 2, 2]), 'oppo_b': array([0, 0, 0, ..., 2, 2, 2]), 'oppo_lla': array([2, 0, 0, ..., 2, 2, 2])}\n",
      "oppo_rua --> pamap_c\n",
      "oppo_b --> pamap_c\n",
      "oppo_lla --> pamap_c\n",
      "{'oppo_rua': 0.9128305582761999, 'oppo_b': 0.8841005550114267, 'oppo_lla': 0.6196539340515834}\n",
      "TARGET- pamap_a\n",
      "oppo_b_model\n",
      "\n",
      "Weights Loaded-       oppo_b_model\n",
      "Target dataset loaded-     pamap_a\n",
      "3063\n",
      "oppo_lua_model\n",
      "\n",
      "Weights Loaded-       oppo_lua_model\n",
      "Target dataset loaded-     pamap_a\n",
      "3063\n",
      "oppo_rua_model\n",
      "\n",
      "Weights Loaded-       oppo_rua_model\n",
      "Target dataset loaded-     pamap_a\n",
      "3063\n",
      "{'oppo_b': array([1, 1, 1, ..., 2, 2, 2]), 'oppo_lua': array([0, 0, 2, ..., 2, 2, 2]), 'oppo_rua': array([0, 0, 2, ..., 2, 2, 2])}\n",
      "oppo_b --> pamap_a\n",
      "oppo_lua --> pamap_a\n",
      "oppo_rua --> pamap_a\n",
      "{'oppo_b': 0.9562520404831865, 'oppo_lua': 0.8570029382957884, 'oppo_rua': 0.8723473718576559}\n",
      "{'dsads_t': {'oppo_lua': 0.7328125, 'oppo_lla': 0.9802083333333333, 'oppo_rua': 0.7770833333333333}, 'dsads_ra': {'oppo_lua': 0.8526041666666667, 'oppo_lla': 0.9901041666666667, 'oppo_rua': 0.765625}, 'dsads_la': {'oppo_lua': 0.9651041666666667, 'oppo_lla': 0.8578125, 'oppo_rla': 0.646875}, 'dsads_rl': {'oppo_lua': 0.7557291666666667, 'oppo_lla': 0.9713541666666666, 'oppo_rua': 0.8901041666666667}, 'dsads_ll': {'oppo_lua': 0.8505208333333333, 'oppo_lla': 0.9854166666666667, 'oppo_rua': 0.8369791666666667}, 'oppo_b': {'oppo_lua': 0.913779370768618, 'oppo_lla': 0.8677817602548785, 'oppo_rua': 0.6770211071286341}, 'oppo_rua': {'oppo_lua': 0.9257268020708881, 'oppo_lla': 0.869573874950219, 'oppo_rla': 0.7228195937873357}, 'oppo_rla': {'oppo_rua': 0.8405017921146953, 'oppo_lua': 0.8972520908004779, 'oppo_lla': 0.7783751493428913}, 'oppo_lua': {'oppo_rua': 0.9516129032258065, 'oppo_lla': 0.815810434090004, 'oppo_b': 0.743926722421346}, 'oppo_lla': {'oppo_lua': 0.9277180406212664, 'oppo_rua': 0.9382716049382716, 'oppo_rla': 0.8092393468737554}, 'pamap_w': {'oppo_b': 0.9986940907606922, 'oppo_rua': 0.9986940907606922, 'oppo_lua': 0.999347045380346}, 'pamap_c': {'oppo_rua': 0.9128305582761999, 'oppo_b': 0.8841005550114267, 'oppo_lla': 0.6196539340515834}, 'pamap_a': {'oppo_b': 0.9562520404831865, 'oppo_lua': 0.8570029382957884, 'oppo_rua': 0.8723473718576559}}\n",
      "TARGET- dsads_t\n",
      "dsads_rl_model\n",
      "\n",
      "Weights Loaded-       dsads_rl_model\n",
      "Target dataset loaded-     dsads_t\n",
      "1920\n",
      "dsads_ra_model\n",
      "\n",
      "Weights Loaded-       dsads_ra_model\n",
      "Target dataset loaded-     dsads_t\n",
      "1920\n",
      "dsads_ll_model\n",
      "\n",
      "Weights Loaded-       dsads_ll_model\n",
      "Target dataset loaded-     dsads_t\n",
      "1920\n",
      "{'dsads_rl': array([2, 2, 2, ..., 3, 0, 3]), 'dsads_ra': array([2, 2, 2, ..., 3, 3, 3]), 'dsads_ll': array([0, 2, 2, ..., 3, 3, 3])}\n",
      "dsads_rl --> dsads_t\n",
      "dsads_ra --> dsads_t\n",
      "dsads_ll --> dsads_t\n",
      "{'dsads_rl': 0.7572916666666667, 'dsads_ra': 0.5630208333333333, 'dsads_ll': 0.8817708333333333}\n",
      "TARGET- dsads_ra\n",
      "dsads_la_model\n",
      "\n",
      "Weights Loaded-       dsads_la_model\n",
      "Target dataset loaded-     dsads_ra\n",
      "1920\n",
      "dsads_ll_model\n",
      "\n",
      "Weights Loaded-       dsads_ll_model\n",
      "Target dataset loaded-     dsads_ra\n",
      "1920\n",
      "dsads_t_model\n",
      "\n",
      "Weights Loaded-       dsads_t_model\n",
      "Target dataset loaded-     dsads_ra\n",
      "1920\n",
      "{'dsads_la': array([1, 1, 0, ..., 3, 3, 3]), 'dsads_ll': array([2, 1, 0, ..., 3, 3, 3]), 'dsads_t': array([2, 0, 0, ..., 3, 3, 3])}\n",
      "dsads_la --> dsads_ra\n",
      "dsads_ll --> dsads_ra\n",
      "dsads_t --> dsads_ra\n",
      "{'dsads_la': 0.7442708333333333, 'dsads_ll': 0.7979166666666667, 'dsads_t': 0.8484375}\n",
      "TARGET- dsads_la\n",
      "dsads_ra_model\n",
      "\n",
      "Weights Loaded-       dsads_ra_model\n",
      "Target dataset loaded-     dsads_la\n",
      "1920\n",
      "dsads_ll_model\n",
      "\n",
      "Weights Loaded-       dsads_ll_model\n",
      "Target dataset loaded-     dsads_la\n",
      "1920\n",
      "dsads_t_model\n",
      "\n",
      "Weights Loaded-       dsads_t_model\n",
      "Target dataset loaded-     dsads_la\n",
      "1920\n",
      "{'dsads_ra': array([2, 2, 2, ..., 3, 3, 3]), 'dsads_ll': array([2, 2, 2, ..., 3, 3, 3]), 'dsads_t': array([2, 2, 2, ..., 3, 3, 3])}\n",
      "dsads_ra --> dsads_la\n",
      "dsads_ll --> dsads_la\n",
      "dsads_t --> dsads_la\n",
      "{'dsads_ra': 0.7369791666666666, 'dsads_ll': 0.8401041666666667, 'dsads_t': 0.8880208333333334}\n",
      "TARGET- dsads_rl\n",
      "dsads_ll_model\n",
      "\n",
      "Weights Loaded-       dsads_ll_model\n",
      "Target dataset loaded-     dsads_rl\n",
      "1920\n",
      "dsads_t_model\n",
      "\n",
      "Weights Loaded-       dsads_t_model\n",
      "Target dataset loaded-     dsads_rl\n",
      "1920\n",
      "dsads_ra_model\n",
      "\n",
      "Weights Loaded-       dsads_ra_model\n",
      "Target dataset loaded-     dsads_rl\n",
      "1920\n",
      "{'dsads_ll': array([1, 2, 1, ..., 3, 3, 3]), 'dsads_t': array([0, 0, 0, ..., 3, 3, 3]), 'dsads_ra': array([1, 0, 0, ..., 3, 3, 3])}\n",
      "dsads_ll --> dsads_rl\n",
      "dsads_t --> dsads_rl\n",
      "dsads_ra --> dsads_rl\n",
      "{'dsads_ll': 0.8171875, 'dsads_t': 0.9026041666666667, 'dsads_ra': 0.6994791666666667}\n",
      "TARGET- dsads_ll\n",
      "dsads_rl_model\n",
      "\n",
      "Weights Loaded-       dsads_rl_model\n",
      "Target dataset loaded-     dsads_ll\n",
      "1920\n",
      "dsads_ra_model\n",
      "\n",
      "Weights Loaded-       dsads_ra_model\n",
      "Target dataset loaded-     dsads_ll\n",
      "1920\n",
      "dsads_t_model\n",
      "\n",
      "Weights Loaded-       dsads_t_model\n",
      "Target dataset loaded-     dsads_ll\n",
      "1920\n",
      "{'dsads_rl': array([1, 2, 2, ..., 3, 3, 3]), 'dsads_ra': array([1, 0, 1, ..., 3, 3, 3]), 'dsads_t': array([0, 0, 1, ..., 3, 3, 3])}\n",
      "dsads_rl --> dsads_ll\n",
      "dsads_ra --> dsads_ll\n",
      "dsads_t --> dsads_ll\n",
      "{'dsads_rl': 0.7046875, 'dsads_ra': 0.7020833333333333, 'dsads_t': 0.8911458333333333}\n",
      "TARGET- oppo_b\n",
      "oppo_lua_model\n",
      "\n",
      "Weights Loaded-       oppo_lua_model\n",
      "Target dataset loaded-     oppo_b\n",
      "5022\n",
      "oppo_rua_model\n",
      "\n",
      "Weights Loaded-       oppo_rua_model\n",
      "Target dataset loaded-     oppo_b\n",
      "5022\n",
      "oppo_lla_model\n",
      "\n",
      "Weights Loaded-       oppo_lla_model\n",
      "Target dataset loaded-     oppo_b\n",
      "5022\n",
      "{'oppo_lua': array([2, 2, 2, ..., 1, 1, 1]), 'oppo_rua': array([2, 2, 2, ..., 2, 2, 2]), 'oppo_lla': array([2, 2, 2, ..., 0, 1, 0])}\n",
      "oppo_lua --> oppo_b\n",
      "oppo_rua --> oppo_b\n",
      "oppo_lla --> oppo_b\n",
      "{'oppo_lua': 0.913779370768618, 'oppo_rua': 0.6770211071286341, 'oppo_lla': 0.8677817602548785}\n",
      "TARGET- oppo_rua\n",
      "oppo_rla_model\n",
      "\n",
      "Weights Loaded-       oppo_rla_model\n",
      "Target dataset loaded-     oppo_rua\n",
      "5022\n",
      "oppo_lua_model\n",
      "\n",
      "Weights Loaded-       oppo_lua_model\n",
      "Target dataset loaded-     oppo_rua\n",
      "5022\n",
      "oppo_lla_model\n",
      "\n",
      "Weights Loaded-       oppo_lla_model\n",
      "Target dataset loaded-     oppo_rua\n",
      "5022\n",
      "{'oppo_rla': array([2, 2, 2, ..., 2, 1, 2]), 'oppo_lua': array([2, 2, 2, ..., 1, 1, 1]), 'oppo_lla': array([2, 2, 2, ..., 0, 1, 1])}\n",
      "oppo_rla --> oppo_rua\n",
      "oppo_lua --> oppo_rua\n",
      "oppo_lla --> oppo_rua\n",
      "{'oppo_rla': 0.7228195937873357, 'oppo_lua': 0.9257268020708881, 'oppo_lla': 0.869573874950219}\n",
      "TARGET- oppo_rla\n",
      "oppo_rua_model\n",
      "\n",
      "Weights Loaded-       oppo_rua_model\n",
      "Target dataset loaded-     oppo_rla\n",
      "5022\n",
      "oppo_lla_model\n",
      "\n",
      "Weights Loaded-       oppo_lla_model\n",
      "Target dataset loaded-     oppo_rla\n",
      "5022\n",
      "oppo_lua_model\n",
      "\n",
      "Weights Loaded-       oppo_lua_model\n",
      "Target dataset loaded-     oppo_rla\n",
      "5022\n",
      "{'oppo_rua': array([1, 1, 1, ..., 2, 1, 1]), 'oppo_lla': array([1, 1, 1, ..., 1, 1, 1]), 'oppo_lua': array([1, 1, 1, ..., 2, 1, 1])}\n",
      "oppo_rua --> oppo_rla\n",
      "oppo_lla --> oppo_rla\n",
      "oppo_lua --> oppo_rla\n",
      "{'oppo_rua': 0.8405017921146953, 'oppo_lla': 0.7783751493428913, 'oppo_lua': 0.8972520908004779}\n",
      "TARGET- oppo_lua\n",
      "oppo_rua_model\n",
      "\n",
      "Weights Loaded-       oppo_rua_model\n",
      "Target dataset loaded-     oppo_lua\n",
      "5022\n",
      "oppo_lla_model\n",
      "\n",
      "Weights Loaded-       oppo_lla_model\n",
      "Target dataset loaded-     oppo_lua\n",
      "5022\n",
      "oppo_rla_model\n",
      "\n",
      "Weights Loaded-       oppo_rla_model\n",
      "Target dataset loaded-     oppo_lua\n",
      "5022\n",
      "{'oppo_rua': array([2, 2, 2, ..., 1, 2, 2]), 'oppo_lla': array([2, 2, 2, ..., 1, 1, 1]), 'oppo_rla': array([2, 2, 2, ..., 2, 2, 2])}\n",
      "oppo_rua --> oppo_lua\n",
      "oppo_lla --> oppo_lua\n",
      "oppo_rla --> oppo_lua\n",
      "{'oppo_rua': 0.9368777379530068, 'oppo_lla': 0.8311429709279171, 'oppo_rla': 0.7289924332935086}\n",
      "TARGET- oppo_lla\n",
      "oppo_lua_model\n",
      "\n",
      "Weights Loaded-       oppo_lua_model\n",
      "Target dataset loaded-     oppo_lla\n",
      "5022\n",
      "oppo_rua_model\n",
      "\n",
      "Weights Loaded-       oppo_rua_model\n",
      "Target dataset loaded-     oppo_lla\n",
      "5022\n",
      "oppo_rla_model\n",
      "\n",
      "Weights Loaded-       oppo_rla_model\n",
      "Target dataset loaded-     oppo_lla\n",
      "5022\n",
      "{'oppo_lua': array([2, 2, 2, ..., 1, 1, 0]), 'oppo_rua': array([2, 2, 2, ..., 1, 1, 1]), 'oppo_rla': array([2, 2, 2, ..., 2, 2, 2])}\n",
      "oppo_lua --> oppo_lla\n",
      "oppo_rua --> oppo_lla\n",
      "oppo_rla --> oppo_lla\n",
      "{'oppo_lua': 0.9277180406212664, 'oppo_rua': 0.9382716049382716, 'oppo_rla': 0.8092393468737554}\n",
      "TARGET- pamap_w\n",
      "pamap_c_model\n",
      "\n",
      "Weights Loaded-       pamap_c_model\n",
      "Target dataset loaded-     pamap_w\n",
      "3063\n",
      "pamap_a_model\n",
      "\n",
      "Weights Loaded-       pamap_a_model\n",
      "Target dataset loaded-     pamap_w\n",
      "3063\n",
      "oppo_lla_model\n",
      "\n",
      "Weights Loaded-       oppo_lla_model\n",
      "Target dataset loaded-     pamap_w\n",
      "3063\n",
      "{'pamap_c': array([0, 0, 0, ..., 0, 0, 0]), 'pamap_a': array([3, 3, 0, ..., 0, 3, 3]), 'oppo_lla': array([2, 2, 1, ..., 2, 2, 2])}\n",
      "pamap_c --> pamap_w\n",
      "pamap_a --> pamap_w\n",
      "oppo_lla --> pamap_w\n",
      "{'pamap_c': 0.782239634345413, 'pamap_a': 0.8047665687234737, 'oppo_lla': 0.22494286647078027}\n",
      "TARGET- pamap_c\n",
      "pamap_w_model\n",
      "\n",
      "Weights Loaded-       pamap_w_model\n",
      "Target dataset loaded-     pamap_c\n",
      "3063\n",
      "pamap_a_model\n",
      "\n",
      "Weights Loaded-       pamap_a_model\n",
      "Target dataset loaded-     pamap_c\n",
      "3063\n",
      "oppo_lla_model\n",
      "\n",
      "Weights Loaded-       oppo_lla_model\n",
      "Target dataset loaded-     pamap_c\n",
      "3063\n",
      "{'pamap_w': array([1, 1, 1, ..., 0, 0, 1]), 'pamap_a': array([1, 1, 0, ..., 3, 2, 1]), 'oppo_lla': array([2, 0, 0, ..., 2, 2, 2])}\n",
      "pamap_w --> pamap_c\n",
      "pamap_a --> pamap_c\n",
      "oppo_lla --> pamap_c\n",
      "{'pamap_w': 0.8246816846229187, 'pamap_a': 0.4884100555011427, 'oppo_lla': 0.40417890956578517}\n",
      "TARGET- pamap_a\n",
      "pamap_c_model\n",
      "\n",
      "Weights Loaded-       pamap_c_model\n",
      "Target dataset loaded-     pamap_a\n",
      "3063\n",
      "pamap_w_model\n",
      "\n",
      "Weights Loaded-       pamap_w_model\n",
      "Target dataset loaded-     pamap_a\n",
      "3063\n",
      "oppo_lla_model\n",
      "\n",
      "Weights Loaded-       oppo_lla_model\n",
      "Target dataset loaded-     pamap_a\n",
      "3063\n",
      "{'pamap_c': array([2, 2, 3, ..., 0, 0, 0]), 'pamap_w': array([1, 1, 1, ..., 0, 1, 1]), 'oppo_lla': array([0, 0, 2, ..., 3, 1, 1])}\n",
      "pamap_c --> pamap_a\n",
      "pamap_w --> pamap_a\n",
      "oppo_lla --> pamap_a\n",
      "{'pamap_c': 0.6255305256284688, 'pamap_w': 0.7685275873326803, 'oppo_lla': 0.4583741429970617}\n",
      "{'dsads_t': {'dsads_rl': 0.7572916666666667, 'dsads_ra': 0.5630208333333333, 'dsads_ll': 0.8817708333333333}, 'dsads_ra': {'dsads_la': 0.7442708333333333, 'dsads_ll': 0.7979166666666667, 'dsads_t': 0.8484375}, 'dsads_la': {'dsads_ra': 0.7369791666666666, 'dsads_ll': 0.8401041666666667, 'dsads_t': 0.8880208333333334}, 'dsads_rl': {'dsads_ll': 0.8171875, 'dsads_t': 0.9026041666666667, 'dsads_ra': 0.6994791666666667}, 'dsads_ll': {'dsads_rl': 0.7046875, 'dsads_ra': 0.7020833333333333, 'dsads_t': 0.8911458333333333}, 'oppo_b': {'oppo_lua': 0.913779370768618, 'oppo_rua': 0.6770211071286341, 'oppo_lla': 0.8677817602548785}, 'oppo_rua': {'oppo_rla': 0.7228195937873357, 'oppo_lua': 0.9257268020708881, 'oppo_lla': 0.869573874950219}, 'oppo_rla': {'oppo_rua': 0.8405017921146953, 'oppo_lla': 0.7783751493428913, 'oppo_lua': 0.8972520908004779}, 'oppo_lua': {'oppo_rua': 0.9368777379530068, 'oppo_lla': 0.8311429709279171, 'oppo_rla': 0.7289924332935086}, 'oppo_lla': {'oppo_lua': 0.9277180406212664, 'oppo_rua': 0.9382716049382716, 'oppo_rla': 0.8092393468737554}, 'pamap_w': {'pamap_c': 0.782239634345413, 'pamap_a': 0.8047665687234737, 'oppo_lla': 0.22494286647078027}, 'pamap_c': {'pamap_w': 0.8246816846229187, 'pamap_a': 0.4884100555011427, 'oppo_lla': 0.40417890956578517}, 'pamap_a': {'pamap_c': 0.6255305256284688, 'pamap_w': 0.7685275873326803, 'oppo_lla': 0.4583741429970617}}\n",
      "TARGET- dsads_t\n",
      "oppo_b_model\n",
      "\n",
      "Weights Loaded-       oppo_b_model\n",
      "Target dataset loaded-     dsads_t\n",
      "1920\n",
      "pamap_c_model\n",
      "\n",
      "Weights Loaded-       pamap_c_model\n",
      "Target dataset loaded-     dsads_t\n",
      "1920\n",
      "oppo_rua_model\n",
      "\n",
      "Weights Loaded-       oppo_rua_model\n",
      "Target dataset loaded-     dsads_t\n",
      "1920\n",
      "{'oppo_b': array([0, 0, 0, ..., 0, 0, 0]), 'pamap_c': array([3, 3, 3, ..., 3, 3, 3]), 'oppo_rua': array([3, 3, 3, ..., 3, 3, 3])}\n",
      "oppo_b --> dsads_t\n",
      "pamap_c --> dsads_t\n",
      "oppo_rua --> dsads_t\n",
      "{'oppo_b': 0.19010416666666666, 'pamap_c': 0.8234375, 'oppo_rua': 0.9760416666666667}\n",
      "TARGET- dsads_ra\n",
      "oppo_b_model\n",
      "\n",
      "Weights Loaded-       oppo_b_model\n",
      "Target dataset loaded-     dsads_ra\n",
      "1920\n",
      "pamap_c_model\n",
      "\n",
      "Weights Loaded-       pamap_c_model\n",
      "Target dataset loaded-     dsads_ra\n",
      "1920\n",
      "oppo_rua_model\n",
      "\n",
      "Weights Loaded-       oppo_rua_model\n",
      "Target dataset loaded-     dsads_ra\n",
      "1920\n",
      "{'oppo_b': array([0, 0, 0, ..., 0, 3, 0]), 'pamap_c': array([3, 3, 3, ..., 3, 3, 3]), 'oppo_rua': array([3, 3, 0, ..., 3, 3, 3])}\n",
      "oppo_b --> dsads_ra\n",
      "pamap_c --> dsads_ra\n",
      "oppo_rua --> dsads_ra\n",
      "{'oppo_b': 0.37395833333333334, 'pamap_c': 0.6869791666666667, 'oppo_rua': 0.9666666666666667}\n",
      "TARGET- dsads_la\n",
      "oppo_b_model\n",
      "\n",
      "Weights Loaded-       oppo_b_model\n",
      "Target dataset loaded-     dsads_la\n",
      "1920\n",
      "pamap_c_model\n",
      "\n",
      "Weights Loaded-       pamap_c_model\n",
      "Target dataset loaded-     dsads_la\n",
      "1920\n",
      "oppo_rua_model\n",
      "\n",
      "Weights Loaded-       oppo_rua_model\n",
      "Target dataset loaded-     dsads_la\n",
      "1920\n",
      "{'oppo_b': array([0, 0, 0, ..., 0, 3, 3]), 'pamap_c': array([1, 1, 1, ..., 3, 0, 3]), 'oppo_rua': array([3, 3, 3, ..., 3, 3, 3])}\n",
      "oppo_b --> dsads_la\n",
      "pamap_c --> dsads_la\n",
      "oppo_rua --> dsads_la\n",
      "{'oppo_b': 0.6005208333333333, 'pamap_c': 0.5213541666666667, 'oppo_rua': 0.7427083333333333}\n",
      "TARGET- dsads_rl\n",
      "oppo_b_model\n",
      "\n",
      "Weights Loaded-       oppo_b_model\n",
      "Target dataset loaded-     dsads_rl\n",
      "1920\n",
      "pamap_c_model\n",
      "\n",
      "Weights Loaded-       pamap_c_model\n",
      "Target dataset loaded-     dsads_rl\n",
      "1920\n",
      "oppo_rua_model\n",
      "\n",
      "Weights Loaded-       oppo_rua_model\n",
      "Target dataset loaded-     dsads_rl\n",
      "1920\n",
      "{'oppo_b': array([0, 0, 0, ..., 0, 0, 0]), 'pamap_c': array([3, 3, 3, ..., 3, 3, 3]), 'oppo_rua': array([3, 3, 0, ..., 2, 3, 3])}\n",
      "oppo_b --> dsads_rl\n",
      "pamap_c --> dsads_rl\n",
      "oppo_rua --> dsads_rl\n",
      "{'oppo_b': 0.3703125, 'pamap_c': 0.7161458333333334, 'oppo_rua': 0.9885416666666667}\n",
      "TARGET- dsads_ll\n",
      "oppo_b_model\n",
      "\n",
      "Weights Loaded-       oppo_b_model\n",
      "Target dataset loaded-     dsads_ll\n",
      "1920\n",
      "pamap_c_model\n",
      "\n",
      "Weights Loaded-       pamap_c_model\n",
      "Target dataset loaded-     dsads_ll\n",
      "1920\n",
      "oppo_rua_model\n",
      "\n",
      "Weights Loaded-       oppo_rua_model\n",
      "Target dataset loaded-     dsads_ll\n",
      "1920\n",
      "{'oppo_b': array([0, 0, 0, ..., 0, 3, 0]), 'pamap_c': array([3, 3, 3, ..., 3, 3, 3]), 'oppo_rua': array([0, 0, 3, ..., 3, 3, 2])}\n",
      "oppo_b --> dsads_ll\n",
      "pamap_c --> dsads_ll\n",
      "oppo_rua --> dsads_ll\n",
      "{'oppo_b': 0.4322916666666667, 'pamap_c': 0.6161458333333333, 'oppo_rua': 0.9692708333333333}\n",
      "TARGET- oppo_b\n",
      "pamap_c_model\n",
      "\n",
      "Weights Loaded-       pamap_c_model\n",
      "Target dataset loaded-     oppo_b\n",
      "5022\n",
      "oppo_rua_model\n",
      "\n",
      "Weights Loaded-       oppo_rua_model\n",
      "Target dataset loaded-     oppo_b\n",
      "5022\n",
      "oppo_lua_model\n",
      "\n",
      "Weights Loaded-       oppo_lua_model\n",
      "Target dataset loaded-     oppo_b\n",
      "5022\n",
      "{'pamap_c': array([1, 1, 1, ..., 1, 1, 1]), 'oppo_rua': array([2, 2, 2, ..., 2, 2, 2]), 'oppo_lua': array([2, 2, 2, ..., 1, 1, 1])}\n",
      "pamap_c --> oppo_b\n",
      "oppo_rua --> oppo_b\n",
      "oppo_lua --> oppo_b\n",
      "{'pamap_c': 0.49143767423337315, 'oppo_rua': 0.6981282357626444, 'oppo_lua': 0.9163679808841099}\n",
      "TARGET- oppo_rua\n",
      "oppo_b_model\n",
      "\n",
      "Weights Loaded-       oppo_b_model\n",
      "Target dataset loaded-     oppo_rua\n",
      "5022\n",
      "pamap_c_model\n",
      "\n",
      "Weights Loaded-       pamap_c_model\n",
      "Target dataset loaded-     oppo_rua\n",
      "5022\n",
      "oppo_lua_model\n",
      "\n",
      "Weights Loaded-       oppo_lua_model\n",
      "Target dataset loaded-     oppo_rua\n",
      "5022\n",
      "{'oppo_b': array([2, 2, 2, ..., 2, 2, 2]), 'pamap_c': array([0, 0, 1, ..., 0, 1, 1]), 'oppo_lua': array([2, 2, 2, ..., 1, 1, 1])}\n",
      "oppo_b --> oppo_rua\n",
      "pamap_c --> oppo_rua\n",
      "oppo_lua --> oppo_rua\n",
      "{'oppo_b': 0.8293508562325766, 'pamap_c': 0.47829549980087616, 'oppo_lua': 0.6929510155316607}\n",
      "TARGET- oppo_rla\n",
      "oppo_b_model\n",
      "\n",
      "Weights Loaded-       oppo_b_model\n",
      "Target dataset loaded-     oppo_rla\n",
      "5022\n",
      "pamap_c_model\n",
      "\n",
      "Weights Loaded-       pamap_c_model\n",
      "Target dataset loaded-     oppo_rla\n",
      "5022\n",
      "oppo_rua_model\n",
      "\n",
      "Weights Loaded-       oppo_rua_model\n",
      "Target dataset loaded-     oppo_rla\n",
      "5022\n",
      "{'oppo_b': array([2, 2, 2, ..., 2, 2, 2]), 'pamap_c': array([0, 0, 0, ..., 3, 0, 0]), 'oppo_rua': array([1, 1, 1, ..., 2, 1, 1])}\n",
      "oppo_b --> oppo_rla\n",
      "pamap_c --> oppo_rla\n",
      "oppo_rua --> oppo_rla\n",
      "{'oppo_b': 0.6385902031063322, 'pamap_c': 0.5702907208283552, 'oppo_rua': 0.5300677021107129}\n",
      "TARGET- oppo_lua\n",
      "oppo_b_model\n",
      "\n",
      "Weights Loaded-       oppo_b_model\n",
      "Target dataset loaded-     oppo_lua\n",
      "5022\n",
      "pamap_c_model\n",
      "\n",
      "Weights Loaded-       pamap_c_model\n",
      "Target dataset loaded-     oppo_lua\n",
      "5022\n",
      "oppo_rua_model\n",
      "\n",
      "Weights Loaded-       oppo_rua_model\n",
      "Target dataset loaded-     oppo_lua\n",
      "5022\n",
      "{'oppo_b': array([2, 2, 2, ..., 2, 2, 2]), 'pamap_c': array([1, 1, 1, ..., 2, 1, 1]), 'oppo_rua': array([2, 2, 2, ..., 1, 2, 2])}\n",
      "oppo_b --> oppo_lua\n",
      "pamap_c --> oppo_lua\n",
      "oppo_rua --> oppo_lua\n",
      "{'oppo_b': 0.8269613699721227, 'pamap_c': 0.4026284348864994, 'oppo_rua': 0.8080446037435285}\n",
      "TARGET- oppo_lla\n",
      "oppo_b_model\n",
      "\n",
      "Weights Loaded-       oppo_b_model\n",
      "Target dataset loaded-     oppo_lla\n",
      "5022\n",
      "pamap_c_model\n",
      "\n",
      "Weights Loaded-       pamap_c_model\n",
      "Target dataset loaded-     oppo_lla\n",
      "5022\n",
      "oppo_rua_model\n",
      "\n",
      "Weights Loaded-       oppo_rua_model\n",
      "Target dataset loaded-     oppo_lla\n",
      "5022\n",
      "{'oppo_b': array([2, 2, 2, ..., 2, 2, 2]), 'pamap_c': array([0, 1, 0, ..., 2, 2, 2]), 'oppo_rua': array([2, 2, 2, ..., 1, 1, 1])}\n",
      "oppo_b --> oppo_lla\n",
      "pamap_c --> oppo_lla\n",
      "oppo_rua --> oppo_lla\n",
      "{'oppo_b': 0.7875348466746316, 'pamap_c': 0.35185185185185186, 'oppo_rua': 0.7522899243329351}\n",
      "TARGET- pamap_w\n",
      "oppo_b_model\n",
      "\n",
      "Weights Loaded-       oppo_b_model\n",
      "Target dataset loaded-     pamap_w\n",
      "3063\n",
      "pamap_c_model\n",
      "\n",
      "Weights Loaded-       pamap_c_model\n",
      "Target dataset loaded-     pamap_w\n",
      "3063\n",
      "oppo_rua_model\n",
      "\n",
      "Weights Loaded-       oppo_rua_model\n",
      "Target dataset loaded-     pamap_w\n",
      "3063\n",
      "{'oppo_b': array([2, 2, 2, ..., 2, 2, 2]), 'pamap_c': array([0, 0, 0, ..., 0, 0, 0]), 'oppo_rua': array([2, 2, 2, ..., 2, 2, 2])}\n",
      "oppo_b --> pamap_w\n",
      "pamap_c --> pamap_w\n",
      "oppo_rua --> pamap_w\n",
      "{'oppo_b': 0.9977146588312112, 'pamap_c': 0.06594841658504734, 'oppo_rua': 0.9977146588312112}\n",
      "TARGET- pamap_c\n",
      "oppo_b_model\n",
      "\n",
      "Weights Loaded-       oppo_b_model\n",
      "Target dataset loaded-     pamap_c\n",
      "3063\n",
      "oppo_rua_model\n",
      "\n",
      "Weights Loaded-       oppo_rua_model\n",
      "Target dataset loaded-     pamap_c\n",
      "3063\n",
      "oppo_lua_model\n",
      "\n",
      "Weights Loaded-       oppo_lua_model\n",
      "Target dataset loaded-     pamap_c\n",
      "3063\n",
      "{'oppo_b': array([0, 0, 0, ..., 2, 2, 2]), 'oppo_rua': array([2, 0, 2, ..., 2, 2, 2]), 'oppo_lua': array([2, 0, 2, ..., 2, 2, 2])}\n",
      "oppo_b --> pamap_c\n",
      "oppo_rua --> pamap_c\n",
      "oppo_lua --> pamap_c\n",
      "{'oppo_b': 0.9138099902056807, 'oppo_rua': 0.8857329415605616, 'oppo_lua': 0.9317662422461639}\n",
      "TARGET- pamap_a\n",
      "oppo_b_model\n",
      "\n",
      "Weights Loaded-       oppo_b_model\n",
      "Target dataset loaded-     pamap_a\n",
      "3063\n",
      "pamap_c_model\n",
      "\n",
      "Weights Loaded-       pamap_c_model\n",
      "Target dataset loaded-     pamap_a\n",
      "3063\n",
      "oppo_rua_model\n",
      "\n",
      "Weights Loaded-       oppo_rua_model\n",
      "Target dataset loaded-     pamap_a\n",
      "3063\n",
      "{'oppo_b': array([1, 1, 1, ..., 2, 2, 2]), 'pamap_c': array([2, 2, 3, ..., 0, 0, 0]), 'oppo_rua': array([0, 0, 2, ..., 2, 2, 2])}\n",
      "oppo_b --> pamap_a\n",
      "pamap_c --> pamap_a\n",
      "oppo_rua --> pamap_a\n",
      "{'oppo_b': 0.8426379366634019, 'pamap_c': 0.33006856023506365, 'oppo_rua': 0.8462291870714985}\n",
      "{'dsads_t': {'oppo_b': 0.19010416666666666, 'pamap_c': 0.8234375, 'oppo_rua': 0.9760416666666667}, 'dsads_ra': {'oppo_b': 0.37395833333333334, 'pamap_c': 0.6869791666666667, 'oppo_rua': 0.9666666666666667}, 'dsads_la': {'oppo_b': 0.6005208333333333, 'pamap_c': 0.5213541666666667, 'oppo_rua': 0.7427083333333333}, 'dsads_rl': {'oppo_b': 0.3703125, 'pamap_c': 0.7161458333333334, 'oppo_rua': 0.9885416666666667}, 'dsads_ll': {'oppo_b': 0.4322916666666667, 'pamap_c': 0.6161458333333333, 'oppo_rua': 0.9692708333333333}, 'oppo_b': {'pamap_c': 0.49143767423337315, 'oppo_rua': 0.6981282357626444, 'oppo_lua': 0.9163679808841099}, 'oppo_rua': {'oppo_b': 0.8293508562325766, 'pamap_c': 0.47829549980087616, 'oppo_lua': 0.6929510155316607}, 'oppo_rla': {'oppo_b': 0.6385902031063322, 'pamap_c': 0.5702907208283552, 'oppo_rua': 0.5300677021107129}, 'oppo_lua': {'oppo_b': 0.8269613699721227, 'pamap_c': 0.4026284348864994, 'oppo_rua': 0.8080446037435285}, 'oppo_lla': {'oppo_b': 0.7875348466746316, 'pamap_c': 0.35185185185185186, 'oppo_rua': 0.7522899243329351}, 'pamap_w': {'oppo_b': 0.9977146588312112, 'pamap_c': 0.06594841658504734, 'oppo_rua': 0.9977146588312112}, 'pamap_c': {'oppo_b': 0.9138099902056807, 'oppo_rua': 0.8857329415605616, 'oppo_lua': 0.9317662422461639}, 'pamap_a': {'oppo_b': 0.8426379366634019, 'pamap_c': 0.33006856023506365, 'oppo_rua': 0.8462291870714985}}\n",
      "----##----\n",
      "{'jsd': {'dsads_t': {'dsads_ll': 0.8817708333333333, 'dsads_ra': 0.5630208333333333, 'dsads_rl': 0.7572916666666667}, 'dsads_ra': {'dsads_la': 0.7223958333333333, 'dsads_ll': 0.834375, 'dsads_rl': 0.8276041666666667}, 'dsads_la': {'dsads_ra': 0.740625, 'dsads_ll': 0.8479166666666667, 'dsads_rl': 0.83125}, 'dsads_rl': {'dsads_ll': 0.6020833333333333, 'dsads_ra': 0.9359375, 'dsads_la': 0.8583333333333333}, 'dsads_ll': {'dsads_rl': 0.5708333333333333, 'dsads_ra': 0.8734375, 'dsads_la': 0.9432291666666667}, 'oppo_b': {'oppo_lua': 0.6979291119076065, 'oppo_rua': 0.9297092791716448, 'oppo_rla': 0.84926324173636}, 'oppo_rua': {'oppo_lua': 0.9257268020708881, 'oppo_rla': 0.7228195937873357, 'oppo_lla': 0.869573874950219}, 'oppo_rla': {'oppo_lua': 0.8972520908004779, 'oppo_rua': 0.8405017921146953, 'oppo_lla': 0.7783751493428913}, 'oppo_lua': {'oppo_rla': 0.7289924332935086, 'oppo_rua': 0.9368777379530068, 'oppo_lla': 0.8311429709279171}, 'oppo_lla': {'oppo_rua': 0.9382716049382716, 'oppo_lua': 0.9277180406212664, 'oppo_rla': 0.8092393468737554}, 'pamap_w': {'pamap_c': 0.8021547502448579, 'pamap_a': 0.7064968984655566, 'dsads_la': 0.13091740124061377}, 'pamap_c': {'pamap_w': 0.7368592882794646, 'pamap_a': 0.41821743388834476, 'dsads_la': 0.25824355207313093}, 'pamap_a': {'pamap_w': 0.6353248449232778, 'pamap_c': 0.6565458700620307, 'dsads_la': 0.32517140058765914}}, 'Adaptivity': {'dsads_t': {'oppo_lua': 0.7328125, 'oppo_lla': 0.9802083333333333, 'oppo_rua': 0.7770833333333333}, 'dsads_ra': {'oppo_lua': 0.8526041666666667, 'oppo_lla': 0.9901041666666667, 'oppo_rua': 0.765625}, 'dsads_la': {'oppo_lua': 0.9651041666666667, 'oppo_lla': 0.8578125, 'oppo_rla': 0.646875}, 'dsads_rl': {'oppo_lua': 0.7557291666666667, 'oppo_lla': 0.9713541666666666, 'oppo_rua': 0.8901041666666667}, 'dsads_ll': {'oppo_lua': 0.8505208333333333, 'oppo_lla': 0.9854166666666667, 'oppo_rua': 0.8369791666666667}, 'oppo_b': {'oppo_lua': 0.913779370768618, 'oppo_lla': 0.8677817602548785, 'oppo_rua': 0.6770211071286341}, 'oppo_rua': {'oppo_lua': 0.9257268020708881, 'oppo_lla': 0.869573874950219, 'oppo_rla': 0.7228195937873357}, 'oppo_rla': {'oppo_rua': 0.8405017921146953, 'oppo_lua': 0.8972520908004779, 'oppo_lla': 0.7783751493428913}, 'oppo_lua': {'oppo_rua': 0.9516129032258065, 'oppo_lla': 0.815810434090004, 'oppo_b': 0.743926722421346}, 'oppo_lla': {'oppo_lua': 0.9277180406212664, 'oppo_rua': 0.9382716049382716, 'oppo_rla': 0.8092393468737554}, 'pamap_w': {'oppo_b': 0.9986940907606922, 'oppo_rua': 0.9986940907606922, 'oppo_lua': 0.999347045380346}, 'pamap_c': {'oppo_rua': 0.9128305582761999, 'oppo_b': 0.8841005550114267, 'oppo_lla': 0.6196539340515834}, 'pamap_a': {'oppo_b': 0.9562520404831865, 'oppo_lua': 0.8570029382957884, 'oppo_rua': 0.8723473718576559}}, 'l2d': {'dsads_t': {'dsads_rl': 0.7572916666666667, 'dsads_ra': 0.5630208333333333, 'dsads_ll': 0.8817708333333333}, 'dsads_ra': {'dsads_la': 0.7442708333333333, 'dsads_ll': 0.7979166666666667, 'dsads_t': 0.8484375}, 'dsads_la': {'dsads_ra': 0.7369791666666666, 'dsads_ll': 0.8401041666666667, 'dsads_t': 0.8880208333333334}, 'dsads_rl': {'dsads_ll': 0.8171875, 'dsads_t': 0.9026041666666667, 'dsads_ra': 0.6994791666666667}, 'dsads_ll': {'dsads_rl': 0.7046875, 'dsads_ra': 0.7020833333333333, 'dsads_t': 0.8911458333333333}, 'oppo_b': {'oppo_lua': 0.913779370768618, 'oppo_rua': 0.6770211071286341, 'oppo_lla': 0.8677817602548785}, 'oppo_rua': {'oppo_rla': 0.7228195937873357, 'oppo_lua': 0.9257268020708881, 'oppo_lla': 0.869573874950219}, 'oppo_rla': {'oppo_rua': 0.8405017921146953, 'oppo_lla': 0.7783751493428913, 'oppo_lua': 0.8972520908004779}, 'oppo_lua': {'oppo_rua': 0.9368777379530068, 'oppo_lla': 0.8311429709279171, 'oppo_rla': 0.7289924332935086}, 'oppo_lla': {'oppo_lua': 0.9277180406212664, 'oppo_rua': 0.9382716049382716, 'oppo_rla': 0.8092393468737554}, 'pamap_w': {'pamap_c': 0.782239634345413, 'pamap_a': 0.8047665687234737, 'oppo_lla': 0.22494286647078027}, 'pamap_c': {'pamap_w': 0.8246816846229187, 'pamap_a': 0.4884100555011427, 'oppo_lla': 0.40417890956578517}, 'pamap_a': {'pamap_c': 0.6255305256284688, 'pamap_w': 0.7685275873326803, 'oppo_lla': 0.4583741429970617}}, 'Source Accuracy': {'dsads_t': {'oppo_b': 0.19010416666666666, 'pamap_c': 0.8234375, 'oppo_rua': 0.9760416666666667}, 'dsads_ra': {'oppo_b': 0.37395833333333334, 'pamap_c': 0.6869791666666667, 'oppo_rua': 0.9666666666666667}, 'dsads_la': {'oppo_b': 0.6005208333333333, 'pamap_c': 0.5213541666666667, 'oppo_rua': 0.7427083333333333}, 'dsads_rl': {'oppo_b': 0.3703125, 'pamap_c': 0.7161458333333334, 'oppo_rua': 0.9885416666666667}, 'dsads_ll': {'oppo_b': 0.4322916666666667, 'pamap_c': 0.6161458333333333, 'oppo_rua': 0.9692708333333333}, 'oppo_b': {'pamap_c': 0.49143767423337315, 'oppo_rua': 0.6981282357626444, 'oppo_lua': 0.9163679808841099}, 'oppo_rua': {'oppo_b': 0.8293508562325766, 'pamap_c': 0.47829549980087616, 'oppo_lua': 0.6929510155316607}, 'oppo_rla': {'oppo_b': 0.6385902031063322, 'pamap_c': 0.5702907208283552, 'oppo_rua': 0.5300677021107129}, 'oppo_lua': {'oppo_b': 0.8269613699721227, 'pamap_c': 0.4026284348864994, 'oppo_rua': 0.8080446037435285}, 'oppo_lla': {'oppo_b': 0.7875348466746316, 'pamap_c': 0.35185185185185186, 'oppo_rua': 0.7522899243329351}, 'pamap_w': {'oppo_b': 0.9977146588312112, 'pamap_c': 0.06594841658504734, 'oppo_rua': 0.9977146588312112}, 'pamap_c': {'oppo_b': 0.9138099902056807, 'oppo_rua': 0.8857329415605616, 'oppo_lua': 0.9317662422461639}, 'pamap_a': {'oppo_b': 0.8426379366634019, 'pamap_c': 0.33006856023506365, 'oppo_rua': 0.8462291870714985}}}\n"
     ]
    }
   ],
   "source": [
    "metrics=['jsd','Adaptivity','l2d','Source Accuracy']\n",
    "metric_dic={}\n",
    "for m in metrics:\n",
    "    temp_df=[]\n",
    "#     print(\"--------\")\n",
    "    target_dict_max_voting={}\n",
    "    for target in datasets:\n",
    "        \n",
    "        temp_df = result_df[result_df['Target']==target][['Source','Target',m]]\n",
    "        if m=='Adaptivity' or m=='Source Accuracy':\n",
    "            temp_df= temp_df.nlargest(3, m)\n",
    "        else:\n",
    "            temp_df= temp_df.nsmallest(3, m)\n",
    "        print(\"TARGET-\",target)\n",
    "#         print(temp_df)\n",
    "        dict_predict_curr={}\n",
    "        for src in temp_df['Source'].values:\n",
    "            # Model Save\n",
    "#             print(\"src\")\n",
    "#             print(src)\n",
    "            file_name = src+\"_model\"\n",
    "            print(file_name)\n",
    "            if file_name in arr_cache_trained_model: # model is already saved\n",
    "                model_src=tf.keras.models.load_model(file_name)\n",
    "                print(\"\")\n",
    "                print(\"Weights Loaded-      \",file_name)\n",
    "            print(\"Target dataset loaded-    \",target)\n",
    "            x_train_target = ar_data[target]\n",
    "            y_pred = model_src.predict(x_train_target) \n",
    "#             print(\"y_pred--->\",y_pred)\n",
    "            output_pred = np.argmax(y_pred, axis=1)\n",
    "#             print(\"output_pred--->\",output_pred)\n",
    "            dict_predict_curr[src]=output_pred\n",
    "            print(len(output_pred))\n",
    "        print(dict_predict_curr)\n",
    "        \n",
    "#         {'dsads_rl': array([2, 2, 2, ..., 3, 0, 3]), 'pamap_a': array([1, 1, 1, ..., 3, 3, 3]), 'oppo_rua': array([3, 3, 3, ..., 3, 3, 3])}\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        sum_arr=[]\n",
    "        for val in range(len(output_pred)):\n",
    "            arr_max_voting_freq=[]\n",
    "            for model_ in dict_predict_curr:\n",
    "                arr_max_voting_freq.append(dict_predict_curr[model_][val])\n",
    "            sum_arr.append(np.bincount(arr_max_voting_freq).argmax())    \n",
    "        max_voted_arr = sum_arr\n",
    "#         print(\"vote freq arr-\", max_voted_arr)\n",
    "        max_voted_model={}\n",
    "        for source_model in dict_predict_curr:\n",
    "            print(source_model,\"-->\",target)\n",
    "            for i,val in enumerate(dict_predict_curr[source_model]):\n",
    "                if max_voted_arr[i]==val:\n",
    "                    if source_model in max_voted_model:\n",
    "                        max_voted_model[source_model]+=1\n",
    "                    else:\n",
    "                        max_voted_model[source_model]=1\n",
    "            max_voted_model[source_model]=max_voted_model[source_model]/len(output_pred)\n",
    "        print(max_voted_model)\n",
    "        \n",
    "        ####\n",
    "        # creating target dict\n",
    "        target_dict_max_voting[target]=max_voted_model\n",
    "    print(target_dict_max_voting)\n",
    "    metric_dic[m]=target_dict_max_voting\n",
    "print(\"----##----\")\n",
    "print(metric_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f821e41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T19:02:39.627586Z",
     "iopub.status.busy": "2022-04-12T19:02:39.627019Z",
     "iopub.status.idle": "2022-04-12T19:02:39.731868Z",
     "shell.execute_reply": "2022-04-12T19:02:39.731444Z"
    },
    "papermill": {
     "duration": 0.876739,
     "end_time": "2022-04-12T19:02:39.732007",
     "exception": false,
     "start_time": "2022-04-12T19:02:38.855268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "df=result_df\n",
    "\n",
    "for metric in metric_dic:\n",
    "    for target in metric_dic[str(metric)]:\n",
    "        for source in metric_dic[str(metric)][str(target)]:\n",
    "            index = df.index[(df[\"Source\"] == str(source)) & (df[\"Target\"] == str(target))]\n",
    "            df.loc[index[0], 'max_voting_'+metric+\"_%\"] = (metric_dic[str(metric)][str(target)][str(source)])*100\n",
    "\n",
    "df.to_csv('Max_Voting_Activity_Recognition_Result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04483195",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T19:02:41.315069Z",
     "iopub.status.busy": "2022-04-12T19:02:41.250776Z",
     "iopub.status.idle": "2022-04-12T19:02:41.328356Z",
     "shell.execute_reply": "2022-04-12T19:02:41.328841Z"
    },
    "papermill": {
     "duration": 0.8256,
     "end_time": "2022-04-12T19:02:41.329019",
     "exception": false,
     "start_time": "2022-04-12T19:02:40.503419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>l2d</th>\n",
       "      <th>jsd</th>\n",
       "      <th>Adaptivity</th>\n",
       "      <th>Source Accuracy</th>\n",
       "      <th>serving</th>\n",
       "      <th>finetune</th>\n",
       "      <th>max_voting_jsd_%</th>\n",
       "      <th>max_voting_Adaptivity_%</th>\n",
       "      <th>max_voting_l2d_%</th>\n",
       "      <th>max_voting_Source Accuracy_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>pamap_c</td>\n",
       "      <td>pamap_w</td>\n",
       "      <td>0.622451</td>\n",
       "      <td>0.005972</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.898858</td>\n",
       "      <td>0.530804</td>\n",
       "      <td>0.734394</td>\n",
       "      <td>80.215475</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.223963</td>\n",
       "      <td>6.594842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>pamap_a</td>\n",
       "      <td>pamap_w</td>\n",
       "      <td>0.743870</td>\n",
       "      <td>0.014660</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.722675</td>\n",
       "      <td>0.477356</td>\n",
       "      <td>0.729498</td>\n",
       "      <td>70.649690</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.476657</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>pamap_w</td>\n",
       "      <td>1.729038</td>\n",
       "      <td>0.044448</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.337005</td>\n",
       "      <td>0.649939</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>pamap_w</td>\n",
       "      <td>1.791822</td>\n",
       "      <td>0.048892</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.643229</td>\n",
       "      <td>0.241126</td>\n",
       "      <td>0.714810</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dsads_t</td>\n",
       "      <td>pamap_w</td>\n",
       "      <td>1.713112</td>\n",
       "      <td>0.041491</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.238678</td>\n",
       "      <td>0.692370</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>pamap_w</td>\n",
       "      <td>1.578720</td>\n",
       "      <td>0.032859</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.747396</td>\n",
       "      <td>0.234598</td>\n",
       "      <td>0.692370</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>oppo_b</td>\n",
       "      <td>pamap_w</td>\n",
       "      <td>1.384871</td>\n",
       "      <td>0.041871</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.234598</td>\n",
       "      <td>0.760914</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.869409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.771466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>pamap_w</td>\n",
       "      <td>1.251849</td>\n",
       "      <td>0.052333</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.897512</td>\n",
       "      <td>0.234598</td>\n",
       "      <td>0.753978</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.869409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.771466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>pamap_w</td>\n",
       "      <td>1.277806</td>\n",
       "      <td>0.051026</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.884577</td>\n",
       "      <td>0.234598</td>\n",
       "      <td>0.752754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.934705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>pamap_w</td>\n",
       "      <td>1.100290</td>\n",
       "      <td>0.049828</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.832836</td>\n",
       "      <td>0.159935</td>\n",
       "      <td>0.738474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.494287</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>pamap_w</td>\n",
       "      <td>1.185198</td>\n",
       "      <td>0.055354</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.841791</td>\n",
       "      <td>0.125255</td>\n",
       "      <td>0.749898</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>dsads_la</td>\n",
       "      <td>pamap_w</td>\n",
       "      <td>1.464021</td>\n",
       "      <td>0.030521</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.037944</td>\n",
       "      <td>0.667483</td>\n",
       "      <td>13.091740</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>pamap_w</td>\n",
       "      <td>pamap_c</td>\n",
       "      <td>0.622451</td>\n",
       "      <td>0.005972</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.809135</td>\n",
       "      <td>0.627499</td>\n",
       "      <td>0.800898</td>\n",
       "      <td>73.685929</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.468168</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>pamap_a</td>\n",
       "      <td>pamap_c</td>\n",
       "      <td>0.646948</td>\n",
       "      <td>0.019264</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.722675</td>\n",
       "      <td>0.372501</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>41.821743</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.841006</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>pamap_c</td>\n",
       "      <td>1.429557</td>\n",
       "      <td>0.045948</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.297022</td>\n",
       "      <td>0.793554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>pamap_c</td>\n",
       "      <td>1.489314</td>\n",
       "      <td>0.052656</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.643229</td>\n",
       "      <td>0.241126</td>\n",
       "      <td>0.784986</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dsads_t</td>\n",
       "      <td>pamap_c</td>\n",
       "      <td>1.351234</td>\n",
       "      <td>0.037984</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.238678</td>\n",
       "      <td>0.776418</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>pamap_c</td>\n",
       "      <td>1.270784</td>\n",
       "      <td>0.037071</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.747396</td>\n",
       "      <td>0.234598</td>\n",
       "      <td>0.792330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>pamap_c</td>\n",
       "      <td>1.242194</td>\n",
       "      <td>0.052731</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.897512</td>\n",
       "      <td>0.197878</td>\n",
       "      <td>0.874337</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.283056</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.573294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>oppo_b</td>\n",
       "      <td>pamap_c</td>\n",
       "      <td>1.323274</td>\n",
       "      <td>0.040178</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.128111</td>\n",
       "      <td>0.873929</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.410056</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.380999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>pamap_c</td>\n",
       "      <td>1.117596</td>\n",
       "      <td>0.047397</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.832836</td>\n",
       "      <td>0.121175</td>\n",
       "      <td>0.806610</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.965393</td>\n",
       "      <td>40.417891</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>pamap_c</td>\n",
       "      <td>1.252205</td>\n",
       "      <td>0.057905</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.841791</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.862913</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>pamap_c</td>\n",
       "      <td>1.273298</td>\n",
       "      <td>0.051980</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.884577</td>\n",
       "      <td>0.060792</td>\n",
       "      <td>0.847001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.176624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>dsads_la</td>\n",
       "      <td>pamap_c</td>\n",
       "      <td>1.233911</td>\n",
       "      <td>0.033504</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.022440</td>\n",
       "      <td>0.783762</td>\n",
       "      <td>25.824355</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>pamap_w</td>\n",
       "      <td>pamap_a</td>\n",
       "      <td>0.743870</td>\n",
       "      <td>0.014660</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.809135</td>\n",
       "      <td>0.622195</td>\n",
       "      <td>0.688290</td>\n",
       "      <td>63.532484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.852759</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>pamap_c</td>\n",
       "      <td>pamap_a</td>\n",
       "      <td>0.646948</td>\n",
       "      <td>0.019264</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.898858</td>\n",
       "      <td>0.558956</td>\n",
       "      <td>0.677683</td>\n",
       "      <td>65.654587</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.553053</td>\n",
       "      <td>33.006856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>pamap_a</td>\n",
       "      <td>1.366061</td>\n",
       "      <td>0.033579</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.404733</td>\n",
       "      <td>0.661771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dsads_t</td>\n",
       "      <td>pamap_a</td>\n",
       "      <td>1.403282</td>\n",
       "      <td>0.036236</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.277438</td>\n",
       "      <td>0.631171</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>oppo_b</td>\n",
       "      <td>pamap_a</td>\n",
       "      <td>1.226980</td>\n",
       "      <td>0.040490</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.252958</td>\n",
       "      <td>0.671563</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.625204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.263794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>pamap_a</td>\n",
       "      <td>1.187925</td>\n",
       "      <td>0.056171</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.884577</td>\n",
       "      <td>0.251734</td>\n",
       "      <td>0.678091</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85.700294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>pamap_a</td>\n",
       "      <td>1.427837</td>\n",
       "      <td>0.038547</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.643229</td>\n",
       "      <td>0.247246</td>\n",
       "      <td>0.679315</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>pamap_a</td>\n",
       "      <td>1.151606</td>\n",
       "      <td>0.059286</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.897512</td>\n",
       "      <td>0.242350</td>\n",
       "      <td>0.699306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87.234737</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.622919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>pamap_a</td>\n",
       "      <td>1.279896</td>\n",
       "      <td>0.028512</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.747396</td>\n",
       "      <td>0.234598</td>\n",
       "      <td>0.641371</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>pamap_a</td>\n",
       "      <td>1.002996</td>\n",
       "      <td>0.062375</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.832836</td>\n",
       "      <td>0.210934</td>\n",
       "      <td>0.679315</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.837414</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>pamap_a</td>\n",
       "      <td>1.097437</td>\n",
       "      <td>0.062846</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.841791</td>\n",
       "      <td>0.153407</td>\n",
       "      <td>0.669931</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>dsads_la</td>\n",
       "      <td>pamap_a</td>\n",
       "      <td>1.213597</td>\n",
       "      <td>0.027482</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.029784</td>\n",
       "      <td>0.681763</td>\n",
       "      <td>32.517140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>0.359323</td>\n",
       "      <td>0.001838</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.884577</td>\n",
       "      <td>0.827028</td>\n",
       "      <td>0.858636</td>\n",
       "      <td>92.572680</td>\n",
       "      <td>92.572680</td>\n",
       "      <td>92.572680</td>\n",
       "      <td>69.295102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>0.410786</td>\n",
       "      <td>0.003059</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.832836</td>\n",
       "      <td>0.730214</td>\n",
       "      <td>0.850174</td>\n",
       "      <td>86.957387</td>\n",
       "      <td>86.957387</td>\n",
       "      <td>86.957387</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>0.322763</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.841791</td>\n",
       "      <td>0.689895</td>\n",
       "      <td>0.858138</td>\n",
       "      <td>72.281959</td>\n",
       "      <td>72.281959</td>\n",
       "      <td>72.281959</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>oppo_b</td>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>0.703657</td>\n",
       "      <td>0.007503</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.567944</td>\n",
       "      <td>0.861374</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.935086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>dsads_la</td>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>1.725070</td>\n",
       "      <td>0.089272</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.825535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>1.727428</td>\n",
       "      <td>0.093210</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.747396</td>\n",
       "      <td>0.487307</td>\n",
       "      <td>0.826531</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>1.868353</td>\n",
       "      <td>0.100481</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.408412</td>\n",
       "      <td>0.806620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>1.859685</td>\n",
       "      <td>0.106835</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.643229</td>\n",
       "      <td>0.341215</td>\n",
       "      <td>0.774017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>pamap_w</td>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>1.251849</td>\n",
       "      <td>0.052333</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.809135</td>\n",
       "      <td>0.318815</td>\n",
       "      <td>0.848681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dsads_t</td>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>1.782091</td>\n",
       "      <td>0.107024</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.318566</td>\n",
       "      <td>0.824540</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>pamap_a</td>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>1.151606</td>\n",
       "      <td>0.059286</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.722675</td>\n",
       "      <td>0.291687</td>\n",
       "      <td>0.832504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>pamap_c</td>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>1.242194</td>\n",
       "      <td>0.052731</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.898858</td>\n",
       "      <td>0.145595</td>\n",
       "      <td>0.845694</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.829550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>0.322763</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.897512</td>\n",
       "      <td>0.669736</td>\n",
       "      <td>0.782230</td>\n",
       "      <td>84.050179</td>\n",
       "      <td>84.050179</td>\n",
       "      <td>84.050179</td>\n",
       "      <td>53.006770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>0.490672</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.884577</td>\n",
       "      <td>0.567695</td>\n",
       "      <td>0.793181</td>\n",
       "      <td>89.725209</td>\n",
       "      <td>89.725209</td>\n",
       "      <td>89.725209</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>0.458541</td>\n",
       "      <td>0.004374</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.832836</td>\n",
       "      <td>0.561473</td>\n",
       "      <td>0.791936</td>\n",
       "      <td>77.837515</td>\n",
       "      <td>77.837515</td>\n",
       "      <td>77.837515</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>oppo_b</td>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>0.819508</td>\n",
       "      <td>0.009806</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.496516</td>\n",
       "      <td>0.776257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.859020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>1.766390</td>\n",
       "      <td>0.097714</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.747396</td>\n",
       "      <td>0.487307</td>\n",
       "      <td>0.764560</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>dsads_la</td>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>1.745335</td>\n",
       "      <td>0.093644</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.464161</td>\n",
       "      <td>0.729965</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>1.901222</td>\n",
       "      <td>0.105857</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.443753</td>\n",
       "      <td>0.753858</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>1.890939</td>\n",
       "      <td>0.111826</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.643229</td>\n",
       "      <td>0.346192</td>\n",
       "      <td>0.779492</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dsads_t</td>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>1.843148</td>\n",
       "      <td>0.116170</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.308113</td>\n",
       "      <td>0.763564</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>pamap_w</td>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>1.185198</td>\n",
       "      <td>0.055354</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.809135</td>\n",
       "      <td>0.302389</td>\n",
       "      <td>0.718019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>pamap_a</td>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>1.097437</td>\n",
       "      <td>0.062846</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.722675</td>\n",
       "      <td>0.270781</td>\n",
       "      <td>0.776755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>pamap_c</td>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>1.252205</td>\n",
       "      <td>0.057905</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.898858</td>\n",
       "      <td>0.219014</td>\n",
       "      <td>0.793181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.029072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>0.359323</td>\n",
       "      <td>0.001838</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.897512</td>\n",
       "      <td>0.814335</td>\n",
       "      <td>0.850423</td>\n",
       "      <td>93.687774</td>\n",
       "      <td>95.161290</td>\n",
       "      <td>93.687774</td>\n",
       "      <td>80.804460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>0.408083</td>\n",
       "      <td>0.004326</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.832836</td>\n",
       "      <td>0.788701</td>\n",
       "      <td>0.836984</td>\n",
       "      <td>83.114297</td>\n",
       "      <td>81.581043</td>\n",
       "      <td>83.114297</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>oppo_b</td>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>0.503649</td>\n",
       "      <td>0.005801</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.652563</td>\n",
       "      <td>0.823295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.392672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.696137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>0.490672</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.841791</td>\n",
       "      <td>0.612743</td>\n",
       "      <td>0.851419</td>\n",
       "      <td>72.899243</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.899243</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>dsads_la</td>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>1.708458</td>\n",
       "      <td>0.086910</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.517173</td>\n",
       "      <td>0.831010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>1.733388</td>\n",
       "      <td>0.091065</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.747396</td>\n",
       "      <td>0.500249</td>\n",
       "      <td>0.791936</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>1.880057</td>\n",
       "      <td>0.098857</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.412145</td>\n",
       "      <td>0.847437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>1.880956</td>\n",
       "      <td>0.104589</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.643229</td>\n",
       "      <td>0.350174</td>\n",
       "      <td>0.827028</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dsads_t</td>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>1.798233</td>\n",
       "      <td>0.108311</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.329766</td>\n",
       "      <td>0.808860</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>pamap_w</td>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>1.277806</td>\n",
       "      <td>0.051026</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.809135</td>\n",
       "      <td>0.316575</td>\n",
       "      <td>0.849925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>pamap_a</td>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>1.187925</td>\n",
       "      <td>0.056171</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.722675</td>\n",
       "      <td>0.279741</td>\n",
       "      <td>0.824291</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>pamap_c</td>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>1.273298</td>\n",
       "      <td>0.051980</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.898858</td>\n",
       "      <td>0.266551</td>\n",
       "      <td>0.830513</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.262843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>0.408083</td>\n",
       "      <td>0.004326</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.884577</td>\n",
       "      <td>0.733201</td>\n",
       "      <td>0.812842</td>\n",
       "      <td>92.771804</td>\n",
       "      <td>92.771804</td>\n",
       "      <td>92.771804</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>0.410786</td>\n",
       "      <td>0.003059</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.897512</td>\n",
       "      <td>0.683425</td>\n",
       "      <td>0.806620</td>\n",
       "      <td>93.827160</td>\n",
       "      <td>93.827160</td>\n",
       "      <td>93.827160</td>\n",
       "      <td>75.228992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>0.458541</td>\n",
       "      <td>0.004374</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.841791</td>\n",
       "      <td>0.655301</td>\n",
       "      <td>0.811598</td>\n",
       "      <td>80.923935</td>\n",
       "      <td>80.923935</td>\n",
       "      <td>80.923935</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>oppo_b</td>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>0.712610</td>\n",
       "      <td>0.010136</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.530363</td>\n",
       "      <td>0.790692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.753485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>dsads_la</td>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>1.572520</td>\n",
       "      <td>0.085790</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.499502</td>\n",
       "      <td>0.778995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>1.615822</td>\n",
       "      <td>0.090679</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.747396</td>\n",
       "      <td>0.496267</td>\n",
       "      <td>0.782230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>1.777116</td>\n",
       "      <td>0.099175</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.475859</td>\n",
       "      <td>0.760329</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>1.774472</td>\n",
       "      <td>0.106481</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.643229</td>\n",
       "      <td>0.338228</td>\n",
       "      <td>0.785217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dsads_t</td>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>1.704680</td>\n",
       "      <td>0.104460</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.328273</td>\n",
       "      <td>0.772026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>pamap_w</td>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>1.100290</td>\n",
       "      <td>0.049828</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.809135</td>\n",
       "      <td>0.298656</td>\n",
       "      <td>0.789199</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>pamap_a</td>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>1.002996</td>\n",
       "      <td>0.062375</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.722675</td>\n",
       "      <td>0.237432</td>\n",
       "      <td>0.770533</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>pamap_c</td>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>1.117596</td>\n",
       "      <td>0.047397</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.898858</td>\n",
       "      <td>0.219512</td>\n",
       "      <td>0.801892</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.185185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>oppo_b</td>\n",
       "      <td>0.503649</td>\n",
       "      <td>0.005801</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.884577</td>\n",
       "      <td>0.791439</td>\n",
       "      <td>0.896217</td>\n",
       "      <td>69.792911</td>\n",
       "      <td>91.377937</td>\n",
       "      <td>91.377937</td>\n",
       "      <td>91.636798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>oppo_b</td>\n",
       "      <td>0.712610</td>\n",
       "      <td>0.010136</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.832836</td>\n",
       "      <td>0.678447</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.778176</td>\n",
       "      <td>86.778176</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>oppo_b</td>\n",
       "      <td>0.703657</td>\n",
       "      <td>0.007503</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.897512</td>\n",
       "      <td>0.660528</td>\n",
       "      <td>0.901692</td>\n",
       "      <td>92.970928</td>\n",
       "      <td>67.702111</td>\n",
       "      <td>67.702111</td>\n",
       "      <td>69.812824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>oppo_b</td>\n",
       "      <td>0.819508</td>\n",
       "      <td>0.009806</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.841791</td>\n",
       "      <td>0.570433</td>\n",
       "      <td>0.894973</td>\n",
       "      <td>84.926324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>oppo_b</td>\n",
       "      <td>1.670562</td>\n",
       "      <td>0.076164</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.747396</td>\n",
       "      <td>0.509706</td>\n",
       "      <td>0.874564</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>dsads_la</td>\n",
       "      <td>oppo_b</td>\n",
       "      <td>1.671462</td>\n",
       "      <td>0.073346</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.488303</td>\n",
       "      <td>0.882031</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>oppo_b</td>\n",
       "      <td>1.779333</td>\n",
       "      <td>0.087971</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.643229</td>\n",
       "      <td>0.428323</td>\n",
       "      <td>0.885266</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>oppo_b</td>\n",
       "      <td>1.760782</td>\n",
       "      <td>0.082694</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.409905</td>\n",
       "      <td>0.886013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>pamap_c</td>\n",
       "      <td>oppo_b</td>\n",
       "      <td>1.323274</td>\n",
       "      <td>0.040178</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.898858</td>\n",
       "      <td>0.396466</td>\n",
       "      <td>0.886262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.143767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dsads_t</td>\n",
       "      <td>oppo_b</td>\n",
       "      <td>1.699683</td>\n",
       "      <td>0.087178</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.341961</td>\n",
       "      <td>0.882778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>pamap_a</td>\n",
       "      <td>oppo_b</td>\n",
       "      <td>1.226980</td>\n",
       "      <td>0.040490</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.722675</td>\n",
       "      <td>0.322051</td>\n",
       "      <td>0.888004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>pamap_w</td>\n",
       "      <td>oppo_b</td>\n",
       "      <td>1.384871</td>\n",
       "      <td>0.041871</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.809135</td>\n",
       "      <td>0.318566</td>\n",
       "      <td>0.887506</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>dsads_t</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.017977</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.747396</td>\n",
       "      <td>0.502604</td>\n",
       "      <td>0.564453</td>\n",
       "      <td>56.302083</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.302083</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>dsads_la</td>\n",
       "      <td>dsads_t</td>\n",
       "      <td>0.778643</td>\n",
       "      <td>0.021905</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.498698</td>\n",
       "      <td>0.582682</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>dsads_t</td>\n",
       "      <td>0.509558</td>\n",
       "      <td>0.014866</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.488932</td>\n",
       "      <td>0.570312</td>\n",
       "      <td>88.177083</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.177083</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>dsads_t</td>\n",
       "      <td>1.798233</td>\n",
       "      <td>0.108311</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.884577</td>\n",
       "      <td>0.470703</td>\n",
       "      <td>0.588542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.281250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>dsads_t</td>\n",
       "      <td>1.704680</td>\n",
       "      <td>0.104460</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.832836</td>\n",
       "      <td>0.401042</td>\n",
       "      <td>0.575521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.020833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>dsads_t</td>\n",
       "      <td>0.479365</td>\n",
       "      <td>0.019388</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.643229</td>\n",
       "      <td>0.342448</td>\n",
       "      <td>0.580729</td>\n",
       "      <td>75.729167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.729167</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>dsads_t</td>\n",
       "      <td>1.782091</td>\n",
       "      <td>0.107024</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.897512</td>\n",
       "      <td>0.317057</td>\n",
       "      <td>0.574870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.708333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.604167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>pamap_a</td>\n",
       "      <td>dsads_t</td>\n",
       "      <td>1.403282</td>\n",
       "      <td>0.036236</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.722675</td>\n",
       "      <td>0.282552</td>\n",
       "      <td>0.574870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>dsads_t</td>\n",
       "      <td>1.843148</td>\n",
       "      <td>0.116170</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.841791</td>\n",
       "      <td>0.276693</td>\n",
       "      <td>0.571615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>oppo_b</td>\n",
       "      <td>dsads_t</td>\n",
       "      <td>1.699683</td>\n",
       "      <td>0.087178</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.259115</td>\n",
       "      <td>0.557943</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.010417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>pamap_w</td>\n",
       "      <td>dsads_t</td>\n",
       "      <td>1.713112</td>\n",
       "      <td>0.041491</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.809135</td>\n",
       "      <td>0.251953</td>\n",
       "      <td>0.608073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>pamap_c</td>\n",
       "      <td>dsads_t</td>\n",
       "      <td>1.351234</td>\n",
       "      <td>0.037984</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.898858</td>\n",
       "      <td>0.251953</td>\n",
       "      <td>0.589844</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.343750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>0.336949</td>\n",
       "      <td>0.005562</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.662760</td>\n",
       "      <td>0.683594</td>\n",
       "      <td>60.208333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.718750</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dsads_t</td>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>0.479365</td>\n",
       "      <td>0.019388</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.590495</td>\n",
       "      <td>0.648438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.260417</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>dsads_la</td>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>0.850386</td>\n",
       "      <td>0.016635</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.513021</td>\n",
       "      <td>0.655599</td>\n",
       "      <td>85.833333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>0.593826</td>\n",
       "      <td>0.012356</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.747396</td>\n",
       "      <td>0.496745</td>\n",
       "      <td>0.678385</td>\n",
       "      <td>93.593750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.947917</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>1.880956</td>\n",
       "      <td>0.104589</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.884577</td>\n",
       "      <td>0.470052</td>\n",
       "      <td>0.649089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.572917</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>1.774472</td>\n",
       "      <td>0.106481</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.832836</td>\n",
       "      <td>0.378906</td>\n",
       "      <td>0.641927</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.135417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>1.859685</td>\n",
       "      <td>0.106835</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.897512</td>\n",
       "      <td>0.347005</td>\n",
       "      <td>0.671224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.010417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.854167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>oppo_b</td>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>1.779333</td>\n",
       "      <td>0.087971</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.336589</td>\n",
       "      <td>0.658854</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.031250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>1.890939</td>\n",
       "      <td>0.111826</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.841791</td>\n",
       "      <td>0.269531</td>\n",
       "      <td>0.649740</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>pamap_w</td>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>1.791822</td>\n",
       "      <td>0.048892</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.809135</td>\n",
       "      <td>0.251953</td>\n",
       "      <td>0.647135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>pamap_c</td>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>1.489314</td>\n",
       "      <td>0.052656</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.898858</td>\n",
       "      <td>0.251953</td>\n",
       "      <td>0.656901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.614583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>pamap_a</td>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>1.427837</td>\n",
       "      <td>0.038547</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.722675</td>\n",
       "      <td>0.224609</td>\n",
       "      <td>0.649089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>dsads_la</td>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>0.396833</td>\n",
       "      <td>0.008943</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.711589</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>72.239583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.427083</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dsads_t</td>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.017977</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.571615</td>\n",
       "      <td>0.705729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.843750</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>1.733388</td>\n",
       "      <td>0.091065</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.884577</td>\n",
       "      <td>0.558594</td>\n",
       "      <td>0.711589</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85.260417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>0.462330</td>\n",
       "      <td>0.011396</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.511068</td>\n",
       "      <td>0.708984</td>\n",
       "      <td>83.437500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.791667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>0.593826</td>\n",
       "      <td>0.012356</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.643229</td>\n",
       "      <td>0.509766</td>\n",
       "      <td>0.699219</td>\n",
       "      <td>82.760417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>1.615822</td>\n",
       "      <td>0.090679</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.832836</td>\n",
       "      <td>0.466146</td>\n",
       "      <td>0.714844</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.010417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>1.727428</td>\n",
       "      <td>0.093210</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.897512</td>\n",
       "      <td>0.401042</td>\n",
       "      <td>0.714844</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.562500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>1.766390</td>\n",
       "      <td>0.097714</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.841791</td>\n",
       "      <td>0.376953</td>\n",
       "      <td>0.712240</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>oppo_b</td>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>1.670562</td>\n",
       "      <td>0.076164</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.306641</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.395833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>pamap_c</td>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>1.270784</td>\n",
       "      <td>0.037071</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.898858</td>\n",
       "      <td>0.258464</td>\n",
       "      <td>0.696615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.697917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>pamap_w</td>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>1.578720</td>\n",
       "      <td>0.032859</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.809135</td>\n",
       "      <td>0.252604</td>\n",
       "      <td>0.710938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>pamap_a</td>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>1.279896</td>\n",
       "      <td>0.028512</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.722675</td>\n",
       "      <td>0.244141</td>\n",
       "      <td>0.701823</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>0.336949</td>\n",
       "      <td>0.005562</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.643229</td>\n",
       "      <td>0.671224</td>\n",
       "      <td>0.663411</td>\n",
       "      <td>57.083333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.468750</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dsads_t</td>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>0.509558</td>\n",
       "      <td>0.014866</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.589844</td>\n",
       "      <td>0.632812</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.114583</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>dsads_la</td>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>0.708819</td>\n",
       "      <td>0.014258</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.544271</td>\n",
       "      <td>0.650391</td>\n",
       "      <td>94.322917</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>0.462330</td>\n",
       "      <td>0.011396</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.747396</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.641927</td>\n",
       "      <td>87.343750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.208333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>1.880057</td>\n",
       "      <td>0.098857</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.884577</td>\n",
       "      <td>0.493490</td>\n",
       "      <td>0.672526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85.052083</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>1.777116</td>\n",
       "      <td>0.099175</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.832836</td>\n",
       "      <td>0.447917</td>\n",
       "      <td>0.651042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.541667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>1.868353</td>\n",
       "      <td>0.100481</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.897512</td>\n",
       "      <td>0.381510</td>\n",
       "      <td>0.669922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.697917</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.927083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>oppo_b</td>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>1.760782</td>\n",
       "      <td>0.082694</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.294922</td>\n",
       "      <td>0.636068</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.229167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>1.901222</td>\n",
       "      <td>0.105857</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.841791</td>\n",
       "      <td>0.276693</td>\n",
       "      <td>0.662109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>pamap_w</td>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>1.729038</td>\n",
       "      <td>0.044448</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.809135</td>\n",
       "      <td>0.251953</td>\n",
       "      <td>0.653646</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>pamap_c</td>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>1.429557</td>\n",
       "      <td>0.045948</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.898858</td>\n",
       "      <td>0.251953</td>\n",
       "      <td>0.642578</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.614583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>pamap_a</td>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>1.366061</td>\n",
       "      <td>0.033579</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.722675</td>\n",
       "      <td>0.231120</td>\n",
       "      <td>0.629557</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dsads_ra</td>\n",
       "      <td>dsads_la</td>\n",
       "      <td>0.396833</td>\n",
       "      <td>0.008943</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.747396</td>\n",
       "      <td>0.681641</td>\n",
       "      <td>0.732422</td>\n",
       "      <td>74.062500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.697917</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dsads_t</td>\n",
       "      <td>dsads_la</td>\n",
       "      <td>0.778643</td>\n",
       "      <td>0.021905</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.720703</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.802083</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>oppo_lua</td>\n",
       "      <td>dsads_la</td>\n",
       "      <td>1.708458</td>\n",
       "      <td>0.086910</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.884577</td>\n",
       "      <td>0.573568</td>\n",
       "      <td>0.727214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.510417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>dsads_ll</td>\n",
       "      <td>dsads_la</td>\n",
       "      <td>0.708819</td>\n",
       "      <td>0.014258</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.539062</td>\n",
       "      <td>0.709635</td>\n",
       "      <td>84.791667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.010417</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>dsads_rl</td>\n",
       "      <td>dsads_la</td>\n",
       "      <td>0.850386</td>\n",
       "      <td>0.016635</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.643229</td>\n",
       "      <td>0.518229</td>\n",
       "      <td>0.706380</td>\n",
       "      <td>83.125000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>oppo_lla</td>\n",
       "      <td>dsads_la</td>\n",
       "      <td>1.572520</td>\n",
       "      <td>0.085790</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.832836</td>\n",
       "      <td>0.486328</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85.781250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>oppo_rla</td>\n",
       "      <td>dsads_la</td>\n",
       "      <td>1.745335</td>\n",
       "      <td>0.093644</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.841791</td>\n",
       "      <td>0.404948</td>\n",
       "      <td>0.712891</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.687500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>oppo_rua</td>\n",
       "      <td>dsads_la</td>\n",
       "      <td>1.725070</td>\n",
       "      <td>0.089272</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.897512</td>\n",
       "      <td>0.402344</td>\n",
       "      <td>0.716797</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.270833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>oppo_b</td>\n",
       "      <td>dsads_la</td>\n",
       "      <td>1.671462</td>\n",
       "      <td>0.073346</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.366536</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.052083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>pamap_c</td>\n",
       "      <td>dsads_la</td>\n",
       "      <td>1.233911</td>\n",
       "      <td>0.033504</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.898858</td>\n",
       "      <td>0.351562</td>\n",
       "      <td>0.710286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.135417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>pamap_w</td>\n",
       "      <td>dsads_la</td>\n",
       "      <td>1.464021</td>\n",
       "      <td>0.030521</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.809135</td>\n",
       "      <td>0.250651</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>pamap_a</td>\n",
       "      <td>dsads_la</td>\n",
       "      <td>1.213597</td>\n",
       "      <td>0.027482</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.722675</td>\n",
       "      <td>0.246094</td>\n",
       "      <td>0.716797</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Source    Target       l2d       jsd  Adaptivity  Source Accuracy  \\\n",
       "142   pamap_c   pamap_w  0.622451  0.005972         7.0         0.898858   \n",
       "154   pamap_a   pamap_w  0.743870  0.014660         7.0         0.722675   \n",
       "57   dsads_ll   pamap_w  1.729038  0.044448         4.0         0.697917   \n",
       "45   dsads_rl   pamap_w  1.791822  0.048892         4.0         0.643229   \n",
       "9     dsads_t   pamap_w  1.713112  0.041491         4.0         0.609375   \n",
       "21   dsads_ra   pamap_w  1.578720  0.032859         4.0         0.747396   \n",
       "69     oppo_b   pamap_w  1.384871  0.041871        11.0         0.910448   \n",
       "81   oppo_rua   pamap_w  1.251849  0.052333        11.0         0.897512   \n",
       "105  oppo_lua   pamap_w  1.277806  0.051026        11.0         0.884577   \n",
       "117  oppo_lla   pamap_w  1.100290  0.049828        11.0         0.832836   \n",
       "93   oppo_rla   pamap_w  1.185198  0.055354        11.0         0.841791   \n",
       "33   dsads_la   pamap_w  1.464021  0.030521         4.0         0.718750   \n",
       "130   pamap_w   pamap_c  0.622451  0.005972         7.0         0.809135   \n",
       "155   pamap_a   pamap_c  0.646948  0.019264         7.0         0.722675   \n",
       "58   dsads_ll   pamap_c  1.429557  0.045948         4.0         0.697917   \n",
       "46   dsads_rl   pamap_c  1.489314  0.052656         4.0         0.643229   \n",
       "10    dsads_t   pamap_c  1.351234  0.037984         4.0         0.609375   \n",
       "22   dsads_ra   pamap_c  1.270784  0.037071         4.0         0.747396   \n",
       "82   oppo_rua   pamap_c  1.242194  0.052731        11.0         0.897512   \n",
       "70     oppo_b   pamap_c  1.323274  0.040178        11.0         0.910448   \n",
       "118  oppo_lla   pamap_c  1.117596  0.047397        11.0         0.832836   \n",
       "94   oppo_rla   pamap_c  1.252205  0.057905        11.0         0.841791   \n",
       "106  oppo_lua   pamap_c  1.273298  0.051980        11.0         0.884577   \n",
       "34   dsads_la   pamap_c  1.233911  0.033504         4.0         0.718750   \n",
       "131   pamap_w   pamap_a  0.743870  0.014660         7.0         0.809135   \n",
       "143   pamap_c   pamap_a  0.646948  0.019264         7.0         0.898858   \n",
       "59   dsads_ll   pamap_a  1.366061  0.033579         4.0         0.697917   \n",
       "11    dsads_t   pamap_a  1.403282  0.036236         4.0         0.609375   \n",
       "71     oppo_b   pamap_a  1.226980  0.040490        11.0         0.910448   \n",
       "107  oppo_lua   pamap_a  1.187925  0.056171        11.0         0.884577   \n",
       "47   dsads_rl   pamap_a  1.427837  0.038547         4.0         0.643229   \n",
       "83   oppo_rua   pamap_a  1.151606  0.059286        11.0         0.897512   \n",
       "23   dsads_ra   pamap_a  1.279896  0.028512         4.0         0.747396   \n",
       "119  oppo_lla   pamap_a  1.002996  0.062375        11.0         0.832836   \n",
       "95   oppo_rla   pamap_a  1.097437  0.062846        11.0         0.841791   \n",
       "35   dsads_la   pamap_a  1.213597  0.027482         4.0         0.718750   \n",
       "102  oppo_lua  oppo_rua  0.359323  0.001838        11.0         0.884577   \n",
       "114  oppo_lla  oppo_rua  0.410786  0.003059        11.0         0.832836   \n",
       "90   oppo_rla  oppo_rua  0.322763  0.001938        11.0         0.841791   \n",
       "65     oppo_b  oppo_rua  0.703657  0.007503        11.0         0.910448   \n",
       "29   dsads_la  oppo_rua  1.725070  0.089272         4.0         0.718750   \n",
       "17   dsads_ra  oppo_rua  1.727428  0.093210         4.0         0.747396   \n",
       "53   dsads_ll  oppo_rua  1.868353  0.100481         4.0         0.697917   \n",
       "41   dsads_rl  oppo_rua  1.859685  0.106835         4.0         0.643229   \n",
       "126   pamap_w  oppo_rua  1.251849  0.052333         7.0         0.809135   \n",
       "5     dsads_t  oppo_rua  1.782091  0.107024         4.0         0.609375   \n",
       "150   pamap_a  oppo_rua  1.151606  0.059286         7.0         0.722675   \n",
       "138   pamap_c  oppo_rua  1.242194  0.052731         7.0         0.898858   \n",
       "78   oppo_rua  oppo_rla  0.322763  0.001938        11.0         0.897512   \n",
       "103  oppo_lua  oppo_rla  0.490672  0.001744        11.0         0.884577   \n",
       "115  oppo_lla  oppo_rla  0.458541  0.004374        11.0         0.832836   \n",
       "66     oppo_b  oppo_rla  0.819508  0.009806        11.0         0.910448   \n",
       "18   dsads_ra  oppo_rla  1.766390  0.097714         4.0         0.747396   \n",
       "30   dsads_la  oppo_rla  1.745335  0.093644         4.0         0.718750   \n",
       "54   dsads_ll  oppo_rla  1.901222  0.105857         4.0         0.697917   \n",
       "42   dsads_rl  oppo_rla  1.890939  0.111826         4.0         0.643229   \n",
       "6     dsads_t  oppo_rla  1.843148  0.116170         4.0         0.609375   \n",
       "127   pamap_w  oppo_rla  1.185198  0.055354         7.0         0.809135   \n",
       "151   pamap_a  oppo_rla  1.097437  0.062846         7.0         0.722675   \n",
       "139   pamap_c  oppo_rla  1.252205  0.057905         7.0         0.898858   \n",
       "79   oppo_rua  oppo_lua  0.359323  0.001838        11.0         0.897512   \n",
       "116  oppo_lla  oppo_lua  0.408083  0.004326        11.0         0.832836   \n",
       "67     oppo_b  oppo_lua  0.503649  0.005801        11.0         0.910448   \n",
       "91   oppo_rla  oppo_lua  0.490672  0.001744        11.0         0.841791   \n",
       "31   dsads_la  oppo_lua  1.708458  0.086910         4.0         0.718750   \n",
       "19   dsads_ra  oppo_lua  1.733388  0.091065         4.0         0.747396   \n",
       "55   dsads_ll  oppo_lua  1.880057  0.098857         4.0         0.697917   \n",
       "43   dsads_rl  oppo_lua  1.880956  0.104589         4.0         0.643229   \n",
       "7     dsads_t  oppo_lua  1.798233  0.108311         4.0         0.609375   \n",
       "128   pamap_w  oppo_lua  1.277806  0.051026         7.0         0.809135   \n",
       "152   pamap_a  oppo_lua  1.187925  0.056171         7.0         0.722675   \n",
       "140   pamap_c  oppo_lua  1.273298  0.051980         7.0         0.898858   \n",
       "104  oppo_lua  oppo_lla  0.408083  0.004326        11.0         0.884577   \n",
       "80   oppo_rua  oppo_lla  0.410786  0.003059        11.0         0.897512   \n",
       "92   oppo_rla  oppo_lla  0.458541  0.004374        11.0         0.841791   \n",
       "68     oppo_b  oppo_lla  0.712610  0.010136        11.0         0.910448   \n",
       "32   dsads_la  oppo_lla  1.572520  0.085790         4.0         0.718750   \n",
       "20   dsads_ra  oppo_lla  1.615822  0.090679         4.0         0.747396   \n",
       "56   dsads_ll  oppo_lla  1.777116  0.099175         4.0         0.697917   \n",
       "44   dsads_rl  oppo_lla  1.774472  0.106481         4.0         0.643229   \n",
       "8     dsads_t  oppo_lla  1.704680  0.104460         4.0         0.609375   \n",
       "129   pamap_w  oppo_lla  1.100290  0.049828         7.0         0.809135   \n",
       "153   pamap_a  oppo_lla  1.002996  0.062375         7.0         0.722675   \n",
       "141   pamap_c  oppo_lla  1.117596  0.047397         7.0         0.898858   \n",
       "101  oppo_lua    oppo_b  0.503649  0.005801        11.0         0.884577   \n",
       "113  oppo_lla    oppo_b  0.712610  0.010136        11.0         0.832836   \n",
       "77   oppo_rua    oppo_b  0.703657  0.007503        11.0         0.897512   \n",
       "89   oppo_rla    oppo_b  0.819508  0.009806        11.0         0.841791   \n",
       "16   dsads_ra    oppo_b  1.670562  0.076164         4.0         0.747396   \n",
       "28   dsads_la    oppo_b  1.671462  0.073346         4.0         0.718750   \n",
       "40   dsads_rl    oppo_b  1.779333  0.087971         4.0         0.643229   \n",
       "52   dsads_ll    oppo_b  1.760782  0.082694         4.0         0.697917   \n",
       "137   pamap_c    oppo_b  1.323274  0.040178         7.0         0.898858   \n",
       "4     dsads_t    oppo_b  1.699683  0.087178         4.0         0.609375   \n",
       "149   pamap_a    oppo_b  1.226980  0.040490         7.0         0.722675   \n",
       "125   pamap_w    oppo_b  1.384871  0.041871         7.0         0.809135   \n",
       "12   dsads_ra   dsads_t  0.505051  0.017977         4.0         0.747396   \n",
       "24   dsads_la   dsads_t  0.778643  0.021905         4.0         0.718750   \n",
       "48   dsads_ll   dsads_t  0.509558  0.014866         4.0         0.697917   \n",
       "96   oppo_lua   dsads_t  1.798233  0.108311        11.0         0.884577   \n",
       "108  oppo_lla   dsads_t  1.704680  0.104460        11.0         0.832836   \n",
       "36   dsads_rl   dsads_t  0.479365  0.019388         4.0         0.643229   \n",
       "72   oppo_rua   dsads_t  1.782091  0.107024        11.0         0.897512   \n",
       "144   pamap_a   dsads_t  1.403282  0.036236         7.0         0.722675   \n",
       "84   oppo_rla   dsads_t  1.843148  0.116170        11.0         0.841791   \n",
       "60     oppo_b   dsads_t  1.699683  0.087178        11.0         0.910448   \n",
       "120   pamap_w   dsads_t  1.713112  0.041491         7.0         0.809135   \n",
       "132   pamap_c   dsads_t  1.351234  0.037984         7.0         0.898858   \n",
       "51   dsads_ll  dsads_rl  0.336949  0.005562         4.0         0.697917   \n",
       "2     dsads_t  dsads_rl  0.479365  0.019388         4.0         0.609375   \n",
       "26   dsads_la  dsads_rl  0.850386  0.016635         4.0         0.718750   \n",
       "14   dsads_ra  dsads_rl  0.593826  0.012356         4.0         0.747396   \n",
       "99   oppo_lua  dsads_rl  1.880956  0.104589        11.0         0.884577   \n",
       "111  oppo_lla  dsads_rl  1.774472  0.106481        11.0         0.832836   \n",
       "75   oppo_rua  dsads_rl  1.859685  0.106835        11.0         0.897512   \n",
       "63     oppo_b  dsads_rl  1.779333  0.087971        11.0         0.910448   \n",
       "87   oppo_rla  dsads_rl  1.890939  0.111826        11.0         0.841791   \n",
       "123   pamap_w  dsads_rl  1.791822  0.048892         7.0         0.809135   \n",
       "135   pamap_c  dsads_rl  1.489314  0.052656         7.0         0.898858   \n",
       "147   pamap_a  dsads_rl  1.427837  0.038547         7.0         0.722675   \n",
       "25   dsads_la  dsads_ra  0.396833  0.008943         4.0         0.718750   \n",
       "0     dsads_t  dsads_ra  0.505051  0.017977         4.0         0.609375   \n",
       "97   oppo_lua  dsads_ra  1.733388  0.091065        11.0         0.884577   \n",
       "49   dsads_ll  dsads_ra  0.462330  0.011396         4.0         0.697917   \n",
       "37   dsads_rl  dsads_ra  0.593826  0.012356         4.0         0.643229   \n",
       "109  oppo_lla  dsads_ra  1.615822  0.090679        11.0         0.832836   \n",
       "73   oppo_rua  dsads_ra  1.727428  0.093210        11.0         0.897512   \n",
       "85   oppo_rla  dsads_ra  1.766390  0.097714        11.0         0.841791   \n",
       "61     oppo_b  dsads_ra  1.670562  0.076164        11.0         0.910448   \n",
       "133   pamap_c  dsads_ra  1.270784  0.037071         7.0         0.898858   \n",
       "121   pamap_w  dsads_ra  1.578720  0.032859         7.0         0.809135   \n",
       "145   pamap_a  dsads_ra  1.279896  0.028512         7.0         0.722675   \n",
       "39   dsads_rl  dsads_ll  0.336949  0.005562         4.0         0.643229   \n",
       "3     dsads_t  dsads_ll  0.509558  0.014866         4.0         0.609375   \n",
       "27   dsads_la  dsads_ll  0.708819  0.014258         4.0         0.718750   \n",
       "15   dsads_ra  dsads_ll  0.462330  0.011396         4.0         0.747396   \n",
       "100  oppo_lua  dsads_ll  1.880057  0.098857        11.0         0.884577   \n",
       "112  oppo_lla  dsads_ll  1.777116  0.099175        11.0         0.832836   \n",
       "76   oppo_rua  dsads_ll  1.868353  0.100481        11.0         0.897512   \n",
       "64     oppo_b  dsads_ll  1.760782  0.082694        11.0         0.910448   \n",
       "88   oppo_rla  dsads_ll  1.901222  0.105857        11.0         0.841791   \n",
       "124   pamap_w  dsads_ll  1.729038  0.044448         7.0         0.809135   \n",
       "136   pamap_c  dsads_ll  1.429557  0.045948         7.0         0.898858   \n",
       "148   pamap_a  dsads_ll  1.366061  0.033579         7.0         0.722675   \n",
       "13   dsads_ra  dsads_la  0.396833  0.008943         4.0         0.747396   \n",
       "1     dsads_t  dsads_la  0.778643  0.021905         4.0         0.609375   \n",
       "98   oppo_lua  dsads_la  1.708458  0.086910        11.0         0.884577   \n",
       "50   dsads_ll  dsads_la  0.708819  0.014258         4.0         0.697917   \n",
       "38   dsads_rl  dsads_la  0.850386  0.016635         4.0         0.643229   \n",
       "110  oppo_lla  dsads_la  1.572520  0.085790        11.0         0.832836   \n",
       "86   oppo_rla  dsads_la  1.745335  0.093644        11.0         0.841791   \n",
       "74   oppo_rua  dsads_la  1.725070  0.089272        11.0         0.897512   \n",
       "62     oppo_b  dsads_la  1.671462  0.073346        11.0         0.910448   \n",
       "134   pamap_c  dsads_la  1.233911  0.033504         7.0         0.898858   \n",
       "122   pamap_w  dsads_la  1.464021  0.030521         7.0         0.809135   \n",
       "146   pamap_a  dsads_la  1.213597  0.027482         7.0         0.722675   \n",
       "\n",
       "      serving  finetune  max_voting_jsd_%  max_voting_Adaptivity_%  \\\n",
       "142  0.530804  0.734394         80.215475                      NaN   \n",
       "154  0.477356  0.729498         70.649690                      NaN   \n",
       "57   0.337005  0.649939               NaN                      NaN   \n",
       "45   0.241126  0.714810               NaN                      NaN   \n",
       "9    0.238678  0.692370               NaN                      NaN   \n",
       "21   0.234598  0.692370               NaN                      NaN   \n",
       "69   0.234598  0.760914               NaN                99.869409   \n",
       "81   0.234598  0.753978               NaN                99.869409   \n",
       "105  0.234598  0.752754               NaN                99.934705   \n",
       "117  0.159935  0.738474               NaN                      NaN   \n",
       "93   0.125255  0.749898               NaN                      NaN   \n",
       "33   0.037944  0.667483         13.091740                      NaN   \n",
       "130  0.627499  0.800898         73.685929                      NaN   \n",
       "155  0.372501  0.813953         41.821743                      NaN   \n",
       "58   0.297022  0.793554               NaN                      NaN   \n",
       "46   0.241126  0.784986               NaN                      NaN   \n",
       "10   0.238678  0.776418               NaN                      NaN   \n",
       "22   0.234598  0.792330               NaN                      NaN   \n",
       "82   0.197878  0.874337               NaN                91.283056   \n",
       "70   0.128111  0.873929               NaN                88.410056   \n",
       "118  0.121175  0.806610               NaN                61.965393   \n",
       "94   0.068543  0.862913               NaN                      NaN   \n",
       "106  0.060792  0.847001               NaN                      NaN   \n",
       "34   0.022440  0.783762         25.824355                      NaN   \n",
       "131  0.622195  0.688290         63.532484                      NaN   \n",
       "143  0.558956  0.677683         65.654587                      NaN   \n",
       "59   0.404733  0.661771               NaN                      NaN   \n",
       "11   0.277438  0.631171               NaN                      NaN   \n",
       "71   0.252958  0.671563               NaN                95.625204   \n",
       "107  0.251734  0.678091               NaN                85.700294   \n",
       "47   0.247246  0.679315               NaN                      NaN   \n",
       "83   0.242350  0.699306               NaN                87.234737   \n",
       "23   0.234598  0.641371               NaN                      NaN   \n",
       "119  0.210934  0.679315               NaN                      NaN   \n",
       "95   0.153407  0.669931               NaN                      NaN   \n",
       "35   0.029784  0.681763         32.517140                      NaN   \n",
       "102  0.827028  0.858636         92.572680                92.572680   \n",
       "114  0.730214  0.850174         86.957387                86.957387   \n",
       "90   0.689895  0.858138         72.281959                72.281959   \n",
       "65   0.567944  0.861374               NaN                      NaN   \n",
       "29   0.489796  0.825535               NaN                      NaN   \n",
       "17   0.487307  0.826531               NaN                      NaN   \n",
       "53   0.408412  0.806620               NaN                      NaN   \n",
       "41   0.341215  0.774017               NaN                      NaN   \n",
       "126  0.318815  0.848681               NaN                      NaN   \n",
       "5    0.318566  0.824540               NaN                      NaN   \n",
       "150  0.291687  0.832504               NaN                      NaN   \n",
       "138  0.145595  0.845694               NaN                      NaN   \n",
       "78   0.669736  0.782230         84.050179                84.050179   \n",
       "103  0.567695  0.793181         89.725209                89.725209   \n",
       "115  0.561473  0.791936         77.837515                77.837515   \n",
       "66   0.496516  0.776257               NaN                      NaN   \n",
       "18   0.487307  0.764560               NaN                      NaN   \n",
       "30   0.464161  0.729965               NaN                      NaN   \n",
       "54   0.443753  0.753858               NaN                      NaN   \n",
       "42   0.346192  0.779492               NaN                      NaN   \n",
       "6    0.308113  0.763564               NaN                      NaN   \n",
       "127  0.302389  0.718019               NaN                      NaN   \n",
       "151  0.270781  0.776755               NaN                      NaN   \n",
       "139  0.219014  0.793181               NaN                      NaN   \n",
       "79   0.814335  0.850423         93.687774                95.161290   \n",
       "116  0.788701  0.836984         83.114297                81.581043   \n",
       "67   0.652563  0.823295               NaN                74.392672   \n",
       "91   0.612743  0.851419         72.899243                      NaN   \n",
       "31   0.517173  0.831010               NaN                      NaN   \n",
       "19   0.500249  0.791936               NaN                      NaN   \n",
       "55   0.412145  0.847437               NaN                      NaN   \n",
       "43   0.350174  0.827028               NaN                      NaN   \n",
       "7    0.329766  0.808860               NaN                      NaN   \n",
       "128  0.316575  0.849925               NaN                      NaN   \n",
       "152  0.279741  0.824291               NaN                      NaN   \n",
       "140  0.266551  0.830513               NaN                      NaN   \n",
       "104  0.733201  0.812842         92.771804                92.771804   \n",
       "80   0.683425  0.806620         93.827160                93.827160   \n",
       "92   0.655301  0.811598         80.923935                80.923935   \n",
       "68   0.530363  0.790692               NaN                      NaN   \n",
       "32   0.499502  0.778995               NaN                      NaN   \n",
       "20   0.496267  0.782230               NaN                      NaN   \n",
       "56   0.475859  0.760329               NaN                      NaN   \n",
       "44   0.338228  0.785217               NaN                      NaN   \n",
       "8    0.328273  0.772026               NaN                      NaN   \n",
       "129  0.298656  0.789199               NaN                      NaN   \n",
       "153  0.237432  0.770533               NaN                      NaN   \n",
       "141  0.219512  0.801892               NaN                      NaN   \n",
       "101  0.791439  0.896217         69.792911                91.377937   \n",
       "113  0.678447  0.877551               NaN                86.778176   \n",
       "77   0.660528  0.901692         92.970928                67.702111   \n",
       "89   0.570433  0.894973         84.926324                      NaN   \n",
       "16   0.509706  0.874564               NaN                      NaN   \n",
       "28   0.488303  0.882031               NaN                      NaN   \n",
       "40   0.428323  0.885266               NaN                      NaN   \n",
       "52   0.409905  0.886013               NaN                      NaN   \n",
       "137  0.396466  0.886262               NaN                      NaN   \n",
       "4    0.341961  0.882778               NaN                      NaN   \n",
       "149  0.322051  0.888004               NaN                      NaN   \n",
       "125  0.318566  0.887506               NaN                      NaN   \n",
       "12   0.502604  0.564453         56.302083                      NaN   \n",
       "24   0.498698  0.582682               NaN                      NaN   \n",
       "48   0.488932  0.570312         88.177083                      NaN   \n",
       "96   0.470703  0.588542               NaN                73.281250   \n",
       "108  0.401042  0.575521               NaN                98.020833   \n",
       "36   0.342448  0.580729         75.729167                      NaN   \n",
       "72   0.317057  0.574870               NaN                77.708333   \n",
       "144  0.282552  0.574870               NaN                      NaN   \n",
       "84   0.276693  0.571615               NaN                      NaN   \n",
       "60   0.259115  0.557943               NaN                      NaN   \n",
       "120  0.251953  0.608073               NaN                      NaN   \n",
       "132  0.251953  0.589844               NaN                      NaN   \n",
       "51   0.662760  0.683594         60.208333                      NaN   \n",
       "2    0.590495  0.648438               NaN                      NaN   \n",
       "26   0.513021  0.655599         85.833333                      NaN   \n",
       "14   0.496745  0.678385         93.593750                      NaN   \n",
       "99   0.470052  0.649089               NaN                75.572917   \n",
       "111  0.378906  0.641927               NaN                97.135417   \n",
       "75   0.347005  0.671224               NaN                89.010417   \n",
       "63   0.336589  0.658854               NaN                      NaN   \n",
       "87   0.269531  0.649740               NaN                      NaN   \n",
       "123  0.251953  0.647135               NaN                      NaN   \n",
       "135  0.251953  0.656901               NaN                      NaN   \n",
       "147  0.224609  0.649089               NaN                      NaN   \n",
       "25   0.711589  0.697917         72.239583                      NaN   \n",
       "0    0.571615  0.705729               NaN                      NaN   \n",
       "97   0.558594  0.711589               NaN                85.260417   \n",
       "49   0.511068  0.708984         83.437500                      NaN   \n",
       "37   0.509766  0.699219         82.760417                      NaN   \n",
       "109  0.466146  0.714844               NaN                99.010417   \n",
       "73   0.401042  0.714844               NaN                76.562500   \n",
       "85   0.376953  0.712240               NaN                      NaN   \n",
       "61   0.306641  0.708333               NaN                      NaN   \n",
       "133  0.258464  0.696615               NaN                      NaN   \n",
       "121  0.252604  0.710938               NaN                      NaN   \n",
       "145  0.244141  0.701823               NaN                      NaN   \n",
       "39   0.671224  0.663411         57.083333                      NaN   \n",
       "3    0.589844  0.632812               NaN                      NaN   \n",
       "27   0.544271  0.650391         94.322917                      NaN   \n",
       "15   0.507812  0.641927         87.343750                      NaN   \n",
       "100  0.493490  0.672526               NaN                85.052083   \n",
       "112  0.447917  0.651042               NaN                98.541667   \n",
       "76   0.381510  0.669922               NaN                83.697917   \n",
       "64   0.294922  0.636068               NaN                      NaN   \n",
       "88   0.276693  0.662109               NaN                      NaN   \n",
       "124  0.251953  0.653646               NaN                      NaN   \n",
       "136  0.251953  0.642578               NaN                      NaN   \n",
       "148  0.231120  0.629557               NaN                      NaN   \n",
       "13   0.681641  0.732422         74.062500                      NaN   \n",
       "1    0.604167  0.720703               NaN                      NaN   \n",
       "98   0.573568  0.727214               NaN                96.510417   \n",
       "50   0.539062  0.709635         84.791667                      NaN   \n",
       "38   0.518229  0.706380         83.125000                      NaN   \n",
       "110  0.486328  0.718750               NaN                85.781250   \n",
       "86   0.404948  0.712891               NaN                64.687500   \n",
       "74   0.402344  0.716797               NaN                      NaN   \n",
       "62   0.366536  0.729167               NaN                      NaN   \n",
       "134  0.351562  0.710286               NaN                      NaN   \n",
       "122  0.250651  0.718750               NaN                      NaN   \n",
       "146  0.246094  0.716797               NaN                      NaN   \n",
       "\n",
       "     max_voting_l2d_%  max_voting_Source Accuracy_%  \n",
       "142         78.223963                      6.594842  \n",
       "154         80.476657                           NaN  \n",
       "57                NaN                           NaN  \n",
       "45                NaN                           NaN  \n",
       "9                 NaN                           NaN  \n",
       "21                NaN                           NaN  \n",
       "69                NaN                     99.771466  \n",
       "81                NaN                     99.771466  \n",
       "105               NaN                           NaN  \n",
       "117         22.494287                           NaN  \n",
       "93                NaN                           NaN  \n",
       "33                NaN                           NaN  \n",
       "130         82.468168                           NaN  \n",
       "155         48.841006                           NaN  \n",
       "58                NaN                           NaN  \n",
       "46                NaN                           NaN  \n",
       "10                NaN                           NaN  \n",
       "22                NaN                           NaN  \n",
       "82                NaN                     88.573294  \n",
       "70                NaN                     91.380999  \n",
       "118         40.417891                           NaN  \n",
       "94                NaN                           NaN  \n",
       "106               NaN                     93.176624  \n",
       "34                NaN                           NaN  \n",
       "131         76.852759                           NaN  \n",
       "143         62.553053                     33.006856  \n",
       "59                NaN                           NaN  \n",
       "11                NaN                           NaN  \n",
       "71                NaN                     84.263794  \n",
       "107               NaN                           NaN  \n",
       "47                NaN                           NaN  \n",
       "83                NaN                     84.622919  \n",
       "23                NaN                           NaN  \n",
       "119         45.837414                           NaN  \n",
       "95                NaN                           NaN  \n",
       "35                NaN                           NaN  \n",
       "102         92.572680                     69.295102  \n",
       "114         86.957387                           NaN  \n",
       "90          72.281959                           NaN  \n",
       "65                NaN                     82.935086  \n",
       "29                NaN                           NaN  \n",
       "17                NaN                           NaN  \n",
       "53                NaN                           NaN  \n",
       "41                NaN                           NaN  \n",
       "126               NaN                           NaN  \n",
       "5                 NaN                           NaN  \n",
       "150               NaN                           NaN  \n",
       "138               NaN                     47.829550  \n",
       "78          84.050179                     53.006770  \n",
       "103         89.725209                           NaN  \n",
       "115         77.837515                           NaN  \n",
       "66                NaN                     63.859020  \n",
       "18                NaN                           NaN  \n",
       "30                NaN                           NaN  \n",
       "54                NaN                           NaN  \n",
       "42                NaN                           NaN  \n",
       "6                 NaN                           NaN  \n",
       "127               NaN                           NaN  \n",
       "151               NaN                           NaN  \n",
       "139               NaN                     57.029072  \n",
       "79          93.687774                     80.804460  \n",
       "116         83.114297                           NaN  \n",
       "67                NaN                     82.696137  \n",
       "91          72.899243                           NaN  \n",
       "31                NaN                           NaN  \n",
       "19                NaN                           NaN  \n",
       "55                NaN                           NaN  \n",
       "43                NaN                           NaN  \n",
       "7                 NaN                           NaN  \n",
       "128               NaN                           NaN  \n",
       "152               NaN                           NaN  \n",
       "140               NaN                     40.262843  \n",
       "104         92.771804                           NaN  \n",
       "80          93.827160                     75.228992  \n",
       "92          80.923935                           NaN  \n",
       "68                NaN                     78.753485  \n",
       "32                NaN                           NaN  \n",
       "20                NaN                           NaN  \n",
       "56                NaN                           NaN  \n",
       "44                NaN                           NaN  \n",
       "8                 NaN                           NaN  \n",
       "129               NaN                           NaN  \n",
       "153               NaN                           NaN  \n",
       "141               NaN                     35.185185  \n",
       "101         91.377937                     91.636798  \n",
       "113         86.778176                           NaN  \n",
       "77          67.702111                     69.812824  \n",
       "89                NaN                           NaN  \n",
       "16                NaN                           NaN  \n",
       "28                NaN                           NaN  \n",
       "40                NaN                           NaN  \n",
       "52                NaN                           NaN  \n",
       "137               NaN                     49.143767  \n",
       "4                 NaN                           NaN  \n",
       "149               NaN                           NaN  \n",
       "125               NaN                           NaN  \n",
       "12          56.302083                           NaN  \n",
       "24                NaN                           NaN  \n",
       "48          88.177083                           NaN  \n",
       "96                NaN                           NaN  \n",
       "108               NaN                           NaN  \n",
       "36          75.729167                           NaN  \n",
       "72                NaN                     97.604167  \n",
       "144               NaN                           NaN  \n",
       "84                NaN                           NaN  \n",
       "60                NaN                     19.010417  \n",
       "120               NaN                           NaN  \n",
       "132               NaN                     82.343750  \n",
       "51          81.718750                           NaN  \n",
       "2           90.260417                           NaN  \n",
       "26                NaN                           NaN  \n",
       "14          69.947917                           NaN  \n",
       "99                NaN                           NaN  \n",
       "111               NaN                           NaN  \n",
       "75                NaN                     98.854167  \n",
       "63                NaN                     37.031250  \n",
       "87                NaN                           NaN  \n",
       "123               NaN                           NaN  \n",
       "135               NaN                     71.614583  \n",
       "147               NaN                           NaN  \n",
       "25          74.427083                           NaN  \n",
       "0           84.843750                           NaN  \n",
       "97                NaN                           NaN  \n",
       "49          79.791667                           NaN  \n",
       "37                NaN                           NaN  \n",
       "109               NaN                           NaN  \n",
       "73                NaN                     96.666667  \n",
       "85                NaN                           NaN  \n",
       "61                NaN                     37.395833  \n",
       "133               NaN                     68.697917  \n",
       "121               NaN                           NaN  \n",
       "145               NaN                           NaN  \n",
       "39          70.468750                           NaN  \n",
       "3           89.114583                           NaN  \n",
       "27                NaN                           NaN  \n",
       "15          70.208333                           NaN  \n",
       "100               NaN                           NaN  \n",
       "112               NaN                           NaN  \n",
       "76                NaN                     96.927083  \n",
       "64                NaN                     43.229167  \n",
       "88                NaN                           NaN  \n",
       "124               NaN                           NaN  \n",
       "136               NaN                     61.614583  \n",
       "148               NaN                           NaN  \n",
       "13          73.697917                           NaN  \n",
       "1           88.802083                           NaN  \n",
       "98                NaN                           NaN  \n",
       "50          84.010417                           NaN  \n",
       "38                NaN                           NaN  \n",
       "110               NaN                           NaN  \n",
       "86                NaN                           NaN  \n",
       "74                NaN                     74.270833  \n",
       "62                NaN                     60.052083  \n",
       "134               NaN                     52.135417  \n",
       "122               NaN                           NaN  \n",
       "146               NaN                           NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad37c13",
   "metadata": {
    "papermill": {
     "duration": 0.808532,
     "end_time": "2022-04-12T19:02:42.889156",
     "exception": false,
     "start_time": "2022-04-12T19:02:42.080624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 617.95951,
   "end_time": "2022-04-12T19:02:47.150952",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-12T18:52:29.191442",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1338ec043ca2434c80a47dfdd2a1dc10": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4a10a9e5485c4ef1b3f9b9b944240d18": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "503f5a9b02934380931f22af9553ac11": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d54c395613f94dc085027ec2f7924f37",
       "placeholder": "​",
       "style": "IPY_MODEL_c15b9e2acba3422cad66822c30510add",
       "value": " 77/78 [00:04&lt;00:00, 14.66it/s]"
      }
     },
     "507e58d1affa4608ac29d4bbc3d94ac7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_be7ca5137d7642768d7c80b14ad0264b",
       "placeholder": "​",
       "style": "IPY_MODEL_d0636fdbe91b4719ba324322871898b4",
       "value": "100%"
      }
     },
     "675411d7ffcb44199dc910a4f4fff8c6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1338ec043ca2434c80a47dfdd2a1dc10",
       "placeholder": "​",
       "style": "IPY_MODEL_f9e337a0260743d281b0c72b80473681",
       "value": " 99%"
      }
     },
     "6acdb566f3ce446f9685b0071739caaf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "73849996d20041bb9e3bf119a98e7980": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "76f404759c6f42e8a040eb8a7029f50b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "78fc05a90df344508092df431759ae38": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8d050cfad694464883433fbde8e3880a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_73849996d20041bb9e3bf119a98e7980",
       "max": 156.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6acdb566f3ce446f9685b0071739caaf",
       "value": 156.0
      }
     },
     "9522508d0af648f6b06bda27998a0494": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_507e58d1affa4608ac29d4bbc3d94ac7",
        "IPY_MODEL_8d050cfad694464883433fbde8e3880a",
        "IPY_MODEL_c8ef2caa439342ecb8a7daf1b627cca4"
       ],
       "layout": "IPY_MODEL_ead6075e0a20465bbbe9fcacb8284df2"
      }
     },
     "bd72bc51dd1f4cdfad4046487d1b8f9c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "be7ca5137d7642768d7c80b14ad0264b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c15b9e2acba3422cad66822c30510add": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c8ef2caa439342ecb8a7daf1b627cca4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e6eaa807dbbc4b5786f55d4903e03dd9",
       "placeholder": "​",
       "style": "IPY_MODEL_bd72bc51dd1f4cdfad4046487d1b8f9c",
       "value": " 156/156 [08:04&lt;00:00,  3.17s/it]"
      }
     },
     "d0636fdbe91b4719ba324322871898b4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d54c395613f94dc085027ec2f7924f37": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e283818e2814495c9965999f2ff99bb8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_78fc05a90df344508092df431759ae38",
       "max": 78.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_76f404759c6f42e8a040eb8a7029f50b",
       "value": 78.0
      }
     },
     "e6eaa807dbbc4b5786f55d4903e03dd9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ead6075e0a20465bbbe9fcacb8284df2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f0a281fc0d3e4299a7798566bc3758b1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_675411d7ffcb44199dc910a4f4fff8c6",
        "IPY_MODEL_e283818e2814495c9965999f2ff99bb8",
        "IPY_MODEL_503f5a9b02934380931f22af9553ac11"
       ],
       "layout": "IPY_MODEL_4a10a9e5485c4ef1b3f9b9b944240d18"
      }
     },
     "f9e337a0260743d281b0c72b80473681": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
